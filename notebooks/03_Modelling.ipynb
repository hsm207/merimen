{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook builds and evaluates a model to classify customer behavior as fraudulent or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to project's root directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-beta1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"./data/train_feat.parquet\")\n",
    "valid_df = pd.read_parquet(\"./data/valid_feat.parquet\")\n",
    "fraud_df = pd.read_parquet(\"./data/fraud_feat.parquet\")\n",
    "\n",
    "test_df = pd.read_parquet(\"./data/test_feat.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Behavior1',\n",
       " 'Behavior2',\n",
       " 'Behavior3',\n",
       " 'Behavior4',\n",
       " 'Behavior5',\n",
       " 'Behavior6',\n",
       " 'Behavior7',\n",
       " 'Behavior8',\n",
       " 'Behavior9',\n",
       " 'Behavior10',\n",
       " 'Behavior11']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [f\"Behavior{i}\" for i in range(1, 12)]\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = len(feature_cols)\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_fraud, _ = fraud_df.shape\n",
    "num_fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Behavior1</th>\n",
       "      <th>Behavior2</th>\n",
       "      <th>Behavior3</th>\n",
       "      <th>Behavior4</th>\n",
       "      <th>Behavior5</th>\n",
       "      <th>Behavior6</th>\n",
       "      <th>Behavior7</th>\n",
       "      <th>Behavior8</th>\n",
       "      <th>Behavior9</th>\n",
       "      <th>Behavior10</th>\n",
       "      <th>Behavior11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-1.116949</td>\n",
       "      <td>-0.284010</td>\n",
       "      <td>-1.070120</td>\n",
       "      <td>-0.827804</td>\n",
       "      <td>0.169460</td>\n",
       "      <td>1.381103</td>\n",
       "      <td>0.715423</td>\n",
       "      <td>0.479916</td>\n",
       "      <td>1.166299</td>\n",
       "      <td>-1.049028</td>\n",
       "      <td>-0.863424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.685185</td>\n",
       "      <td>-1.455636</td>\n",
       "      <td>-0.763855</td>\n",
       "      <td>0.910445</td>\n",
       "      <td>2.492966</td>\n",
       "      <td>-1.559258</td>\n",
       "      <td>-0.738419</td>\n",
       "      <td>-0.556776</td>\n",
       "      <td>1.076575</td>\n",
       "      <td>-0.469531</td>\n",
       "      <td>-0.599081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.882029</td>\n",
       "      <td>0.929629</td>\n",
       "      <td>-0.199266</td>\n",
       "      <td>1.172973</td>\n",
       "      <td>0.270157</td>\n",
       "      <td>0.804269</td>\n",
       "      <td>0.087448</td>\n",
       "      <td>0.177107</td>\n",
       "      <td>1.164299</td>\n",
       "      <td>-1.382487</td>\n",
       "      <td>-0.409866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1.965932</td>\n",
       "      <td>1.088959</td>\n",
       "      <td>0.954181</td>\n",
       "      <td>-1.865497</td>\n",
       "      <td>-0.236305</td>\n",
       "      <td>1.540129</td>\n",
       "      <td>-1.697855</td>\n",
       "      <td>-0.002534</td>\n",
       "      <td>1.047617</td>\n",
       "      <td>0.836702</td>\n",
       "      <td>0.179371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.337095</td>\n",
       "      <td>1.921309</td>\n",
       "      <td>0.445954</td>\n",
       "      <td>0.775971</td>\n",
       "      <td>2.157673</td>\n",
       "      <td>-1.365846</td>\n",
       "      <td>1.344258</td>\n",
       "      <td>-0.228552</td>\n",
       "      <td>1.661230</td>\n",
       "      <td>0.573365</td>\n",
       "      <td>0.135853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.642768</td>\n",
       "      <td>0.073340</td>\n",
       "      <td>0.026926</td>\n",
       "      <td>-0.690515</td>\n",
       "      <td>0.937142</td>\n",
       "      <td>0.661341</td>\n",
       "      <td>-0.607261</td>\n",
       "      <td>-0.550967</td>\n",
       "      <td>-0.701392</td>\n",
       "      <td>-0.668839</td>\n",
       "      <td>0.630568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>-0.414703</td>\n",
       "      <td>1.103888</td>\n",
       "      <td>1.693856</td>\n",
       "      <td>-0.757967</td>\n",
       "      <td>-0.175606</td>\n",
       "      <td>-0.033972</td>\n",
       "      <td>1.084393</td>\n",
       "      <td>0.013140</td>\n",
       "      <td>1.019464</td>\n",
       "      <td>0.246194</td>\n",
       "      <td>-1.160555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Behavior1  Behavior2  Behavior3  Behavior4  Behavior5  Behavior6  \\\n",
       "50   -1.116949  -0.284010  -1.070120  -0.827804   0.169460   1.381103   \n",
       "127   0.685185  -1.455636  -0.763855   0.910445   2.492966  -1.559258   \n",
       "37    0.882029   0.929629  -0.199266   1.172973   0.270157   0.804269   \n",
       "149   1.965932   1.088959   0.954181  -1.865497  -0.236305   1.540129   \n",
       "19    0.337095   1.921309   0.445954   0.775971   2.157673  -1.365846   \n",
       "104   0.642768   0.073340   0.026926  -0.690515   0.937142   0.661341   \n",
       "179  -0.414703   1.103888   1.693856  -0.757967  -0.175606  -0.033972   \n",
       "\n",
       "     Behavior7  Behavior8  Behavior9  Behavior10  Behavior11  \n",
       "50    0.715423   0.479916   1.166299   -1.049028   -0.863424  \n",
       "127  -0.738419  -0.556776   1.076575   -0.469531   -0.599081  \n",
       "37    0.087448   0.177107   1.164299   -1.382487   -0.409866  \n",
       "149  -1.697855  -0.002534   1.047617    0.836702    0.179371  \n",
       "19    1.344258  -0.228552   1.661230    0.573365    0.135853  \n",
       "104  -0.607261  -0.550967  -0.701392   -0.668839    0.630568  \n",
       "179   1.084393   0.013140   1.019464    0.246194   -1.160555  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = valid_df.sample(n=num_fraud, random_state=123)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to evaluate a model in terms of its reconstruction error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    eval_features = eval_df[feature_cols].values\n",
    "    fraud_features = fraud_df[feature_cols].values\n",
    "    \n",
    "    loss_eval, _ = model.evaluate(x= eval_features,\n",
    "                                  y= eval_features)\n",
    "\n",
    "    loss_fraud, _ = model.evaluate(x=fraud_features,\n",
    "                                   y=fraud_features)\n",
    "\n",
    "    print(f\"Average loss on the eval set:\\t{loss_eval:>7.4f}\\nAverage loss on fraud set:\\t {loss_fraud:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute the reconstruction loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reconstruction_loss(model, df):\n",
    "    features = df[feature_cols].values\n",
    "    predictions = model.predict(features)\n",
    "    losses = tf.keras.losses.mean_squared_error(y_true=features,\n",
    "                                                y_pred=predictions)\n",
    "    \n",
    "    return pd.DataFrame({\"reconstruction_loss\": losses})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/500\n",
      "800/800 [==============================] - 0s 293us/sample - loss: 1.1860 - mean_squared_error: 1.1860 - val_loss: 1.1496 - val_mean_squared_error: 1.1496\n",
      "Epoch 2/500\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 1.0675 - mean_squared_error: 1.0675 - val_loss: 1.0467 - val_mean_squared_error: 1.0467\n",
      "Epoch 3/500\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.9771 - mean_squared_error: 0.9771 - val_loss: 0.9687 - val_mean_squared_error: 0.9687\n",
      "Epoch 4/500\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 0.9079 - mean_squared_error: 0.9079 - val_loss: 0.9076 - val_mean_squared_error: 0.9076\n",
      "Epoch 5/500\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.8518 - mean_squared_error: 0.8518 - val_loss: 0.8587 - val_mean_squared_error: 0.8587\n",
      "Epoch 6/500\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.8064 - mean_squared_error: 0.8064 - val_loss: 0.8178 - val_mean_squared_error: 0.8178\n",
      "Epoch 7/500\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.7681 - mean_squared_error: 0.7681 - val_loss: 0.7827 - val_mean_squared_error: 0.7827\n",
      "Epoch 8/500\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.7348 - mean_squared_error: 0.7348 - val_loss: 0.7526 - val_mean_squared_error: 0.7526\n",
      "Epoch 9/500\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.7062 - mean_squared_error: 0.7062 - val_loss: 0.7255 - val_mean_squared_error: 0.7255\n",
      "Epoch 10/500\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.6807 - mean_squared_error: 0.6807 - val_loss: 0.7024 - val_mean_squared_error: 0.7024\n",
      "Epoch 11/500\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 0.6586 - mean_squared_error: 0.6586 - val_loss: 0.6820 - val_mean_squared_error: 0.6820\n",
      "Epoch 12/500\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.6390 - mean_squared_error: 0.6390 - val_loss: 0.6638 - val_mean_squared_error: 0.6638\n",
      "Epoch 13/500\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.6216 - mean_squared_error: 0.6216 - val_loss: 0.6477 - val_mean_squared_error: 0.6477\n",
      "Epoch 14/500\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 0.6062 - mean_squared_error: 0.6062 - val_loss: 0.6337 - val_mean_squared_error: 0.6337\n",
      "Epoch 15/500\n",
      "800/800 [==============================] - 0s 201us/sample - loss: 0.5925 - mean_squared_error: 0.5925 - val_loss: 0.6216 - val_mean_squared_error: 0.6216\n",
      "Epoch 16/500\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5802 - mean_squared_error: 0.5802 - val_loss: 0.6106 - val_mean_squared_error: 0.6106\n",
      "Epoch 17/500\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5693 - mean_squared_error: 0.5693 - val_loss: 0.6008 - val_mean_squared_error: 0.6008\n",
      "Epoch 18/500\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5593 - mean_squared_error: 0.5593 - val_loss: 0.5920 - val_mean_squared_error: 0.5920\n",
      "Epoch 19/500\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5502 - mean_squared_error: 0.5502 - val_loss: 0.5841 - val_mean_squared_error: 0.5841\n",
      "Epoch 20/500\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.5418 - mean_squared_error: 0.5418 - val_loss: 0.5768 - val_mean_squared_error: 0.5768\n",
      "Epoch 21/500\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.5340 - mean_squared_error: 0.5340 - val_loss: 0.5704 - val_mean_squared_error: 0.5704\n",
      "Epoch 22/500\n",
      "800/800 [==============================] - 0s 44us/sample - loss: 0.5268 - mean_squared_error: 0.5268 - val_loss: 0.5642 - val_mean_squared_error: 0.5642\n",
      "Epoch 23/500\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.5202 - mean_squared_error: 0.5202 - val_loss: 0.5585 - val_mean_squared_error: 0.5585\n",
      "Epoch 24/500\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.5140 - mean_squared_error: 0.5140 - val_loss: 0.5531 - val_mean_squared_error: 0.5531\n",
      "Epoch 25/500\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 0.5081 - mean_squared_error: 0.5081 - val_loss: 0.5486 - val_mean_squared_error: 0.5486\n",
      "Epoch 26/500\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.5028 - mean_squared_error: 0.5028 - val_loss: 0.5437 - val_mean_squared_error: 0.5437\n",
      "Epoch 27/500\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.4977 - mean_squared_error: 0.4977 - val_loss: 0.5395 - val_mean_squared_error: 0.5395\n",
      "Epoch 28/500\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.4933 - mean_squared_error: 0.4933 - val_loss: 0.5358 - val_mean_squared_error: 0.5358\n",
      "Epoch 29/500\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.4890 - mean_squared_error: 0.4890 - val_loss: 0.5323 - val_mean_squared_error: 0.5323\n",
      "Epoch 30/500\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4852 - mean_squared_error: 0.4852 - val_loss: 0.5291 - val_mean_squared_error: 0.5291\n",
      "Epoch 31/500\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4819 - mean_squared_error: 0.4819 - val_loss: 0.5260 - val_mean_squared_error: 0.5260\n",
      "Epoch 32/500\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.4789 - mean_squared_error: 0.4789 - val_loss: 0.5238 - val_mean_squared_error: 0.5238\n",
      "Epoch 33/500\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.4761 - mean_squared_error: 0.4761 - val_loss: 0.5215 - val_mean_squared_error: 0.5215\n",
      "Epoch 34/500\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.4739 - mean_squared_error: 0.4739 - val_loss: 0.5195 - val_mean_squared_error: 0.5195\n",
      "Epoch 35/500\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.4715 - mean_squared_error: 0.4715 - val_loss: 0.5179 - val_mean_squared_error: 0.5179\n",
      "Epoch 36/500\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.4697 - mean_squared_error: 0.4697 - val_loss: 0.5162 - val_mean_squared_error: 0.5162\n",
      "Epoch 37/500\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4680 - mean_squared_error: 0.4680 - val_loss: 0.5149 - val_mean_squared_error: 0.5149\n",
      "Epoch 38/500\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4665 - mean_squared_error: 0.4665 - val_loss: 0.5138 - val_mean_squared_error: 0.5138\n",
      "Epoch 39/500\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4651 - mean_squared_error: 0.4651 - val_loss: 0.5127 - val_mean_squared_error: 0.5127\n",
      "Epoch 40/500\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4639 - mean_squared_error: 0.4639 - val_loss: 0.5117 - val_mean_squared_error: 0.5117\n",
      "Epoch 41/500\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4628 - mean_squared_error: 0.4628 - val_loss: 0.5108 - val_mean_squared_error: 0.5108\n",
      "Epoch 42/500\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4617 - mean_squared_error: 0.4617 - val_loss: 0.5100 - val_mean_squared_error: 0.5100\n",
      "Epoch 43/500\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4608 - mean_squared_error: 0.4608 - val_loss: 0.5088 - val_mean_squared_error: 0.5088\n",
      "Epoch 44/500\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4598 - mean_squared_error: 0.4598 - val_loss: 0.5083 - val_mean_squared_error: 0.5083\n",
      "Epoch 45/500\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4591 - mean_squared_error: 0.4591 - val_loss: 0.5076 - val_mean_squared_error: 0.5076\n",
      "Epoch 46/500\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.4582 - mean_squared_error: 0.4582 - val_loss: 0.5069 - val_mean_squared_error: 0.5069\n",
      "Epoch 47/500\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.4574 - mean_squared_error: 0.4574 - val_loss: 0.5063 - val_mean_squared_error: 0.5063\n",
      "Epoch 48/500\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4565 - mean_squared_error: 0.4565 - val_loss: 0.5057 - val_mean_squared_error: 0.5057\n",
      "Epoch 49/500\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4558 - mean_squared_error: 0.4558 - val_loss: 0.5049 - val_mean_squared_error: 0.5049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.4552 - mean_squared_error: 0.4552 - val_loss: 0.5043 - val_mean_squared_error: 0.5043\n",
      "Epoch 51/500\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4545 - mean_squared_error: 0.4545 - val_loss: 0.5034 - val_mean_squared_error: 0.5034\n",
      "Epoch 52/500\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4537 - mean_squared_error: 0.4537 - val_loss: 0.5029 - val_mean_squared_error: 0.5029\n",
      "Epoch 53/500\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4529 - mean_squared_error: 0.4529 - val_loss: 0.5022 - val_mean_squared_error: 0.5022\n",
      "Epoch 54/500\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.4523 - mean_squared_error: 0.4523 - val_loss: 0.5016 - val_mean_squared_error: 0.5016\n",
      "Epoch 55/500\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4516 - mean_squared_error: 0.4516 - val_loss: 0.5010 - val_mean_squared_error: 0.5010\n",
      "Epoch 56/500\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4510 - mean_squared_error: 0.4510 - val_loss: 0.5003 - val_mean_squared_error: 0.5003\n",
      "Epoch 57/500\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.4503 - mean_squared_error: 0.4503 - val_loss: 0.4999 - val_mean_squared_error: 0.4999\n",
      "Epoch 58/500\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4497 - mean_squared_error: 0.4497 - val_loss: 0.4992 - val_mean_squared_error: 0.4992\n",
      "Epoch 59/500\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4492 - mean_squared_error: 0.4492 - val_loss: 0.4986 - val_mean_squared_error: 0.4986\n",
      "Epoch 60/500\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4485 - mean_squared_error: 0.4485 - val_loss: 0.4980 - val_mean_squared_error: 0.4980\n",
      "Epoch 61/500\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 0.4478 - mean_squared_error: 0.4478 - val_loss: 0.4970 - val_mean_squared_error: 0.4970\n",
      "Epoch 62/500\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 0.4472 - mean_squared_error: 0.4472 - val_loss: 0.4965 - val_mean_squared_error: 0.4965\n",
      "Epoch 63/500\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.4467 - mean_squared_error: 0.4467 - val_loss: 0.4959 - val_mean_squared_error: 0.4959\n",
      "Epoch 64/500\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.4459 - mean_squared_error: 0.4459 - val_loss: 0.4955 - val_mean_squared_error: 0.4955\n",
      "Epoch 65/500\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 0.4454 - mean_squared_error: 0.4454 - val_loss: 0.4948 - val_mean_squared_error: 0.4948\n",
      "Epoch 66/500\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.4447 - mean_squared_error: 0.4447 - val_loss: 0.4940 - val_mean_squared_error: 0.4940\n",
      "Epoch 67/500\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4441 - mean_squared_error: 0.4441 - val_loss: 0.4932 - val_mean_squared_error: 0.4932\n",
      "Epoch 68/500\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4435 - mean_squared_error: 0.4435 - val_loss: 0.4927 - val_mean_squared_error: 0.4927\n",
      "Epoch 69/500\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4430 - mean_squared_error: 0.4430 - val_loss: 0.4920 - val_mean_squared_error: 0.4920\n",
      "Epoch 70/500\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4423 - mean_squared_error: 0.4423 - val_loss: 0.4914 - val_mean_squared_error: 0.4914\n",
      "Epoch 71/500\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4417 - mean_squared_error: 0.4417 - val_loss: 0.4909 - val_mean_squared_error: 0.4909\n",
      "Epoch 72/500\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4412 - mean_squared_error: 0.4412 - val_loss: 0.4901 - val_mean_squared_error: 0.4901\n",
      "Epoch 73/500\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4406 - mean_squared_error: 0.4406 - val_loss: 0.4898 - val_mean_squared_error: 0.4898\n",
      "Epoch 74/500\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4399 - mean_squared_error: 0.4399 - val_loss: 0.4890 - val_mean_squared_error: 0.4890\n",
      "Epoch 75/500\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4393 - mean_squared_error: 0.4393 - val_loss: 0.4882 - val_mean_squared_error: 0.4882\n",
      "Epoch 76/500\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4385 - mean_squared_error: 0.4385 - val_loss: 0.4875 - val_mean_squared_error: 0.4875\n",
      "Epoch 77/500\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.4380 - mean_squared_error: 0.4380 - val_loss: 0.4871 - val_mean_squared_error: 0.4871\n",
      "Epoch 78/500\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 0.4373 - mean_squared_error: 0.4373 - val_loss: 0.4866 - val_mean_squared_error: 0.4866\n",
      "Epoch 79/500\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 0.4367 - mean_squared_error: 0.4367 - val_loss: 0.4857 - val_mean_squared_error: 0.4857\n",
      "Epoch 80/500\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.4361 - mean_squared_error: 0.4361 - val_loss: 0.4851 - val_mean_squared_error: 0.4851\n",
      "Epoch 81/500\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 0.4356 - mean_squared_error: 0.4356 - val_loss: 0.4846 - val_mean_squared_error: 0.4846\n",
      "Epoch 82/500\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 0.4349 - mean_squared_error: 0.4349 - val_loss: 0.4839 - val_mean_squared_error: 0.4839\n",
      "Epoch 83/500\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 0.4342 - mean_squared_error: 0.4342 - val_loss: 0.4830 - val_mean_squared_error: 0.4830\n",
      "Epoch 84/500\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 0.4337 - mean_squared_error: 0.4337 - val_loss: 0.4827 - val_mean_squared_error: 0.4827\n",
      "Epoch 85/500\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.4331 - mean_squared_error: 0.4331 - val_loss: 0.4819 - val_mean_squared_error: 0.4819\n",
      "Epoch 86/500\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.4324 - mean_squared_error: 0.4324 - val_loss: 0.4812 - val_mean_squared_error: 0.4812\n",
      "Epoch 87/500\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.4318 - mean_squared_error: 0.4318 - val_loss: 0.4806 - val_mean_squared_error: 0.4806\n",
      "Epoch 88/500\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.4312 - mean_squared_error: 0.4312 - val_loss: 0.4799 - val_mean_squared_error: 0.4799\n",
      "Epoch 89/500\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.4305 - mean_squared_error: 0.4305 - val_loss: 0.4790 - val_mean_squared_error: 0.4790\n",
      "Epoch 90/500\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 0.4298 - mean_squared_error: 0.4298 - val_loss: 0.4783 - val_mean_squared_error: 0.4783\n",
      "Epoch 91/500\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4292 - mean_squared_error: 0.4292 - val_loss: 0.4781 - val_mean_squared_error: 0.4781\n",
      "Epoch 92/500\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.4286 - mean_squared_error: 0.4286 - val_loss: 0.4771 - val_mean_squared_error: 0.4771\n",
      "Epoch 93/500\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 0.4278 - mean_squared_error: 0.4278 - val_loss: 0.4765 - val_mean_squared_error: 0.4765\n",
      "Epoch 94/500\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.4273 - mean_squared_error: 0.4273 - val_loss: 0.4759 - val_mean_squared_error: 0.4759\n",
      "Epoch 95/500\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.4267 - mean_squared_error: 0.4267 - val_loss: 0.4755 - val_mean_squared_error: 0.4755\n",
      "Epoch 96/500\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4260 - mean_squared_error: 0.4260 - val_loss: 0.4744 - val_mean_squared_error: 0.4744\n",
      "Epoch 97/500\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.4253 - mean_squared_error: 0.4253 - val_loss: 0.4735 - val_mean_squared_error: 0.4735\n",
      "Epoch 98/500\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4246 - mean_squared_error: 0.4246 - val_loss: 0.4732 - val_mean_squared_error: 0.4732\n",
      "Epoch 99/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4241 - mean_squared_error: 0.4241 - val_loss: 0.4723 - val_mean_squared_error: 0.4723\n",
      "Epoch 100/500\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4234 - mean_squared_error: 0.4234 - val_loss: 0.4720 - val_mean_squared_error: 0.4720\n",
      "Epoch 101/500\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.4227 - mean_squared_error: 0.4227 - val_loss: 0.4708 - val_mean_squared_error: 0.4708\n",
      "Epoch 102/500\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.4221 - mean_squared_error: 0.4221 - val_loss: 0.4707 - val_mean_squared_error: 0.4707\n",
      "Epoch 103/500\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.4215 - mean_squared_error: 0.4215 - val_loss: 0.4698 - val_mean_squared_error: 0.4698\n",
      "Epoch 104/500\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4210 - mean_squared_error: 0.4210 - val_loss: 0.4691 - val_mean_squared_error: 0.4691\n",
      "Epoch 105/500\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.4203 - mean_squared_error: 0.4203 - val_loss: 0.4687 - val_mean_squared_error: 0.4687\n",
      "Epoch 106/500\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.4196 - mean_squared_error: 0.4196 - val_loss: 0.4678 - val_mean_squared_error: 0.4678\n",
      "Epoch 107/500\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.4191 - mean_squared_error: 0.4191 - val_loss: 0.4667 - val_mean_squared_error: 0.4667\n",
      "Epoch 108/500\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.4185 - mean_squared_error: 0.4185 - val_loss: 0.4662 - val_mean_squared_error: 0.4662\n",
      "Epoch 109/500\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.4178 - mean_squared_error: 0.4178 - val_loss: 0.4655 - val_mean_squared_error: 0.4655\n",
      "Epoch 110/500\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.4173 - mean_squared_error: 0.4173 - val_loss: 0.4647 - val_mean_squared_error: 0.4647\n",
      "Epoch 111/500\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.4166 - mean_squared_error: 0.4166 - val_loss: 0.4638 - val_mean_squared_error: 0.4638\n",
      "Epoch 112/500\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4159 - mean_squared_error: 0.4159 - val_loss: 0.4637 - val_mean_squared_error: 0.4637\n",
      "Epoch 113/500\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4153 - mean_squared_error: 0.4153 - val_loss: 0.4629 - val_mean_squared_error: 0.4629\n",
      "Epoch 114/500\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4150 - mean_squared_error: 0.4150 - val_loss: 0.4618 - val_mean_squared_error: 0.4618\n",
      "Epoch 115/500\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4143 - mean_squared_error: 0.4143 - val_loss: 0.4618 - val_mean_squared_error: 0.4618\n",
      "Epoch 116/500\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.4137 - mean_squared_error: 0.4137 - val_loss: 0.4607 - val_mean_squared_error: 0.4607\n",
      "Epoch 117/500\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.4132 - mean_squared_error: 0.4132 - val_loss: 0.4599 - val_mean_squared_error: 0.4599\n",
      "Epoch 118/500\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4123 - mean_squared_error: 0.4123 - val_loss: 0.4591 - val_mean_squared_error: 0.4591\n",
      "Epoch 119/500\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.4120 - mean_squared_error: 0.4120 - val_loss: 0.4588 - val_mean_squared_error: 0.4588\n",
      "Epoch 120/500\n",
      "800/800 [==============================] - 0s 44us/sample - loss: 0.4113 - mean_squared_error: 0.4113 - val_loss: 0.4580 - val_mean_squared_error: 0.4580\n",
      "Epoch 121/500\n",
      "800/800 [==============================] - 0s 43us/sample - loss: 0.4109 - mean_squared_error: 0.4109 - val_loss: 0.4576 - val_mean_squared_error: 0.4576\n",
      "Epoch 122/500\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.4102 - mean_squared_error: 0.4102 - val_loss: 0.4564 - val_mean_squared_error: 0.4564\n",
      "Epoch 123/500\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.4095 - mean_squared_error: 0.4095 - val_loss: 0.4561 - val_mean_squared_error: 0.4561\n",
      "Epoch 124/500\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4091 - mean_squared_error: 0.4091 - val_loss: 0.4554 - val_mean_squared_error: 0.4554\n",
      "Epoch 125/500\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.4086 - mean_squared_error: 0.4086 - val_loss: 0.4542 - val_mean_squared_error: 0.4542\n",
      "Epoch 126/500\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4080 - mean_squared_error: 0.4080 - val_loss: 0.4543 - val_mean_squared_error: 0.4543\n",
      "Epoch 127/500\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.4077 - mean_squared_error: 0.4077 - val_loss: 0.4538 - val_mean_squared_error: 0.4538\n",
      "Epoch 128/500\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4070 - mean_squared_error: 0.4070 - val_loss: 0.4522 - val_mean_squared_error: 0.4522\n",
      "Epoch 129/500\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4065 - mean_squared_error: 0.4065 - val_loss: 0.4522 - val_mean_squared_error: 0.4522\n",
      "Epoch 130/500\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 0.4061 - mean_squared_error: 0.4061 - val_loss: 0.4517 - val_mean_squared_error: 0.4517\n",
      "Epoch 131/500\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.4054 - mean_squared_error: 0.4054 - val_loss: 0.4514 - val_mean_squared_error: 0.4514\n",
      "Epoch 132/500\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.4048 - mean_squared_error: 0.4048 - val_loss: 0.4503 - val_mean_squared_error: 0.4503\n",
      "Epoch 133/500\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4046 - mean_squared_error: 0.4046 - val_loss: 0.4499 - val_mean_squared_error: 0.4499\n",
      "Epoch 134/500\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4040 - mean_squared_error: 0.4040 - val_loss: 0.4492 - val_mean_squared_error: 0.4492\n",
      "Epoch 135/500\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4034 - mean_squared_error: 0.4034 - val_loss: 0.4492 - val_mean_squared_error: 0.4492\n",
      "Epoch 136/500\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4030 - mean_squared_error: 0.4030 - val_loss: 0.4480 - val_mean_squared_error: 0.4480\n",
      "Epoch 137/500\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.4023 - mean_squared_error: 0.4023 - val_loss: 0.4474 - val_mean_squared_error: 0.4474\n",
      "Epoch 138/500\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.4021 - mean_squared_error: 0.4021 - val_loss: 0.4469 - val_mean_squared_error: 0.4469\n",
      "Epoch 139/500\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.4016 - mean_squared_error: 0.4016 - val_loss: 0.4466 - val_mean_squared_error: 0.4466\n",
      "Epoch 140/500\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 0.4012 - mean_squared_error: 0.4012 - val_loss: 0.4458 - val_mean_squared_error: 0.4458\n",
      "Epoch 141/500\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.4007 - mean_squared_error: 0.4007 - val_loss: 0.4457 - val_mean_squared_error: 0.4457\n",
      "Epoch 142/500\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.4002 - mean_squared_error: 0.4002 - val_loss: 0.4448 - val_mean_squared_error: 0.4448\n",
      "Epoch 143/500\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.4000 - mean_squared_error: 0.4000 - val_loss: 0.4446 - val_mean_squared_error: 0.4446\n",
      "Epoch 144/500\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3995 - mean_squared_error: 0.3995 - val_loss: 0.4443 - val_mean_squared_error: 0.4443\n",
      "Epoch 145/500\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3992 - mean_squared_error: 0.3992 - val_loss: 0.4430 - val_mean_squared_error: 0.4430\n",
      "Epoch 146/500\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.3985 - mean_squared_error: 0.3985 - val_loss: 0.4428 - val_mean_squared_error: 0.4428\n",
      "Epoch 147/500\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3981 - mean_squared_error: 0.3981 - val_loss: 0.4424 - val_mean_squared_error: 0.4424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/500\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3978 - mean_squared_error: 0.3978 - val_loss: 0.4422 - val_mean_squared_error: 0.4422\n",
      "Epoch 149/500\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3973 - mean_squared_error: 0.3973 - val_loss: 0.4413 - val_mean_squared_error: 0.4413\n",
      "Epoch 150/500\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3971 - mean_squared_error: 0.3971 - val_loss: 0.4407 - val_mean_squared_error: 0.4407\n",
      "Epoch 151/500\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.3968 - mean_squared_error: 0.3968 - val_loss: 0.4407 - val_mean_squared_error: 0.4407\n",
      "Epoch 152/500\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.3965 - mean_squared_error: 0.3965 - val_loss: 0.4404 - val_mean_squared_error: 0.4404\n",
      "Epoch 153/500\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.3962 - mean_squared_error: 0.3962 - val_loss: 0.4393 - val_mean_squared_error: 0.4393\n",
      "Epoch 154/500\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3957 - mean_squared_error: 0.3957 - val_loss: 0.4390 - val_mean_squared_error: 0.4390\n",
      "Epoch 155/500\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.3953 - mean_squared_error: 0.3953 - val_loss: 0.4390 - val_mean_squared_error: 0.4390\n",
      "Epoch 156/500\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3952 - mean_squared_error: 0.3952 - val_loss: 0.4380 - val_mean_squared_error: 0.4380\n",
      "Epoch 157/500\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3945 - mean_squared_error: 0.3945 - val_loss: 0.4379 - val_mean_squared_error: 0.4379\n",
      "Epoch 158/500\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3943 - mean_squared_error: 0.3943 - val_loss: 0.4377 - val_mean_squared_error: 0.4377\n",
      "Epoch 159/500\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3942 - mean_squared_error: 0.3942 - val_loss: 0.4377 - val_mean_squared_error: 0.4377\n",
      "Epoch 160/500\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3938 - mean_squared_error: 0.3938 - val_loss: 0.4365 - val_mean_squared_error: 0.4365\n",
      "Epoch 161/500\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.3935 - mean_squared_error: 0.3935 - val_loss: 0.4367 - val_mean_squared_error: 0.4367\n",
      "Epoch 162/500\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3933 - mean_squared_error: 0.3933 - val_loss: 0.4364 - val_mean_squared_error: 0.4364\n",
      "Epoch 163/500\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3930 - mean_squared_error: 0.3930 - val_loss: 0.4361 - val_mean_squared_error: 0.4361\n",
      "Epoch 164/500\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.3927 - mean_squared_error: 0.3927 - val_loss: 0.4355 - val_mean_squared_error: 0.4355\n",
      "Epoch 165/500\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3924 - mean_squared_error: 0.3924 - val_loss: 0.4345 - val_mean_squared_error: 0.4345\n",
      "Epoch 166/500\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3921 - mean_squared_error: 0.3921 - val_loss: 0.4345 - val_mean_squared_error: 0.4345\n",
      "Epoch 167/500\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.3920 - mean_squared_error: 0.3920 - val_loss: 0.4345 - val_mean_squared_error: 0.4345\n",
      "Epoch 168/500\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3917 - mean_squared_error: 0.3917 - val_loss: 0.4338 - val_mean_squared_error: 0.4338\n",
      "Epoch 169/500\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3916 - mean_squared_error: 0.3916 - val_loss: 0.4338 - val_mean_squared_error: 0.4338\n",
      "Epoch 170/500\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 0.3912 - mean_squared_error: 0.3912 - val_loss: 0.4333 - val_mean_squared_error: 0.4333\n",
      "Epoch 171/500\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.3912 - mean_squared_error: 0.3912 - val_loss: 0.4327 - val_mean_squared_error: 0.4327\n",
      "Epoch 172/500\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3907 - mean_squared_error: 0.3907 - val_loss: 0.4330 - val_mean_squared_error: 0.4330\n",
      "Epoch 173/500\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.3905 - mean_squared_error: 0.3905 - val_loss: 0.4323 - val_mean_squared_error: 0.4323\n",
      "Epoch 174/500\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3903 - mean_squared_error: 0.3903 - val_loss: 0.4331 - val_mean_squared_error: 0.4331\n",
      "Epoch 175/500\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3904 - mean_squared_error: 0.3904 - val_loss: 0.4317 - val_mean_squared_error: 0.4317\n",
      "Epoch 176/500\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3900 - mean_squared_error: 0.3900 - val_loss: 0.4325 - val_mean_squared_error: 0.4325\n",
      "Epoch 177/500\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.3897 - mean_squared_error: 0.3897 - val_loss: 0.4313 - val_mean_squared_error: 0.4313\n",
      "Epoch 178/500\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.3894 - mean_squared_error: 0.3894 - val_loss: 0.4313 - val_mean_squared_error: 0.4313\n",
      "Epoch 179/500\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3892 - mean_squared_error: 0.3892 - val_loss: 0.4308 - val_mean_squared_error: 0.4308\n",
      "Epoch 180/500\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3894 - mean_squared_error: 0.3894 - val_loss: 0.4312 - val_mean_squared_error: 0.4312\n",
      "Epoch 181/500\n",
      "800/800 [==============================] - 0s 213us/sample - loss: 0.3896 - mean_squared_error: 0.3896 - val_loss: 0.4303 - val_mean_squared_error: 0.4303\n",
      "Epoch 182/500\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.3892 - mean_squared_error: 0.3892 - val_loss: 0.4312 - val_mean_squared_error: 0.4312\n",
      "Epoch 183/500\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.3888 - mean_squared_error: 0.3888 - val_loss: 0.4296 - val_mean_squared_error: 0.4296\n",
      "Epoch 184/500\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3886 - mean_squared_error: 0.3886 - val_loss: 0.4301 - val_mean_squared_error: 0.4301\n",
      "Epoch 185/500\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3887 - mean_squared_error: 0.3887 - val_loss: 0.4295 - val_mean_squared_error: 0.4295\n",
      "Epoch 186/500\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.3882 - mean_squared_error: 0.3882 - val_loss: 0.4299 - val_mean_squared_error: 0.4299\n",
      "Epoch 187/500\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.3881 - mean_squared_error: 0.3881 - val_loss: 0.4293 - val_mean_squared_error: 0.4293\n",
      "Epoch 188/500\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3878 - mean_squared_error: 0.3878 - val_loss: 0.4291 - val_mean_squared_error: 0.4291\n",
      "Epoch 189/500\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3877 - mean_squared_error: 0.3877 - val_loss: 0.4288 - val_mean_squared_error: 0.4288\n",
      "Epoch 190/500\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3875 - mean_squared_error: 0.3875 - val_loss: 0.4289 - val_mean_squared_error: 0.4289\n",
      "Epoch 191/500\n",
      "800/800 [==============================] - 0s 43us/sample - loss: 0.3880 - mean_squared_error: 0.3880 - val_loss: 0.4283 - val_mean_squared_error: 0.4283\n",
      "Epoch 192/500\n",
      "800/800 [==============================] - 0s 44us/sample - loss: 0.3877 - mean_squared_error: 0.3877 - val_loss: 0.4277 - val_mean_squared_error: 0.4277\n",
      "Epoch 193/500\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3870 - mean_squared_error: 0.3870 - val_loss: 0.4284 - val_mean_squared_error: 0.4284\n",
      "Epoch 194/500\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.3871 - mean_squared_error: 0.3871 - val_loss: 0.4274 - val_mean_squared_error: 0.4274\n",
      "Epoch 195/500\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.3869 - mean_squared_error: 0.3869 - val_loss: 0.4275 - val_mean_squared_error: 0.4275\n",
      "Epoch 196/500\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3872 - mean_squared_error: 0.3872 - val_loss: 0.4281 - val_mean_squared_error: 0.4281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/500\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.3868 - mean_squared_error: 0.3868 - val_loss: 0.4275 - val_mean_squared_error: 0.4275\n",
      "Epoch 198/500\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 0.3869 - mean_squared_error: 0.3869 - val_loss: 0.4268 - val_mean_squared_error: 0.4268\n",
      "Epoch 199/500\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.3865 - mean_squared_error: 0.3865 - val_loss: 0.4273 - val_mean_squared_error: 0.4273\n",
      "Epoch 200/500\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3868 - mean_squared_error: 0.3868 - val_loss: 0.4270 - val_mean_squared_error: 0.4270\n",
      "Epoch 201/500\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3864 - mean_squared_error: 0.3864 - val_loss: 0.4272 - val_mean_squared_error: 0.4272\n",
      "Epoch 202/500\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.3862 - mean_squared_error: 0.3862 - val_loss: 0.4262 - val_mean_squared_error: 0.4262\n",
      "Epoch 203/500\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3861 - mean_squared_error: 0.3861 - val_loss: 0.4266 - val_mean_squared_error: 0.4266\n",
      "Epoch 204/500\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.3858 - mean_squared_error: 0.3858 - val_loss: 0.4261 - val_mean_squared_error: 0.4261\n",
      "Epoch 205/500\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.3857 - mean_squared_error: 0.3857 - val_loss: 0.4260 - val_mean_squared_error: 0.4260\n",
      "Epoch 206/500\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3856 - mean_squared_error: 0.3856 - val_loss: 0.4262 - val_mean_squared_error: 0.4262\n",
      "Epoch 207/500\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3857 - mean_squared_error: 0.3857 - val_loss: 0.4254 - val_mean_squared_error: 0.4254\n",
      "Epoch 208/500\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3855 - mean_squared_error: 0.3855 - val_loss: 0.4256 - val_mean_squared_error: 0.4256\n",
      "Epoch 209/500\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.3855 - mean_squared_error: 0.3855 - val_loss: 0.4256 - val_mean_squared_error: 0.4256\n",
      "Epoch 210/500\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3853 - mean_squared_error: 0.3853 - val_loss: 0.4252 - val_mean_squared_error: 0.4252\n",
      "Epoch 211/500\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3857 - mean_squared_error: 0.3857 - val_loss: 0.4257 - val_mean_squared_error: 0.4257\n",
      "Epoch 212/500\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.3855 - mean_squared_error: 0.3855 - val_loss: 0.4250 - val_mean_squared_error: 0.4250\n",
      "Epoch 213/500\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.3851 - mean_squared_error: 0.3851 - val_loss: 0.4251 - val_mean_squared_error: 0.4251\n",
      "Epoch 214/500\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.3854 - mean_squared_error: 0.3854 - val_loss: 0.4252 - val_mean_squared_error: 0.4252\n",
      "Epoch 215/500\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.3848 - mean_squared_error: 0.3848 - val_loss: 0.4249 - val_mean_squared_error: 0.4249\n",
      "Epoch 216/500\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.3852 - mean_squared_error: 0.3852 - val_loss: 0.4251 - val_mean_squared_error: 0.4251\n",
      "Epoch 217/500\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 0.3850 - mean_squared_error: 0.3850 - val_loss: 0.4246 - val_mean_squared_error: 0.4246\n",
      "Epoch 218/500\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.3847 - mean_squared_error: 0.3847 - val_loss: 0.4243 - val_mean_squared_error: 0.4243\n",
      "Epoch 219/500\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.3845 - mean_squared_error: 0.3845 - val_loss: 0.4241 - val_mean_squared_error: 0.4241\n",
      "Epoch 220/500\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.3845 - mean_squared_error: 0.3845 - val_loss: 0.4247 - val_mean_squared_error: 0.4247\n",
      "Epoch 221/500\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 0.3846 - mean_squared_error: 0.3846 - val_loss: 0.4239 - val_mean_squared_error: 0.4239\n",
      "Epoch 222/500\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.3847 - mean_squared_error: 0.3847 - val_loss: 0.4247 - val_mean_squared_error: 0.4247\n",
      "Epoch 223/500\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.3847 - mean_squared_error: 0.3847 - val_loss: 0.4243 - val_mean_squared_error: 0.4243\n",
      "Epoch 224/500\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 0.3844 - mean_squared_error: 0.3844 - val_loss: 0.4237 - val_mean_squared_error: 0.4237\n",
      "Epoch 225/500\n",
      "800/800 [==============================] - 0s 179us/sample - loss: 0.3844 - mean_squared_error: 0.3844 - val_loss: 0.4244 - val_mean_squared_error: 0.4244\n",
      "Epoch 226/500\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 0.3845 - mean_squared_error: 0.3845 - val_loss: 0.4237 - val_mean_squared_error: 0.4237\n",
      "Epoch 227/500\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 0.3849 - mean_squared_error: 0.3849 - val_loss: 0.4235 - val_mean_squared_error: 0.4235\n",
      "Epoch 228/500\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.3845 - mean_squared_error: 0.3845 - val_loss: 0.4236 - val_mean_squared_error: 0.4236\n",
      "Epoch 229/500\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3839 - mean_squared_error: 0.3839 - val_loss: 0.4235 - val_mean_squared_error: 0.4235\n",
      "Epoch 230/500\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.3839 - mean_squared_error: 0.3839 - val_loss: 0.4232 - val_mean_squared_error: 0.4232\n",
      "Epoch 231/500\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3839 - mean_squared_error: 0.3839 - val_loss: 0.4235 - val_mean_squared_error: 0.4235\n",
      "Epoch 232/500\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3840 - mean_squared_error: 0.3840 - val_loss: 0.4236 - val_mean_squared_error: 0.4236\n",
      "Epoch 233/500\n",
      "800/800 [==============================] - 0s 297us/sample - loss: 0.3839 - mean_squared_error: 0.3839 - val_loss: 0.4231 - val_mean_squared_error: 0.4231\n",
      "Epoch 234/500\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 0.3838 - mean_squared_error: 0.3838 - val_loss: 0.4235 - val_mean_squared_error: 0.4235\n",
      "Epoch 235/500\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 0.3835 - mean_squared_error: 0.3835 - val_loss: 0.4232 - val_mean_squared_error: 0.4232\n",
      "Epoch 236/500\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 0.3838 - mean_squared_error: 0.3838 - val_loss: 0.4225 - val_mean_squared_error: 0.4225\n",
      "Epoch 237/500\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 0.3838 - mean_squared_error: 0.3838 - val_loss: 0.4234 - val_mean_squared_error: 0.4234\n",
      "Epoch 238/500\n",
      "800/800 [==============================] - 0s 300us/sample - loss: 0.3838 - mean_squared_error: 0.3838 - val_loss: 0.4234 - val_mean_squared_error: 0.4234\n",
      "Epoch 239/500\n",
      "800/800 [==============================] - 0s 405us/sample - loss: 0.3839 - mean_squared_error: 0.3839 - val_loss: 0.4218 - val_mean_squared_error: 0.4218\n",
      "Epoch 240/500\n",
      "800/800 [==============================] - 0s 191us/sample - loss: 0.3838 - mean_squared_error: 0.3838 - val_loss: 0.4229 - val_mean_squared_error: 0.4229\n",
      "Epoch 241/500\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 0.3833 - mean_squared_error: 0.3833 - val_loss: 0.4222 - val_mean_squared_error: 0.4222\n",
      "Epoch 242/500\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 0.3832 - mean_squared_error: 0.3832 - val_loss: 0.4226 - val_mean_squared_error: 0.4226\n",
      "Epoch 243/500\n",
      "800/800 [==============================] - 0s 227us/sample - loss: 0.3834 - mean_squared_error: 0.3834 - val_loss: 0.4224 - val_mean_squared_error: 0.4224\n",
      "Epoch 244/500\n",
      "800/800 [==============================] - 0s 367us/sample - loss: 0.3837 - mean_squared_error: 0.3837 - val_loss: 0.4220 - val_mean_squared_error: 0.4220\n",
      "Epoch 245/500\n",
      "800/800 [==============================] - 0s 281us/sample - loss: 0.3834 - mean_squared_error: 0.3834 - val_loss: 0.4222 - val_mean_squared_error: 0.4222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246/500\n",
      "800/800 [==============================] - 0s 182us/sample - loss: 0.3834 - mean_squared_error: 0.3834 - val_loss: 0.4226 - val_mean_squared_error: 0.4226\n",
      "Epoch 247/500\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.3832 - mean_squared_error: 0.3832 - val_loss: 0.4217 - val_mean_squared_error: 0.4217\n",
      "Epoch 248/500\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.3830 - mean_squared_error: 0.3830 - val_loss: 0.4220 - val_mean_squared_error: 0.4220\n",
      "Epoch 249/500\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.3830 - mean_squared_error: 0.3830 - val_loss: 0.4225 - val_mean_squared_error: 0.4225\n",
      "Epoch 250/500\n",
      "800/800 [==============================] - 0s 174us/sample - loss: 0.3829 - mean_squared_error: 0.3829 - val_loss: 0.4215 - val_mean_squared_error: 0.4215\n",
      "Epoch 251/500\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 0.3829 - mean_squared_error: 0.3829 - val_loss: 0.4223 - val_mean_squared_error: 0.4223\n",
      "Epoch 252/500\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.3827 - mean_squared_error: 0.3827 - val_loss: 0.4220 - val_mean_squared_error: 0.4220\n",
      "Epoch 253/500\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.3829 - mean_squared_error: 0.3829 - val_loss: 0.4214 - val_mean_squared_error: 0.4214\n",
      "Epoch 254/500\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.3831 - mean_squared_error: 0.3831 - val_loss: 0.4221 - val_mean_squared_error: 0.4221\n",
      "Epoch 255/500\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.3832 - mean_squared_error: 0.3832 - val_loss: 0.4219 - val_mean_squared_error: 0.4219\n",
      "Epoch 256/500\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.3828 - mean_squared_error: 0.3828 - val_loss: 0.4219 - val_mean_squared_error: 0.4219\n",
      "Epoch 257/500\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.3827 - mean_squared_error: 0.3827 - val_loss: 0.4209 - val_mean_squared_error: 0.4209\n",
      "Epoch 258/500\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 0.3824 - mean_squared_error: 0.3824 - val_loss: 0.4211 - val_mean_squared_error: 0.4211\n",
      "Epoch 259/500\n",
      "800/800 [==============================] - 0s 82us/sample - loss: 0.3825 - mean_squared_error: 0.3825 - val_loss: 0.4218 - val_mean_squared_error: 0.4218\n",
      "Epoch 260/500\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.3831 - mean_squared_error: 0.3831 - val_loss: 0.4210 - val_mean_squared_error: 0.4210\n",
      "Epoch 261/500\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 0.3828 - mean_squared_error: 0.3828 - val_loss: 0.4219 - val_mean_squared_error: 0.4219\n",
      "Epoch 262/500\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 0.3823 - mean_squared_error: 0.3823 - val_loss: 0.4209 - val_mean_squared_error: 0.4209\n",
      "Epoch 263/500\n",
      "800/800 [==============================] - 0s 222us/sample - loss: 0.3824 - mean_squared_error: 0.3824 - val_loss: 0.4216 - val_mean_squared_error: 0.4216\n",
      "Epoch 264/500\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 0.3832 - mean_squared_error: 0.3832 - val_loss: 0.4218 - val_mean_squared_error: 0.4218\n",
      "Epoch 265/500\n",
      "800/800 [==============================] - 0s 172us/sample - loss: 0.3825 - mean_squared_error: 0.3825 - val_loss: 0.4213 - val_mean_squared_error: 0.4213\n",
      "Epoch 266/500\n",
      "800/800 [==============================] - 0s 223us/sample - loss: 0.3827 - mean_squared_error: 0.3827 - val_loss: 0.4208 - val_mean_squared_error: 0.4208\n",
      "Epoch 267/500\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.3827 - mean_squared_error: 0.3827 - val_loss: 0.4208 - val_mean_squared_error: 0.4208\n",
      "Epoch 268/500\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3703 - mean_squared_error: 0.37 - 0s 146us/sample - loss: 0.3823 - mean_squared_error: 0.3823 - val_loss: 0.4215 - val_mean_squared_error: 0.4215\n",
      "Epoch 269/500\n",
      "800/800 [==============================] - 0s 163us/sample - loss: 0.3825 - mean_squared_error: 0.3825 - val_loss: 0.4206 - val_mean_squared_error: 0.4206\n",
      "Epoch 270/500\n",
      "800/800 [==============================] - 0s 167us/sample - loss: 0.3825 - mean_squared_error: 0.3825 - val_loss: 0.4207 - val_mean_squared_error: 0.4207\n",
      "Epoch 271/500\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 0.3826 - mean_squared_error: 0.3826 - val_loss: 0.4205 - val_mean_squared_error: 0.4205\n",
      "Epoch 272/500\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 0.3823 - mean_squared_error: 0.3823 - val_loss: 0.4212 - val_mean_squared_error: 0.4212\n",
      "Epoch 273/500\n",
      "800/800 [==============================] - 0s 170us/sample - loss: 0.3821 - mean_squared_error: 0.3821 - val_loss: 0.4206 - val_mean_squared_error: 0.4206\n",
      "Epoch 274/500\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 0.3823 - mean_squared_error: 0.3823 - val_loss: 0.4210 - val_mean_squared_error: 0.4210\n",
      "Epoch 275/500\n",
      "800/800 [==============================] - 0s 200us/sample - loss: 0.3824 - mean_squared_error: 0.3824 - val_loss: 0.4207 - val_mean_squared_error: 0.4207\n",
      "Epoch 276/500\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.3829 - mean_squared_error: 0.3829 - val_loss: 0.4209 - val_mean_squared_error: 0.4209\n",
      "Epoch 277/500\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.3823 - mean_squared_error: 0.3823 - val_loss: 0.4211 - val_mean_squared_error: 0.4211\n",
      "Epoch 278/500\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.3823 - mean_squared_error: 0.3823 - val_loss: 0.4201 - val_mean_squared_error: 0.4201\n",
      "Epoch 279/500\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3822 - mean_squared_error: 0.3822 - val_loss: 0.4200 - val_mean_squared_error: 0.4200\n",
      "Epoch 280/500\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3823 - mean_squared_error: 0.3823 - val_loss: 0.4204 - val_mean_squared_error: 0.4204\n",
      "Epoch 281/500\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.3824 - mean_squared_error: 0.3824 - val_loss: 0.4209 - val_mean_squared_error: 0.4209\n",
      "Epoch 282/500\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.3820 - mean_squared_error: 0.3820 - val_loss: 0.4202 - val_mean_squared_error: 0.4202\n",
      "Epoch 283/500\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.3819 - mean_squared_error: 0.3819 - val_loss: 0.4204 - val_mean_squared_error: 0.4204\n",
      "Epoch 284/500\n",
      "800/800 [==============================] - 0s 165us/sample - loss: 0.3820 - mean_squared_error: 0.3820 - val_loss: 0.4205 - val_mean_squared_error: 0.4205\n",
      "Epoch 285/500\n",
      "800/800 [==============================] - 0s 218us/sample - loss: 0.3819 - mean_squared_error: 0.3819 - val_loss: 0.4206 - val_mean_squared_error: 0.4206\n",
      "Epoch 286/500\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.3831 - mean_squared_error: 0.38 - 0s 249us/sample - loss: 0.3824 - mean_squared_error: 0.3824 - val_loss: 0.4203 - val_mean_squared_error: 0.4203\n",
      "Epoch 287/500\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.3821 - mean_squared_error: 0.3821 - val_loss: 0.4209 - val_mean_squared_error: 0.4209\n",
      "Epoch 288/500\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.3819 - mean_squared_error: 0.3819 - val_loss: 0.4204 - val_mean_squared_error: 0.4204\n",
      "Epoch 289/500\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 0.3819 - mean_squared_error: 0.3819 - val_loss: 0.4199 - val_mean_squared_error: 0.4199\n",
      "Epoch 290/500\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.3819 - mean_squared_error: 0.3819 - val_loss: 0.4196 - val_mean_squared_error: 0.4196\n",
      "Epoch 291/500\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.3819 - mean_squared_error: 0.3819 - val_loss: 0.4198 - val_mean_squared_error: 0.4198\n",
      "Epoch 292/500\n",
      "800/800 [==============================] - 0s 181us/sample - loss: 0.3820 - mean_squared_error: 0.3820 - val_loss: 0.4201 - val_mean_squared_error: 0.4201\n",
      "Epoch 293/500\n",
      "800/800 [==============================] - 0s 158us/sample - loss: 0.3818 - mean_squared_error: 0.3818 - val_loss: 0.4204 - val_mean_squared_error: 0.4204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294/500\n",
      "800/800 [==============================] - 0s 178us/sample - loss: 0.3818 - mean_squared_error: 0.3818 - val_loss: 0.4200 - val_mean_squared_error: 0.4200\n",
      "Epoch 295/500\n",
      "800/800 [==============================] - 0s 189us/sample - loss: 0.3817 - mean_squared_error: 0.3817 - val_loss: 0.4196 - val_mean_squared_error: 0.4196\n",
      "Epoch 296/500\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 0.3819 - mean_squared_error: 0.3819 - val_loss: 0.4199 - val_mean_squared_error: 0.4199\n",
      "Epoch 297/500\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 0.3818 - mean_squared_error: 0.3818 - val_loss: 0.4202 - val_mean_squared_error: 0.4202\n",
      "Epoch 298/500\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.3820 - mean_squared_error: 0.3820 - val_loss: 0.4206 - val_mean_squared_error: 0.4206\n",
      "Epoch 299/500\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.3816 - mean_squared_error: 0.3816 - val_loss: 0.4198 - val_mean_squared_error: 0.4198\n",
      "Epoch 300/500\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 0.3814 - mean_squared_error: 0.3814 - val_loss: 0.4198 - val_mean_squared_error: 0.4198\n",
      "Epoch 301/500\n",
      "800/800 [==============================] - 0s 232us/sample - loss: 0.3817 - mean_squared_error: 0.3817 - val_loss: 0.4196 - val_mean_squared_error: 0.4196\n",
      "Epoch 302/500\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.3813 - mean_squared_error: 0.3813 - val_loss: 0.4200 - val_mean_squared_error: 0.4200\n",
      "Epoch 303/500\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.3814 - mean_squared_error: 0.3814 - val_loss: 0.4199 - val_mean_squared_error: 0.4199\n",
      "Epoch 304/500\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.3816 - mean_squared_error: 0.3816 - val_loss: 0.4200 - val_mean_squared_error: 0.4200\n",
      "Epoch 305/500\n",
      "800/800 [==============================] - 0s 198us/sample - loss: 0.3814 - mean_squared_error: 0.3814 - val_loss: 0.4192 - val_mean_squared_error: 0.4192\n",
      "Epoch 306/500\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.3817 - mean_squared_error: 0.3817 - val_loss: 0.4191 - val_mean_squared_error: 0.4191\n",
      "Epoch 307/500\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.3818 - mean_squared_error: 0.3818 - val_loss: 0.4201 - val_mean_squared_error: 0.4201\n",
      "Epoch 308/500\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.3816 - mean_squared_error: 0.3816 - val_loss: 0.4196 - val_mean_squared_error: 0.4196\n",
      "Epoch 309/500\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 0.3816 - mean_squared_error: 0.3816 - val_loss: 0.4200 - val_mean_squared_error: 0.4200\n",
      "Epoch 310/500\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.3815 - mean_squared_error: 0.3815 - val_loss: 0.4196 - val_mean_squared_error: 0.4196\n",
      "Epoch 311/500\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 0.3818 - mean_squared_error: 0.3818 - val_loss: 0.4189 - val_mean_squared_error: 0.4189\n",
      "Epoch 312/500\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.3814 - mean_squared_error: 0.3814 - val_loss: 0.4190 - val_mean_squared_error: 0.4190\n",
      "Epoch 313/500\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.3812 - mean_squared_error: 0.3812 - val_loss: 0.4193 - val_mean_squared_error: 0.4193\n",
      "Epoch 314/500\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.3816 - mean_squared_error: 0.3816 - val_loss: 0.4199 - val_mean_squared_error: 0.4199\n",
      "Epoch 315/500\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.3811 - mean_squared_error: 0.3811 - val_loss: 0.4189 - val_mean_squared_error: 0.4189\n",
      "Epoch 316/500\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.3812 - mean_squared_error: 0.3812 - val_loss: 0.4196 - val_mean_squared_error: 0.4196\n",
      "Epoch 317/500\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.3815 - mean_squared_error: 0.3815 - val_loss: 0.4191 - val_mean_squared_error: 0.4191\n",
      "Epoch 318/500\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.3815 - mean_squared_error: 0.3815 - val_loss: 0.4200 - val_mean_squared_error: 0.4200\n",
      "Epoch 319/500\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.3813 - mean_squared_error: 0.3813 - val_loss: 0.4191 - val_mean_squared_error: 0.4191\n",
      "Epoch 320/500\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 0.3809 - mean_squared_error: 0.3809 - val_loss: 0.4194 - val_mean_squared_error: 0.4194\n",
      "Epoch 321/500\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 0.3813 - mean_squared_error: 0.3813 - val_loss: 0.4190 - val_mean_squared_error: 0.4190\n",
      "Epoch 322/500\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.3813 - mean_squared_error: 0.3813 - val_loss: 0.4188 - val_mean_squared_error: 0.4188\n",
      "Epoch 323/500\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.3813 - mean_squared_error: 0.3813 - val_loss: 0.4197 - val_mean_squared_error: 0.4197\n",
      "Epoch 324/500\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.3815 - mean_squared_error: 0.3815 - val_loss: 0.4187 - val_mean_squared_error: 0.4187\n",
      "Epoch 325/500\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.3810 - mean_squared_error: 0.3810 - val_loss: 0.4188 - val_mean_squared_error: 0.4188\n",
      "Epoch 326/500\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.3816 - mean_squared_error: 0.3816 - val_loss: 0.4192 - val_mean_squared_error: 0.4192\n",
      "Epoch 327/500\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.3814 - mean_squared_error: 0.3814 - val_loss: 0.4192 - val_mean_squared_error: 0.4192\n",
      "Epoch 328/500\n",
      "800/800 [==============================] - 0s 244us/sample - loss: 0.3810 - mean_squared_error: 0.3810 - val_loss: 0.4194 - val_mean_squared_error: 0.4194\n",
      "Epoch 329/500\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.3811 - mean_squared_error: 0.3811 - val_loss: 0.4186 - val_mean_squared_error: 0.4186\n",
      "Epoch 330/500\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.3815 - mean_squared_error: 0.3815 - val_loss: 0.4185 - val_mean_squared_error: 0.4185\n",
      "Epoch 331/500\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.3813 - mean_squared_error: 0.3813 - val_loss: 0.4188 - val_mean_squared_error: 0.4188\n",
      "Epoch 332/500\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 0.3814 - mean_squared_error: 0.3814 - val_loss: 0.4182 - val_mean_squared_error: 0.4182\n",
      "Epoch 333/500\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.3809 - mean_squared_error: 0.3809 - val_loss: 0.4190 - val_mean_squared_error: 0.4190\n",
      "Epoch 334/500\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.3808 - mean_squared_error: 0.3808 - val_loss: 0.4188 - val_mean_squared_error: 0.4188\n",
      "Epoch 335/500\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.3809 - mean_squared_error: 0.3809 - val_loss: 0.4192 - val_mean_squared_error: 0.4192\n",
      "Epoch 336/500\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.3810 - mean_squared_error: 0.3810 - val_loss: 0.4183 - val_mean_squared_error: 0.4183\n",
      "Epoch 337/500\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.3809 - mean_squared_error: 0.3809 - val_loss: 0.4192 - val_mean_squared_error: 0.4192\n",
      "Epoch 338/500\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.3808 - mean_squared_error: 0.3808 - val_loss: 0.4194 - val_mean_squared_error: 0.4194\n",
      "Epoch 339/500\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 0.3810 - mean_squared_error: 0.3810 - val_loss: 0.4191 - val_mean_squared_error: 0.4191\n",
      "Epoch 340/500\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.3812 - mean_squared_error: 0.3812 - val_loss: 0.4189 - val_mean_squared_error: 0.4189\n",
      "Epoch 341/500\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.3809 - mean_squared_error: 0.3809 - val_loss: 0.4190 - val_mean_squared_error: 0.4190\n",
      "Epoch 342/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 110us/sample - loss: 0.3807 - mean_squared_error: 0.3807 - val_loss: 0.4184 - val_mean_squared_error: 0.4184\n",
      "Epoch 343/500\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.3811 - mean_squared_error: 0.3811 - val_loss: 0.4187 - val_mean_squared_error: 0.4187\n",
      "Epoch 344/500\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.3807 - mean_squared_error: 0.3807 - val_loss: 0.4182 - val_mean_squared_error: 0.4182\n",
      "Epoch 345/500\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 0.3811 - mean_squared_error: 0.3811 - val_loss: 0.4191 - val_mean_squared_error: 0.4191\n",
      "Epoch 346/500\n",
      "800/800 [==============================] - 0s 208us/sample - loss: 0.3810 - mean_squared_error: 0.3810 - val_loss: 0.4185 - val_mean_squared_error: 0.4185\n",
      "Epoch 347/500\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 0.3807 - mean_squared_error: 0.3807 - val_loss: 0.4188 - val_mean_squared_error: 0.4188\n",
      "Epoch 348/500\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.3808 - mean_squared_error: 0.3808 - val_loss: 0.4187 - val_mean_squared_error: 0.4187\n",
      "Epoch 349/500\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 0.3807 - mean_squared_error: 0.3807 - val_loss: 0.4186 - val_mean_squared_error: 0.4186\n",
      "Epoch 350/500\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.3813 - mean_squared_error: 0.3813 - val_loss: 0.4175 - val_mean_squared_error: 0.4175\n",
      "Epoch 351/500\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.3812 - mean_squared_error: 0.3812 - val_loss: 0.4202 - val_mean_squared_error: 0.4202\n",
      "Epoch 352/500\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 0.3806 - mean_squared_error: 0.3806 - val_loss: 0.4182 - val_mean_squared_error: 0.4182\n",
      "Epoch 353/500\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.3806 - mean_squared_error: 0.3806 - val_loss: 0.4188 - val_mean_squared_error: 0.4188\n",
      "Epoch 354/500\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3808 - mean_squared_error: 0.3808 - val_loss: 0.4186 - val_mean_squared_error: 0.4186\n",
      "Epoch 355/500\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3812 - mean_squared_error: 0.3812 - val_loss: 0.4186 - val_mean_squared_error: 0.4186\n",
      "Epoch 356/500\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.3809 - mean_squared_error: 0.3809 - val_loss: 0.4184 - val_mean_squared_error: 0.4184\n",
      "Epoch 357/500\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.3812 - mean_squared_error: 0.3812 - val_loss: 0.4188 - val_mean_squared_error: 0.4188\n",
      "Epoch 358/500\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.3813 - mean_squared_error: 0.3813 - val_loss: 0.4172 - val_mean_squared_error: 0.4172\n",
      "Epoch 359/500\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.3809 - mean_squared_error: 0.3809 - val_loss: 0.4186 - val_mean_squared_error: 0.4186\n",
      "Epoch 360/500\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.3811 - mean_squared_error: 0.3811 - val_loss: 0.4178 - val_mean_squared_error: 0.4178\n",
      "Epoch 361/500\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 0.3810 - mean_squared_error: 0.3810 - val_loss: 0.4185 - val_mean_squared_error: 0.4185\n",
      "Epoch 362/500\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 0.3810 - mean_squared_error: 0.3810 - val_loss: 0.4177 - val_mean_squared_error: 0.4177\n",
      "Epoch 363/500\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 0.3807 - mean_squared_error: 0.3807 - val_loss: 0.4183 - val_mean_squared_error: 0.4183\n",
      "Epoch 364/500\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.3804 - mean_squared_error: 0.3804 - val_loss: 0.4186 - val_mean_squared_error: 0.4186\n",
      "Epoch 365/500\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.3808 - mean_squared_error: 0.3808 - val_loss: 0.4180 - val_mean_squared_error: 0.4180\n",
      "Epoch 366/500\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.3806 - mean_squared_error: 0.3806 - val_loss: 0.4193 - val_mean_squared_error: 0.4193\n",
      "Epoch 367/500\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.3808 - mean_squared_error: 0.3808 - val_loss: 0.4182 - val_mean_squared_error: 0.4182\n",
      "Epoch 368/500\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.3807 - mean_squared_error: 0.3807 - val_loss: 0.4179 - val_mean_squared_error: 0.4179\n",
      "Epoch 369/500\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.3811 - mean_squared_error: 0.3811 - val_loss: 0.4182 - val_mean_squared_error: 0.4182\n",
      "Epoch 370/500\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3813 - mean_squared_error: 0.3813 - val_loss: 0.4191 - val_mean_squared_error: 0.4191\n",
      "Epoch 371/500\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3807 - mean_squared_error: 0.3807 - val_loss: 0.4177 - val_mean_squared_error: 0.4177\n",
      "Epoch 372/500\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.3810 - mean_squared_error: 0.3810 - val_loss: 0.4186 - val_mean_squared_error: 0.4186\n",
      "Epoch 373/500\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.3806 - mean_squared_error: 0.3806 - val_loss: 0.4179 - val_mean_squared_error: 0.4179\n",
      "Epoch 374/500\n",
      "800/800 [==============================] - 0s 326us/sample - loss: 0.3811 - mean_squared_error: 0.3811 - val_loss: 0.4182 - val_mean_squared_error: 0.4182\n",
      "Epoch 375/500\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.3810 - mean_squared_error: 0.3810 - val_loss: 0.4176 - val_mean_squared_error: 0.4176\n",
      "Epoch 376/500\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.3806 - mean_squared_error: 0.3806 - val_loss: 0.4184 - val_mean_squared_error: 0.4184\n",
      "Epoch 377/500\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.3809 - mean_squared_error: 0.3809 - val_loss: 0.4183 - val_mean_squared_error: 0.4183\n",
      "Epoch 378/500\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.3810 - mean_squared_error: 0.3810 - val_loss: 0.4178 - val_mean_squared_error: 0.4178\n",
      "Epoch 379/500\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 0.3809 - mean_squared_error: 0.3809 - val_loss: 0.4184 - val_mean_squared_error: 0.4184\n",
      "Epoch 380/500\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.3804 - mean_squared_error: 0.3804 - val_loss: 0.4181 - val_mean_squared_error: 0.4181\n",
      "Epoch 381/500\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.3806 - mean_squared_error: 0.3806 - val_loss: 0.4174 - val_mean_squared_error: 0.4174\n",
      "Epoch 382/500\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 0.3806 - mean_squared_error: 0.3806 - val_loss: 0.4179 - val_mean_squared_error: 0.4179\n",
      "Epoch 383/500\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.3805 - mean_squared_error: 0.3805 - val_loss: 0.4175 - val_mean_squared_error: 0.4175\n",
      "Epoch 384/500\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.3805 - mean_squared_error: 0.3805 - val_loss: 0.4179 - val_mean_squared_error: 0.4179\n",
      "Epoch 385/500\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.3805 - mean_squared_error: 0.3805 - val_loss: 0.4185 - val_mean_squared_error: 0.4185\n",
      "Epoch 386/500\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.3806 - mean_squared_error: 0.3806 - val_loss: 0.4179 - val_mean_squared_error: 0.4179\n",
      "Epoch 387/500\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3803 - mean_squared_error: 0.3803 - val_loss: 0.4177 - val_mean_squared_error: 0.4177\n",
      "Epoch 388/500\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3804 - mean_squared_error: 0.3804 - val_loss: 0.4179 - val_mean_squared_error: 0.4179\n",
      "Epoch 389/500\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.3804 - mean_squared_error: 0.3804 - val_loss: 0.4179 - val_mean_squared_error: 0.4179\n",
      "Epoch 390/500\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.3803 - mean_squared_error: 0.3803 - val_loss: 0.4173 - val_mean_squared_error: 0.4173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/500\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.3804 - mean_squared_error: 0.3804 - val_loss: 0.4182 - val_mean_squared_error: 0.4182\n",
      "Epoch 392/500\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.3803 - mean_squared_error: 0.3803 - val_loss: 0.4172 - val_mean_squared_error: 0.4172\n",
      "Epoch 393/500\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.3808 - mean_squared_error: 0.3808 - val_loss: 0.4182 - val_mean_squared_error: 0.4182\n",
      "Epoch 394/500\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 0.3803 - mean_squared_error: 0.3803 - val_loss: 0.4174 - val_mean_squared_error: 0.4174\n",
      "Epoch 395/500\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 0.3809 - mean_squared_error: 0.3809 - val_loss: 0.4172 - val_mean_squared_error: 0.4172\n",
      "Epoch 396/500\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 0.3807 - mean_squared_error: 0.3807 - val_loss: 0.4179 - val_mean_squared_error: 0.4179\n",
      "Epoch 397/500\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.3808 - mean_squared_error: 0.3808 - val_loss: 0.4185 - val_mean_squared_error: 0.4185\n",
      "Epoch 398/500\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.3805 - mean_squared_error: 0.3805 - val_loss: 0.4169 - val_mean_squared_error: 0.4169\n",
      "Epoch 399/500\n",
      "800/800 [==============================] - 0s 231us/sample - loss: 0.3802 - mean_squared_error: 0.3802 - val_loss: 0.4181 - val_mean_squared_error: 0.4181\n",
      "Epoch 400/500\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.3803 - mean_squared_error: 0.3803 - val_loss: 0.4182 - val_mean_squared_error: 0.4182\n",
      "Epoch 401/500\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.3802 - mean_squared_error: 0.3802 - val_loss: 0.4176 - val_mean_squared_error: 0.4176\n",
      "Epoch 402/500\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.3803 - mean_squared_error: 0.3803 - val_loss: 0.4181 - val_mean_squared_error: 0.4181\n",
      "Epoch 403/500\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3802 - mean_squared_error: 0.3802 - val_loss: 0.4181 - val_mean_squared_error: 0.4181\n",
      "Epoch 404/500\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.3805 - mean_squared_error: 0.3805 - val_loss: 0.4181 - val_mean_squared_error: 0.4181\n",
      "Epoch 405/500\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.3809 - mean_squared_error: 0.3809 - val_loss: 0.4180 - val_mean_squared_error: 0.4180\n",
      "Epoch 406/500\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3805 - mean_squared_error: 0.3805 - val_loss: 0.4170 - val_mean_squared_error: 0.4170\n",
      "Epoch 407/500\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3805 - mean_squared_error: 0.3805 - val_loss: 0.4180 - val_mean_squared_error: 0.4180\n",
      "Epoch 408/500\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3804 - mean_squared_error: 0.3804 - val_loss: 0.4168 - val_mean_squared_error: 0.4168\n",
      "Epoch 409/500\n",
      "800/800 [==============================] - 0s 44us/sample - loss: 0.3805 - mean_squared_error: 0.3805 - val_loss: 0.4175 - val_mean_squared_error: 0.4175\n",
      "Epoch 410/500\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.3800 - mean_squared_error: 0.3800 - val_loss: 0.4178 - val_mean_squared_error: 0.4178\n",
      "Epoch 411/500\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.3805 - mean_squared_error: 0.3805 - val_loss: 0.4177 - val_mean_squared_error: 0.4177\n",
      "Epoch 412/500\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 0.3805 - mean_squared_error: 0.3805 - val_loss: 0.4183 - val_mean_squared_error: 0.4183\n",
      "Epoch 413/500\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.3806 - mean_squared_error: 0.3806 - val_loss: 0.4165 - val_mean_squared_error: 0.4165\n",
      "Epoch 414/500\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.3804 - mean_squared_error: 0.3804 - val_loss: 0.4178 - val_mean_squared_error: 0.4178\n",
      "Epoch 415/500\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3804 - mean_squared_error: 0.3804 - val_loss: 0.4172 - val_mean_squared_error: 0.4172\n",
      "Epoch 416/500\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3803 - mean_squared_error: 0.3803 - val_loss: 0.4174 - val_mean_squared_error: 0.4174\n",
      "Epoch 417/500\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.3803 - mean_squared_error: 0.3803 - val_loss: 0.4176 - val_mean_squared_error: 0.4176\n",
      "Epoch 418/500\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3802 - mean_squared_error: 0.3802 - val_loss: 0.4176 - val_mean_squared_error: 0.4176\n",
      "Epoch 419/500\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.3801 - mean_squared_error: 0.3801 - val_loss: 0.4177 - val_mean_squared_error: 0.4177\n",
      "Epoch 420/500\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3803 - mean_squared_error: 0.3803 - val_loss: 0.4174 - val_mean_squared_error: 0.4174\n",
      "Epoch 421/500\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3809 - mean_squared_error: 0.3809 - val_loss: 0.4170 - val_mean_squared_error: 0.4170\n",
      "Epoch 422/500\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3805 - mean_squared_error: 0.3805 - val_loss: 0.4175 - val_mean_squared_error: 0.4175\n",
      "Epoch 423/500\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3802 - mean_squared_error: 0.3802 - val_loss: 0.4170 - val_mean_squared_error: 0.4170\n",
      "Epoch 424/500\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.3803 - mean_squared_error: 0.3803 - val_loss: 0.4176 - val_mean_squared_error: 0.4176\n",
      "Epoch 425/500\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3802 - mean_squared_error: 0.3802 - val_loss: 0.4172 - val_mean_squared_error: 0.4172\n",
      "Epoch 426/500\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3801 - mean_squared_error: 0.3801 - val_loss: 0.4175 - val_mean_squared_error: 0.4175\n",
      "Epoch 427/500\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3804 - mean_squared_error: 0.3804 - val_loss: 0.4166 - val_mean_squared_error: 0.4166\n",
      "Epoch 428/500\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.3805 - mean_squared_error: 0.3805 - val_loss: 0.4180 - val_mean_squared_error: 0.4180\n",
      "Epoch 429/500\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3803 - mean_squared_error: 0.3803 - val_loss: 0.4173 - val_mean_squared_error: 0.4173\n",
      "Epoch 430/500\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.3802 - mean_squared_error: 0.3802 - val_loss: 0.4168 - val_mean_squared_error: 0.4168\n",
      "Epoch 431/500\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3807 - mean_squared_error: 0.3807 - val_loss: 0.4172 - val_mean_squared_error: 0.4172\n",
      "Epoch 432/500\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3801 - mean_squared_error: 0.3801 - val_loss: 0.4169 - val_mean_squared_error: 0.4169\n",
      "Epoch 433/500\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 0.3801 - mean_squared_error: 0.3801 - val_loss: 0.4175 - val_mean_squared_error: 0.4175\n",
      "Epoch 434/500\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.3801 - mean_squared_error: 0.3801 - val_loss: 0.4173 - val_mean_squared_error: 0.4173\n",
      "Epoch 435/500\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3802 - mean_squared_error: 0.3802 - val_loss: 0.4163 - val_mean_squared_error: 0.4163\n",
      "Epoch 436/500\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3802 - mean_squared_error: 0.3802 - val_loss: 0.4166 - val_mean_squared_error: 0.4166\n",
      "Epoch 437/500\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3806 - mean_squared_error: 0.3806 - val_loss: 0.4181 - val_mean_squared_error: 0.4181\n",
      "Epoch 438/500\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3804 - mean_squared_error: 0.3804 - val_loss: 0.4168 - val_mean_squared_error: 0.4168\n",
      "Epoch 439/500\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3801 - mean_squared_error: 0.3801 - val_loss: 0.4175 - val_mean_squared_error: 0.4175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440/500\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3800 - mean_squared_error: 0.3800 - val_loss: 0.4166 - val_mean_squared_error: 0.4166\n",
      "Epoch 441/500\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.3805 - mean_squared_error: 0.3805 - val_loss: 0.4174 - val_mean_squared_error: 0.4174\n",
      "Epoch 442/500\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.3804 - mean_squared_error: 0.3804 - val_loss: 0.4169 - val_mean_squared_error: 0.4169\n",
      "Epoch 443/500\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3803 - mean_squared_error: 0.3803 - val_loss: 0.4172 - val_mean_squared_error: 0.4172\n",
      "Epoch 444/500\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3802 - mean_squared_error: 0.3802 - val_loss: 0.4170 - val_mean_squared_error: 0.4170\n",
      "Epoch 445/500\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3801 - mean_squared_error: 0.3801 - val_loss: 0.4172 - val_mean_squared_error: 0.4172\n",
      "Epoch 446/500\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.3800 - mean_squared_error: 0.3800 - val_loss: 0.4171 - val_mean_squared_error: 0.4171\n",
      "Epoch 447/500\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.3800 - mean_squared_error: 0.3800 - val_loss: 0.4172 - val_mean_squared_error: 0.4172\n",
      "Epoch 448/500\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 0.3807 - mean_squared_error: 0.3807 - val_loss: 0.4172 - val_mean_squared_error: 0.4172\n",
      "Epoch 449/500\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3805 - mean_squared_error: 0.3805 - val_loss: 0.4171 - val_mean_squared_error: 0.4171\n",
      "Epoch 450/500\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3804 - mean_squared_error: 0.3804 - val_loss: 0.4172 - val_mean_squared_error: 0.4172\n",
      "Epoch 451/500\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 0.3803 - mean_squared_error: 0.3803 - val_loss: 0.4170 - val_mean_squared_error: 0.4170\n",
      "Epoch 452/500\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.3801 - mean_squared_error: 0.3801 - val_loss: 0.4164 - val_mean_squared_error: 0.4164\n",
      "Epoch 453/500\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.3800 - mean_squared_error: 0.3800 - val_loss: 0.4177 - val_mean_squared_error: 0.4177\n",
      "Epoch 454/500\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.3800 - mean_squared_error: 0.3800 - val_loss: 0.4166 - val_mean_squared_error: 0.4166\n",
      "Epoch 455/500\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.3801 - mean_squared_error: 0.3801 - val_loss: 0.4172 - val_mean_squared_error: 0.4172\n",
      "Epoch 456/500\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.3804 - mean_squared_error: 0.3804 - val_loss: 0.4182 - val_mean_squared_error: 0.4182\n",
      "Epoch 457/500\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.3799 - mean_squared_error: 0.3799 - val_loss: 0.4169 - val_mean_squared_error: 0.4169\n",
      "Epoch 458/500\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.3800 - mean_squared_error: 0.3800 - val_loss: 0.4174 - val_mean_squared_error: 0.4174\n",
      "Epoch 459/500\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.3800 - mean_squared_error: 0.3800 - val_loss: 0.4167 - val_mean_squared_error: 0.4167\n",
      "Epoch 460/500\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.3806 - mean_squared_error: 0.3806 - val_loss: 0.4174 - val_mean_squared_error: 0.4174\n",
      "Epoch 461/500\n",
      "800/800 [==============================] - 0s 164us/sample - loss: 0.3801 - mean_squared_error: 0.3801 - val_loss: 0.4171 - val_mean_squared_error: 0.4171\n",
      "Epoch 462/500\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 0.3803 - mean_squared_error: 0.3803 - val_loss: 0.4167 - val_mean_squared_error: 0.4167\n",
      "Epoch 463/500\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 0.3800 - mean_squared_error: 0.3800 - val_loss: 0.4162 - val_mean_squared_error: 0.4162\n",
      "Epoch 464/500\n",
      "800/800 [==============================] - 0s 309us/sample - loss: 0.3799 - mean_squared_error: 0.3799 - val_loss: 0.4174 - val_mean_squared_error: 0.4174\n",
      "Epoch 465/500\n",
      "800/800 [==============================] - 0s 172us/sample - loss: 0.3800 - mean_squared_error: 0.3800 - val_loss: 0.4174 - val_mean_squared_error: 0.4174\n",
      "Epoch 466/500\n",
      "800/800 [==============================] - 0s 242us/sample - loss: 0.3799 - mean_squared_error: 0.3799 - val_loss: 0.4165 - val_mean_squared_error: 0.4165\n",
      "Epoch 467/500\n",
      "800/800 [==============================] - 0s 335us/sample - loss: 0.3799 - mean_squared_error: 0.3799 - val_loss: 0.4169 - val_mean_squared_error: 0.4169\n",
      "Epoch 468/500\n",
      "800/800 [==============================] - 0s 453us/sample - loss: 0.3807 - mean_squared_error: 0.3807 - val_loss: 0.4169 - val_mean_squared_error: 0.4169\n",
      "Epoch 469/500\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 0.3801 - mean_squared_error: 0.3801 - val_loss: 0.4178 - val_mean_squared_error: 0.4178\n",
      "Epoch 470/500\n",
      "800/800 [==============================] - 1s 1ms/sample - loss: 0.3798 - mean_squared_error: 0.3798 - val_loss: 0.4161 - val_mean_squared_error: 0.4161\n",
      "Epoch 471/500\n",
      "800/800 [==============================] - 0s 405us/sample - loss: 0.3802 - mean_squared_error: 0.3802 - val_loss: 0.4175 - val_mean_squared_error: 0.4175\n",
      "Epoch 472/500\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 0.3799 - mean_squared_error: 0.3799 - val_loss: 0.4162 - val_mean_squared_error: 0.4162\n",
      "Epoch 473/500\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.3798 - mean_squared_error: 0.3798 - val_loss: 0.4177 - val_mean_squared_error: 0.4177\n",
      "Epoch 474/500\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 0.3799 - mean_squared_error: 0.3799 - val_loss: 0.4163 - val_mean_squared_error: 0.4163\n",
      "Epoch 475/500\n",
      "800/800 [==============================] - 0s 237us/sample - loss: 0.3800 - mean_squared_error: 0.3800 - val_loss: 0.4168 - val_mean_squared_error: 0.4168\n",
      "Epoch 476/500\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.3797 - mean_squared_error: 0.3797 - val_loss: 0.4174 - val_mean_squared_error: 0.4174\n",
      "Epoch 477/500\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3803 - mean_squared_error: 0.3803 - val_loss: 0.4159 - val_mean_squared_error: 0.4159\n",
      "Epoch 478/500\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.3798 - mean_squared_error: 0.3798 - val_loss: 0.4169 - val_mean_squared_error: 0.4169\n",
      "Epoch 479/500\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3796 - mean_squared_error: 0.3796 - val_loss: 0.4169 - val_mean_squared_error: 0.4169\n",
      "Epoch 480/500\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3797 - mean_squared_error: 0.3797 - val_loss: 0.4170 - val_mean_squared_error: 0.4170\n",
      "Epoch 481/500\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3797 - mean_squared_error: 0.3797 - val_loss: 0.4167 - val_mean_squared_error: 0.4167\n",
      "Epoch 482/500\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.3801 - mean_squared_error: 0.3801 - val_loss: 0.4162 - val_mean_squared_error: 0.4162\n",
      "Epoch 483/500\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 0.3799 - mean_squared_error: 0.3799 - val_loss: 0.4174 - val_mean_squared_error: 0.4174\n",
      "Epoch 484/500\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.3798 - mean_squared_error: 0.3798 - val_loss: 0.4170 - val_mean_squared_error: 0.4170\n",
      "Epoch 485/500\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.3801 - mean_squared_error: 0.3801 - val_loss: 0.4163 - val_mean_squared_error: 0.4163\n",
      "Epoch 486/500\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 0.3800 - mean_squared_error: 0.3800 - val_loss: 0.4174 - val_mean_squared_error: 0.4174\n",
      "Epoch 487/500\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.3801 - mean_squared_error: 0.3801 - val_loss: 0.4170 - val_mean_squared_error: 0.4170\n",
      "Epoch 488/500\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.3802 - mean_squared_error: 0.3802 - val_loss: 0.4171 - val_mean_squared_error: 0.4171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489/500\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.3801 - mean_squared_error: 0.3801 - val_loss: 0.4167 - val_mean_squared_error: 0.4167\n",
      "Epoch 490/500\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.3797 - mean_squared_error: 0.3797 - val_loss: 0.4170 - val_mean_squared_error: 0.4170\n",
      "Epoch 491/500\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.3803 - mean_squared_error: 0.3803 - val_loss: 0.4161 - val_mean_squared_error: 0.4161\n",
      "Epoch 492/500\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.3796 - mean_squared_error: 0.3796 - val_loss: 0.4166 - val_mean_squared_error: 0.4166\n",
      "Epoch 493/500\n",
      "800/800 [==============================] - 0s 44us/sample - loss: 0.3794 - mean_squared_error: 0.3794 - val_loss: 0.4167 - val_mean_squared_error: 0.4167\n",
      "Epoch 494/500\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.3796 - mean_squared_error: 0.3796 - val_loss: 0.4169 - val_mean_squared_error: 0.4169\n",
      "Epoch 495/500\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.3800 - mean_squared_error: 0.3800 - val_loss: 0.4166 - val_mean_squared_error: 0.4166\n",
      "Epoch 496/500\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.3796 - mean_squared_error: 0.3796 - val_loss: 0.4162 - val_mean_squared_error: 0.4162\n",
      "Epoch 497/500\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.3800 - mean_squared_error: 0.3800 - val_loss: 0.4164 - val_mean_squared_error: 0.4164\n",
      "Epoch 498/500\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.3797 - mean_squared_error: 0.3797 - val_loss: 0.4168 - val_mean_squared_error: 0.4168\n",
      "Epoch 499/500\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.3802 - mean_squared_error: 0.3802 - val_loss: 0.4168 - val_mean_squared_error: 0.4168\n",
      "Epoch 500/500\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 0.3797 - mean_squared_error: 0.3797 - val_loss: 0.4168 - val_mean_squared_error: 0.4168\n",
      "CPU times: user 33.4 s, sys: 1.57 s, total: 35 s\n",
      "Wall time: 41.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "baseline = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input([num_features]),\n",
    "    tf.keras.layers.Dense(6, activation=tf.keras.layers.LeakyReLU()),\n",
    "    tf.keras.layers.Dense(num_features),\n",
    "])\n",
    "\n",
    "baseline.compile(optimizer='adam',\n",
    "                 loss='mean_squared_error',\n",
    "                 metrics=['mean_squared_error'])\n",
    "\n",
    "baseline.fit(x=train_df[feature_cols], \n",
    "             y=train_df[feature_cols],  \n",
    "             epochs=500,\n",
    "             validation_data=(valid_df[feature_cols], valid_df[feature_cols])\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/sample - loss: 0.4105 - mean_squared_error: 0.4105\n",
      "7/7 [==============================] - 0s 127us/sample - loss: 1.4843 - mean_squared_error: 1.4843\n",
      "Average loss on the eval set:\t 0.4105\n",
      "Average loss on fraud set:\t 1.4843\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_eval = compute_reconstruction_loss(baseline, eval_df)\n",
    "baseline_fraud = compute_reconstruction_loss(baseline, fraud_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs = [128, 6]\n",
    "decoder_outputs = encoder_outputs[1::-1] if len(encoder_outputs) > 1 else []\n",
    "\n",
    "def build_dense_layer(layer_name, output_dimension):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(output_dimension, activation=None),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('elu')\n",
    "    ],\n",
    "    name=layer_name)\n",
    "\n",
    "encoder_layers = [build_dense_layer(f\"encoder_layer_{i}\", output_dim)\n",
    "                  for i, output_dim in enumerate(encoder_outputs)]\n",
    "\n",
    "encoder_layers.insert(0, tf.keras.layers.Input([num_features]))\n",
    "\n",
    "encoder_model = tf.keras.Sequential(encoder_layers, name=\"encoder\")\n",
    "\n",
    "\n",
    "\n",
    "decoder_layers = [build_dense_layer(f\"decoder_layer_{i}\", output_dim)\n",
    "                 for i, output_dim in enumerate(decoder_outputs)]\n",
    "\n",
    "encoder_output_shape = encoder_model.layers[-1].output.shape.as_list()[1:]\n",
    "\n",
    "decoder_layers.insert(0, tf.keras.layers.Input(encoder_output_shape))\n",
    "\n",
    "decoder_model = tf.keras.Sequential(decoder_layers, name=\"decoder\")\n",
    "\n",
    "output_layer = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(num_features)\n",
    "    ],\n",
    "    name=\"output_layer\")\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        encoder_model,\n",
    "        decoder_model,\n",
    "        output_layer\n",
    "    ],\n",
    "    name=\"autoencoder\")\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/700\n",
      "800/800 [==============================] - 1s 1ms/sample - loss: 1.9007 - mean_squared_error: 1.9007 - val_loss: 1.0097 - val_mean_squared_error: 1.0097\n",
      "Epoch 2/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 1.6899 - mean_squared_error: 1.6899 - val_loss: 0.9992 - val_mean_squared_error: 0.9992\n",
      "Epoch 3/700\n",
      "800/800 [==============================] - 0s 14us/sample - loss: 1.5106 - mean_squared_error: 1.5106 - val_loss: 0.9905 - val_mean_squared_error: 0.9905\n",
      "Epoch 4/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 1.3608 - mean_squared_error: 1.3608 - val_loss: 0.9835 - val_mean_squared_error: 0.9835\n",
      "Epoch 5/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 1.2380 - mean_squared_error: 1.2380 - val_loss: 0.9781 - val_mean_squared_error: 0.9781\n",
      "Epoch 6/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 1.1390 - mean_squared_error: 1.1390 - val_loss: 0.9740 - val_mean_squared_error: 0.9740\n",
      "Epoch 7/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 1.0603 - mean_squared_error: 1.0603 - val_loss: 0.9710 - val_mean_squared_error: 0.9710\n",
      "Epoch 8/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.9984 - mean_squared_error: 0.9984 - val_loss: 0.9689 - val_mean_squared_error: 0.9689\n",
      "Epoch 9/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.9501 - mean_squared_error: 0.9501 - val_loss: 0.9675 - val_mean_squared_error: 0.9675\n",
      "Epoch 10/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.9126 - mean_squared_error: 0.9126 - val_loss: 0.9664 - val_mean_squared_error: 0.9664\n",
      "Epoch 11/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.8834 - mean_squared_error: 0.8834 - val_loss: 0.9656 - val_mean_squared_error: 0.9656\n",
      "Epoch 12/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.8603 - mean_squared_error: 0.8603 - val_loss: 0.9649 - val_mean_squared_error: 0.9649\n",
      "Epoch 13/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.8415 - mean_squared_error: 0.8415 - val_loss: 0.9640 - val_mean_squared_error: 0.9640\n",
      "Epoch 14/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.8255 - mean_squared_error: 0.8255 - val_loss: 0.9629 - val_mean_squared_error: 0.9629\n",
      "Epoch 15/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.8112 - mean_squared_error: 0.8112 - val_loss: 0.9615 - val_mean_squared_error: 0.9615\n",
      "Epoch 16/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.7976 - mean_squared_error: 0.7976 - val_loss: 0.9597 - val_mean_squared_error: 0.9597\n",
      "Epoch 17/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.7842 - mean_squared_error: 0.7842 - val_loss: 0.9576 - val_mean_squared_error: 0.9576\n",
      "Epoch 18/700\n",
      "800/800 [==============================] - 0s 14us/sample - loss: 0.7710 - mean_squared_error: 0.7710 - val_loss: 0.9551 - val_mean_squared_error: 0.9551\n",
      "Epoch 19/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.7578 - mean_squared_error: 0.7578 - val_loss: 0.9524 - val_mean_squared_error: 0.9524\n",
      "Epoch 20/700\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 0.7450 - mean_squared_error: 0.7450 - val_loss: 0.9494 - val_mean_squared_error: 0.9494\n",
      "Epoch 21/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.7329 - mean_squared_error: 0.7329 - val_loss: 0.9463 - val_mean_squared_error: 0.9463\n",
      "Epoch 22/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.7217 - mean_squared_error: 0.7217 - val_loss: 0.9430 - val_mean_squared_error: 0.9430\n",
      "Epoch 23/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.7116 - mean_squared_error: 0.7116 - val_loss: 0.9398 - val_mean_squared_error: 0.9398\n",
      "Epoch 24/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.7027 - mean_squared_error: 0.7027 - val_loss: 0.9366 - val_mean_squared_error: 0.9366\n",
      "Epoch 25/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.6949 - mean_squared_error: 0.6949 - val_loss: 0.9335 - val_mean_squared_error: 0.9335\n",
      "Epoch 26/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.6881 - mean_squared_error: 0.6881 - val_loss: 0.9306 - val_mean_squared_error: 0.9306\n",
      "Epoch 27/700\n",
      "800/800 [==============================] - 0s 14us/sample - loss: 0.6819 - mean_squared_error: 0.6819 - val_loss: 0.9277 - val_mean_squared_error: 0.9277\n",
      "Epoch 28/700\n",
      "800/800 [==============================] - 0s 14us/sample - loss: 0.6763 - mean_squared_error: 0.6763 - val_loss: 0.9251 - val_mean_squared_error: 0.9251\n",
      "Epoch 29/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.6710 - mean_squared_error: 0.6710 - val_loss: 0.9226 - val_mean_squared_error: 0.9226\n",
      "Epoch 30/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.9203 - val_mean_squared_error: 0.9203\n",
      "Epoch 31/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.6608 - mean_squared_error: 0.6608 - val_loss: 0.9182 - val_mean_squared_error: 0.9182\n",
      "Epoch 32/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.6558 - mean_squared_error: 0.6558 - val_loss: 0.9163 - val_mean_squared_error: 0.9163\n",
      "Epoch 33/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.6508 - mean_squared_error: 0.6508 - val_loss: 0.9147 - val_mean_squared_error: 0.9147\n",
      "Epoch 34/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.6460 - mean_squared_error: 0.6460 - val_loss: 0.9132 - val_mean_squared_error: 0.9132\n",
      "Epoch 35/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.6412 - mean_squared_error: 0.6412 - val_loss: 0.9118 - val_mean_squared_error: 0.9118\n",
      "Epoch 36/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.6366 - mean_squared_error: 0.6366 - val_loss: 0.9106 - val_mean_squared_error: 0.9106\n",
      "Epoch 37/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.6321 - mean_squared_error: 0.6321 - val_loss: 0.9096 - val_mean_squared_error: 0.9096\n",
      "Epoch 38/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.6278 - mean_squared_error: 0.6278 - val_loss: 0.9086 - val_mean_squared_error: 0.9086\n",
      "Epoch 39/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.6236 - mean_squared_error: 0.6236 - val_loss: 0.9078 - val_mean_squared_error: 0.9078\n",
      "Epoch 40/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.6197 - mean_squared_error: 0.6197 - val_loss: 0.9069 - val_mean_squared_error: 0.9069\n",
      "Epoch 41/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.6159 - mean_squared_error: 0.6159 - val_loss: 0.9061 - val_mean_squared_error: 0.9061\n",
      "Epoch 42/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.6123 - mean_squared_error: 0.6123 - val_loss: 0.9053 - val_mean_squared_error: 0.9053\n",
      "Epoch 43/700\n",
      "800/800 [==============================] - 0s 27us/sample - loss: 0.6088 - mean_squared_error: 0.6088 - val_loss: 0.9045 - val_mean_squared_error: 0.9045\n",
      "Epoch 44/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.6054 - mean_squared_error: 0.6054 - val_loss: 0.9036 - val_mean_squared_error: 0.9036\n",
      "Epoch 45/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.6022 - mean_squared_error: 0.6022 - val_loss: 0.9026 - val_mean_squared_error: 0.9026\n",
      "Epoch 46/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.5990 - mean_squared_error: 0.5990 - val_loss: 0.9016 - val_mean_squared_error: 0.9016\n",
      "Epoch 47/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.5959 - mean_squared_error: 0.5959 - val_loss: 0.9006 - val_mean_squared_error: 0.9006\n",
      "Epoch 48/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5930 - mean_squared_error: 0.5930 - val_loss: 0.8995 - val_mean_squared_error: 0.8995\n",
      "Epoch 49/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5901 - mean_squared_error: 0.5901 - val_loss: 0.8982 - val_mean_squared_error: 0.8982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.5874 - mean_squared_error: 0.5874 - val_loss: 0.8970 - val_mean_squared_error: 0.8970\n",
      "Epoch 51/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.5847 - mean_squared_error: 0.5847 - val_loss: 0.8957 - val_mean_squared_error: 0.8957\n",
      "Epoch 52/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.5823 - mean_squared_error: 0.5823 - val_loss: 0.8943 - val_mean_squared_error: 0.8943\n",
      "Epoch 53/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.5800 - mean_squared_error: 0.5800 - val_loss: 0.8928 - val_mean_squared_error: 0.8928\n",
      "Epoch 54/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.5778 - mean_squared_error: 0.5778 - val_loss: 0.8914 - val_mean_squared_error: 0.8914\n",
      "Epoch 55/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5758 - mean_squared_error: 0.5758 - val_loss: 0.8899 - val_mean_squared_error: 0.8899\n",
      "Epoch 56/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.5739 - mean_squared_error: 0.5739 - val_loss: 0.8884 - val_mean_squared_error: 0.8884\n",
      "Epoch 57/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.5721 - mean_squared_error: 0.5721 - val_loss: 0.8868 - val_mean_squared_error: 0.8868\n",
      "Epoch 58/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.5704 - mean_squared_error: 0.5704 - val_loss: 0.8853 - val_mean_squared_error: 0.8853\n",
      "Epoch 59/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5688 - mean_squared_error: 0.5688 - val_loss: 0.8838 - val_mean_squared_error: 0.8838\n",
      "Epoch 60/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5673 - mean_squared_error: 0.5673 - val_loss: 0.8822 - val_mean_squared_error: 0.8822\n",
      "Epoch 61/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5659 - mean_squared_error: 0.5659 - val_loss: 0.8807 - val_mean_squared_error: 0.8807\n",
      "Epoch 62/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5645 - mean_squared_error: 0.5645 - val_loss: 0.8792 - val_mean_squared_error: 0.8792\n",
      "Epoch 63/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.5631 - mean_squared_error: 0.5631 - val_loss: 0.8777 - val_mean_squared_error: 0.8777\n",
      "Epoch 64/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.5618 - mean_squared_error: 0.5618 - val_loss: 0.8763 - val_mean_squared_error: 0.8763\n",
      "Epoch 65/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.5605 - mean_squared_error: 0.5605 - val_loss: 0.8749 - val_mean_squared_error: 0.8749\n",
      "Epoch 66/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.5593 - mean_squared_error: 0.5593 - val_loss: 0.8734 - val_mean_squared_error: 0.8734\n",
      "Epoch 67/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5581 - mean_squared_error: 0.5581 - val_loss: 0.8720 - val_mean_squared_error: 0.8720\n",
      "Epoch 68/700\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 0.5570 - mean_squared_error: 0.5570 - val_loss: 0.8706 - val_mean_squared_error: 0.8706\n",
      "Epoch 69/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5559 - mean_squared_error: 0.5559 - val_loss: 0.8693 - val_mean_squared_error: 0.8693\n",
      "Epoch 70/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5548 - mean_squared_error: 0.5548 - val_loss: 0.8679 - val_mean_squared_error: 0.8679\n",
      "Epoch 71/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5537 - mean_squared_error: 0.5537 - val_loss: 0.8665 - val_mean_squared_error: 0.8665\n",
      "Epoch 72/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.5527 - mean_squared_error: 0.5527 - val_loss: 0.8651 - val_mean_squared_error: 0.8651\n",
      "Epoch 73/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.5517 - mean_squared_error: 0.5517 - val_loss: 0.8637 - val_mean_squared_error: 0.8637\n",
      "Epoch 74/700\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 0.5508 - mean_squared_error: 0.5508 - val_loss: 0.8623 - val_mean_squared_error: 0.8623\n",
      "Epoch 75/700\n",
      "800/800 [==============================] - 0s 28us/sample - loss: 0.5498 - mean_squared_error: 0.5498 - val_loss: 0.8609 - val_mean_squared_error: 0.8609\n",
      "Epoch 76/700\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 0.5489 - mean_squared_error: 0.5489 - val_loss: 0.8595 - val_mean_squared_error: 0.8595\n",
      "Epoch 77/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.5480 - mean_squared_error: 0.5480 - val_loss: 0.8581 - val_mean_squared_error: 0.8581\n",
      "Epoch 78/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.5471 - mean_squared_error: 0.5471 - val_loss: 0.8567 - val_mean_squared_error: 0.8567\n",
      "Epoch 79/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.5462 - mean_squared_error: 0.5462 - val_loss: 0.8553 - val_mean_squared_error: 0.8553\n",
      "Epoch 80/700\n",
      "800/800 [==============================] - 0s 26us/sample - loss: 0.5454 - mean_squared_error: 0.5454 - val_loss: 0.8539 - val_mean_squared_error: 0.8539\n",
      "Epoch 81/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.5446 - mean_squared_error: 0.5446 - val_loss: 0.8525 - val_mean_squared_error: 0.8525\n",
      "Epoch 82/700\n",
      "800/800 [==============================] - 0s 26us/sample - loss: 0.5438 - mean_squared_error: 0.5438 - val_loss: 0.8511 - val_mean_squared_error: 0.8511\n",
      "Epoch 83/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.5430 - mean_squared_error: 0.5430 - val_loss: 0.8498 - val_mean_squared_error: 0.8498\n",
      "Epoch 84/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.5423 - mean_squared_error: 0.5423 - val_loss: 0.8485 - val_mean_squared_error: 0.8485\n",
      "Epoch 85/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.5415 - mean_squared_error: 0.5415 - val_loss: 0.8471 - val_mean_squared_error: 0.8471\n",
      "Epoch 86/700\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 0.5408 - mean_squared_error: 0.5408 - val_loss: 0.8458 - val_mean_squared_error: 0.8458\n",
      "Epoch 87/700\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.5401 - mean_squared_error: 0.5401 - val_loss: 0.8445 - val_mean_squared_error: 0.8445\n",
      "Epoch 88/700\n",
      "800/800 [==============================] - 0s 25us/sample - loss: 0.5394 - mean_squared_error: 0.5394 - val_loss: 0.8431 - val_mean_squared_error: 0.8431\n",
      "Epoch 89/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.5387 - mean_squared_error: 0.5387 - val_loss: 0.8418 - val_mean_squared_error: 0.8418\n",
      "Epoch 90/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.5380 - mean_squared_error: 0.5380 - val_loss: 0.8405 - val_mean_squared_error: 0.8405\n",
      "Epoch 91/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.5374 - mean_squared_error: 0.5374 - val_loss: 0.8391 - val_mean_squared_error: 0.8391\n",
      "Epoch 92/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.5367 - mean_squared_error: 0.5367 - val_loss: 0.8377 - val_mean_squared_error: 0.8377\n",
      "Epoch 93/700\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 0.5361 - mean_squared_error: 0.5361 - val_loss: 0.8364 - val_mean_squared_error: 0.8364\n",
      "Epoch 94/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.5354 - mean_squared_error: 0.5354 - val_loss: 0.8350 - val_mean_squared_error: 0.8350\n",
      "Epoch 95/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.5348 - mean_squared_error: 0.5348 - val_loss: 0.8337 - val_mean_squared_error: 0.8337\n",
      "Epoch 96/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5342 - mean_squared_error: 0.5342 - val_loss: 0.8323 - val_mean_squared_error: 0.8323\n",
      "Epoch 97/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.5336 - mean_squared_error: 0.5336 - val_loss: 0.8310 - val_mean_squared_error: 0.8310\n",
      "Epoch 98/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.5330 - mean_squared_error: 0.5330 - val_loss: 0.8296 - val_mean_squared_error: 0.8296\n",
      "Epoch 99/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 20us/sample - loss: 0.5324 - mean_squared_error: 0.5324 - val_loss: 0.8283 - val_mean_squared_error: 0.8283\n",
      "Epoch 100/700\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 0.5318 - mean_squared_error: 0.5318 - val_loss: 0.8270 - val_mean_squared_error: 0.8270\n",
      "Epoch 101/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.5312 - mean_squared_error: 0.5312 - val_loss: 0.8257 - val_mean_squared_error: 0.8257\n",
      "Epoch 102/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.5307 - mean_squared_error: 0.5307 - val_loss: 0.8244 - val_mean_squared_error: 0.8244\n",
      "Epoch 103/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.5301 - mean_squared_error: 0.5301 - val_loss: 0.8231 - val_mean_squared_error: 0.8231\n",
      "Epoch 104/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5295 - mean_squared_error: 0.5295 - val_loss: 0.8218 - val_mean_squared_error: 0.8218\n",
      "Epoch 105/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.5290 - mean_squared_error: 0.5290 - val_loss: 0.8205 - val_mean_squared_error: 0.8205\n",
      "Epoch 106/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.5284 - mean_squared_error: 0.5284 - val_loss: 0.8192 - val_mean_squared_error: 0.8192\n",
      "Epoch 107/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.5279 - mean_squared_error: 0.5279 - val_loss: 0.8180 - val_mean_squared_error: 0.8180\n",
      "Epoch 108/700\n",
      "800/800 [==============================] - 0s 26us/sample - loss: 0.5274 - mean_squared_error: 0.5274 - val_loss: 0.8167 - val_mean_squared_error: 0.8167\n",
      "Epoch 109/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.5268 - mean_squared_error: 0.5268 - val_loss: 0.8154 - val_mean_squared_error: 0.8154\n",
      "Epoch 110/700\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 0.5263 - mean_squared_error: 0.5263 - val_loss: 0.8141 - val_mean_squared_error: 0.8141\n",
      "Epoch 111/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.5258 - mean_squared_error: 0.5258 - val_loss: 0.8128 - val_mean_squared_error: 0.8128\n",
      "Epoch 112/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.5253 - mean_squared_error: 0.5253 - val_loss: 0.8116 - val_mean_squared_error: 0.8116\n",
      "Epoch 113/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5248 - mean_squared_error: 0.5248 - val_loss: 0.8103 - val_mean_squared_error: 0.8103\n",
      "Epoch 114/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.5243 - mean_squared_error: 0.5243 - val_loss: 0.8090 - val_mean_squared_error: 0.8090\n",
      "Epoch 115/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.5237 - mean_squared_error: 0.5237 - val_loss: 0.8077 - val_mean_squared_error: 0.8077\n",
      "Epoch 116/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.5232 - mean_squared_error: 0.5232 - val_loss: 0.8065 - val_mean_squared_error: 0.8065\n",
      "Epoch 117/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5227 - mean_squared_error: 0.5227 - val_loss: 0.8052 - val_mean_squared_error: 0.8052\n",
      "Epoch 118/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5222 - mean_squared_error: 0.5222 - val_loss: 0.8039 - val_mean_squared_error: 0.8039\n",
      "Epoch 119/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.5217 - mean_squared_error: 0.5217 - val_loss: 0.8026 - val_mean_squared_error: 0.8026\n",
      "Epoch 120/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5212 - mean_squared_error: 0.5212 - val_loss: 0.8014 - val_mean_squared_error: 0.8014\n",
      "Epoch 121/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.5207 - mean_squared_error: 0.5207 - val_loss: 0.8001 - val_mean_squared_error: 0.8001\n",
      "Epoch 122/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5202 - mean_squared_error: 0.5202 - val_loss: 0.7988 - val_mean_squared_error: 0.7988\n",
      "Epoch 123/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5197 - mean_squared_error: 0.5197 - val_loss: 0.7976 - val_mean_squared_error: 0.7976\n",
      "Epoch 124/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.5192 - mean_squared_error: 0.5192 - val_loss: 0.7963 - val_mean_squared_error: 0.7963\n",
      "Epoch 125/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5187 - mean_squared_error: 0.5187 - val_loss: 0.7950 - val_mean_squared_error: 0.7950\n",
      "Epoch 126/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5182 - mean_squared_error: 0.5182 - val_loss: 0.7938 - val_mean_squared_error: 0.7938\n",
      "Epoch 127/700\n",
      "800/800 [==============================] - 0s 25us/sample - loss: 0.5177 - mean_squared_error: 0.5177 - val_loss: 0.7925 - val_mean_squared_error: 0.7925\n",
      "Epoch 128/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5172 - mean_squared_error: 0.5172 - val_loss: 0.7912 - val_mean_squared_error: 0.7912\n",
      "Epoch 129/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5167 - mean_squared_error: 0.5167 - val_loss: 0.7900 - val_mean_squared_error: 0.7900\n",
      "Epoch 130/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.5162 - mean_squared_error: 0.5162 - val_loss: 0.7887 - val_mean_squared_error: 0.7887\n",
      "Epoch 131/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.5157 - mean_squared_error: 0.5157 - val_loss: 0.7874 - val_mean_squared_error: 0.7874\n",
      "Epoch 132/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.5152 - mean_squared_error: 0.5152 - val_loss: 0.7861 - val_mean_squared_error: 0.7861\n",
      "Epoch 133/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.5146 - mean_squared_error: 0.5146 - val_loss: 0.7849 - val_mean_squared_error: 0.7849\n",
      "Epoch 134/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.5141 - mean_squared_error: 0.5141 - val_loss: 0.7836 - val_mean_squared_error: 0.7836\n",
      "Epoch 135/700\n",
      "800/800 [==============================] - 0s 26us/sample - loss: 0.5136 - mean_squared_error: 0.5136 - val_loss: 0.7823 - val_mean_squared_error: 0.7823\n",
      "Epoch 136/700\n",
      "800/800 [==============================] - 0s 25us/sample - loss: 0.5130 - mean_squared_error: 0.5130 - val_loss: 0.7810 - val_mean_squared_error: 0.7810\n",
      "Epoch 137/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.5125 - mean_squared_error: 0.5125 - val_loss: 0.7797 - val_mean_squared_error: 0.7797\n",
      "Epoch 138/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.5119 - mean_squared_error: 0.5119 - val_loss: 0.7785 - val_mean_squared_error: 0.7785\n",
      "Epoch 139/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.5113 - mean_squared_error: 0.5113 - val_loss: 0.7772 - val_mean_squared_error: 0.7772\n",
      "Epoch 140/700\n",
      "800/800 [==============================] - 0s 27us/sample - loss: 0.5107 - mean_squared_error: 0.5107 - val_loss: 0.7759 - val_mean_squared_error: 0.7759\n",
      "Epoch 141/700\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 0.5101 - mean_squared_error: 0.5101 - val_loss: 0.7746 - val_mean_squared_error: 0.7746\n",
      "Epoch 142/700\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 0.5095 - mean_squared_error: 0.5095 - val_loss: 0.7733 - val_mean_squared_error: 0.7733\n",
      "Epoch 143/700\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 0.5088 - mean_squared_error: 0.5088 - val_loss: 0.7720 - val_mean_squared_error: 0.7720\n",
      "Epoch 144/700\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 0.5082 - mean_squared_error: 0.5082 - val_loss: 0.7707 - val_mean_squared_error: 0.7707\n",
      "Epoch 145/700\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 0.5075 - mean_squared_error: 0.5075 - val_loss: 0.7693 - val_mean_squared_error: 0.7693\n",
      "Epoch 146/700\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 0.5068 - mean_squared_error: 0.5068 - val_loss: 0.7680 - val_mean_squared_error: 0.7680\n",
      "Epoch 147/700\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 0.5060 - mean_squared_error: 0.5060 - val_loss: 0.7667 - val_mean_squared_error: 0.7667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/700\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 0.5052 - mean_squared_error: 0.5052 - val_loss: 0.7654 - val_mean_squared_error: 0.7654\n",
      "Epoch 149/700\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 0.5044 - mean_squared_error: 0.5044 - val_loss: 0.7640 - val_mean_squared_error: 0.7640\n",
      "Epoch 150/700\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 0.5036 - mean_squared_error: 0.5036 - val_loss: 0.7627 - val_mean_squared_error: 0.7627\n",
      "Epoch 151/700\n",
      "800/800 [==============================] - 0s 43us/sample - loss: 0.5027 - mean_squared_error: 0.5027 - val_loss: 0.7613 - val_mean_squared_error: 0.7613\n",
      "Epoch 152/700\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 0.5018 - mean_squared_error: 0.5018 - val_loss: 0.7599 - val_mean_squared_error: 0.7599\n",
      "Epoch 153/700\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 0.5008 - mean_squared_error: 0.5008 - val_loss: 0.7585 - val_mean_squared_error: 0.7585\n",
      "Epoch 154/700\n",
      "800/800 [==============================] - 0s 42us/sample - loss: 0.4997 - mean_squared_error: 0.4997 - val_loss: 0.7571 - val_mean_squared_error: 0.7571\n",
      "Epoch 155/700\n",
      "800/800 [==============================] - 0s 42us/sample - loss: 0.4986 - mean_squared_error: 0.4986 - val_loss: 0.7557 - val_mean_squared_error: 0.7557\n",
      "Epoch 156/700\n",
      "800/800 [==============================] - 0s 41us/sample - loss: 0.4975 - mean_squared_error: 0.4975 - val_loss: 0.7542 - val_mean_squared_error: 0.7542\n",
      "Epoch 157/700\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 0.4962 - mean_squared_error: 0.4962 - val_loss: 0.7528 - val_mean_squared_error: 0.7528\n",
      "Epoch 158/700\n",
      "800/800 [==============================] - 0s 26us/sample - loss: 0.4949 - mean_squared_error: 0.4949 - val_loss: 0.7513 - val_mean_squared_error: 0.7513\n",
      "Epoch 159/700\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 0.4935 - mean_squared_error: 0.4935 - val_loss: 0.7497 - val_mean_squared_error: 0.7497\n",
      "Epoch 160/700\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 0.4920 - mean_squared_error: 0.4920 - val_loss: 0.7482 - val_mean_squared_error: 0.7482\n",
      "Epoch 161/700\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 0.4905 - mean_squared_error: 0.4905 - val_loss: 0.7466 - val_mean_squared_error: 0.7466\n",
      "Epoch 162/700\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4888 - mean_squared_error: 0.4888 - val_loss: 0.7449 - val_mean_squared_error: 0.7449\n",
      "Epoch 163/700\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.4870 - mean_squared_error: 0.4870 - val_loss: 0.7433 - val_mean_squared_error: 0.7433\n",
      "Epoch 164/700\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 0.4852 - mean_squared_error: 0.4852 - val_loss: 0.7415 - val_mean_squared_error: 0.7415\n",
      "Epoch 165/700\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 0.4832 - mean_squared_error: 0.4832 - val_loss: 0.7397 - val_mean_squared_error: 0.7397\n",
      "Epoch 166/700\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 0.4811 - mean_squared_error: 0.4811 - val_loss: 0.7378 - val_mean_squared_error: 0.7378\n",
      "Epoch 167/700\n",
      "800/800 [==============================] - 0s 26us/sample - loss: 0.4790 - mean_squared_error: 0.4790 - val_loss: 0.7359 - val_mean_squared_error: 0.7359\n",
      "Epoch 168/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.4767 - mean_squared_error: 0.4767 - val_loss: 0.7339 - val_mean_squared_error: 0.7339\n",
      "Epoch 169/700\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 0.4744 - mean_squared_error: 0.4744 - val_loss: 0.7318 - val_mean_squared_error: 0.7318\n",
      "Epoch 170/700\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 0.4721 - mean_squared_error: 0.4721 - val_loss: 0.7296 - val_mean_squared_error: 0.7296\n",
      "Epoch 171/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.4698 - mean_squared_error: 0.4698 - val_loss: 0.7274 - val_mean_squared_error: 0.7274\n",
      "Epoch 172/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.4674 - mean_squared_error: 0.4674 - val_loss: 0.7251 - val_mean_squared_error: 0.7251\n",
      "Epoch 173/700\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 0.4652 - mean_squared_error: 0.4652 - val_loss: 0.7227 - val_mean_squared_error: 0.7227\n",
      "Epoch 174/700\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 0.4630 - mean_squared_error: 0.4630 - val_loss: 0.7202 - val_mean_squared_error: 0.7202\n",
      "Epoch 175/700\n",
      "800/800 [==============================] - 0s 25us/sample - loss: 0.4610 - mean_squared_error: 0.4610 - val_loss: 0.7177 - val_mean_squared_error: 0.7177\n",
      "Epoch 176/700\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 0.4592 - mean_squared_error: 0.4592 - val_loss: 0.7151 - val_mean_squared_error: 0.7151\n",
      "Epoch 177/700\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 0.4575 - mean_squared_error: 0.4575 - val_loss: 0.7125 - val_mean_squared_error: 0.7125\n",
      "Epoch 178/700\n",
      "800/800 [==============================] - 0s 39us/sample - loss: 0.4560 - mean_squared_error: 0.4560 - val_loss: 0.7099 - val_mean_squared_error: 0.7099\n",
      "Epoch 179/700\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 0.4547 - mean_squared_error: 0.4547 - val_loss: 0.7073 - val_mean_squared_error: 0.7073\n",
      "Epoch 180/700\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4536 - mean_squared_error: 0.4536 - val_loss: 0.7047 - val_mean_squared_error: 0.7047\n",
      "Epoch 181/700\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.4526 - mean_squared_error: 0.4526 - val_loss: 0.7021 - val_mean_squared_error: 0.7021\n",
      "Epoch 182/700\n",
      "800/800 [==============================] - 0s 41us/sample - loss: 0.4516 - mean_squared_error: 0.4516 - val_loss: 0.6996 - val_mean_squared_error: 0.6996\n",
      "Epoch 183/700\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 0.4507 - mean_squared_error: 0.4507 - val_loss: 0.6972 - val_mean_squared_error: 0.6972\n",
      "Epoch 184/700\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 0.4497 - mean_squared_error: 0.4497 - val_loss: 0.6948 - val_mean_squared_error: 0.6948\n",
      "Epoch 185/700\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 0.4488 - mean_squared_error: 0.4488 - val_loss: 0.6924 - val_mean_squared_error: 0.6924\n",
      "Epoch 186/700\n",
      "800/800 [==============================] - 0s 27us/sample - loss: 0.4478 - mean_squared_error: 0.4478 - val_loss: 0.6902 - val_mean_squared_error: 0.6902\n",
      "Epoch 187/700\n",
      "800/800 [==============================] - 0s 41us/sample - loss: 0.4469 - mean_squared_error: 0.4469 - val_loss: 0.6880 - val_mean_squared_error: 0.6880\n",
      "Epoch 188/700\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4459 - mean_squared_error: 0.4459 - val_loss: 0.6859 - val_mean_squared_error: 0.6859\n",
      "Epoch 189/700\n",
      "800/800 [==============================] - 0s 27us/sample - loss: 0.4449 - mean_squared_error: 0.4449 - val_loss: 0.6838 - val_mean_squared_error: 0.6838\n",
      "Epoch 190/700\n",
      "800/800 [==============================] - 0s 28us/sample - loss: 0.4439 - mean_squared_error: 0.4439 - val_loss: 0.6818 - val_mean_squared_error: 0.6818\n",
      "Epoch 191/700\n",
      "800/800 [==============================] - 0s 28us/sample - loss: 0.4430 - mean_squared_error: 0.4430 - val_loss: 0.6798 - val_mean_squared_error: 0.6798\n",
      "Epoch 192/700\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 0.4421 - mean_squared_error: 0.4421 - val_loss: 0.6779 - val_mean_squared_error: 0.6779\n",
      "Epoch 193/700\n",
      "800/800 [==============================] - 0s 28us/sample - loss: 0.4412 - mean_squared_error: 0.4412 - val_loss: 0.6760 - val_mean_squared_error: 0.6760\n",
      "Epoch 194/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.4403 - mean_squared_error: 0.4403 - val_loss: 0.6741 - val_mean_squared_error: 0.6741\n",
      "Epoch 195/700\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 0.4394 - mean_squared_error: 0.4394 - val_loss: 0.6723 - val_mean_squared_error: 0.6723\n",
      "Epoch 196/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.4386 - mean_squared_error: 0.4386 - val_loss: 0.6705 - val_mean_squared_error: 0.6705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.4378 - mean_squared_error: 0.4378 - val_loss: 0.6687 - val_mean_squared_error: 0.6687\n",
      "Epoch 198/700\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 0.4370 - mean_squared_error: 0.4370 - val_loss: 0.6669 - val_mean_squared_error: 0.6669\n",
      "Epoch 199/700\n",
      "800/800 [==============================] - 0s 38us/sample - loss: 0.4362 - mean_squared_error: 0.4362 - val_loss: 0.6652 - val_mean_squared_error: 0.6652\n",
      "Epoch 200/700\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 0.4355 - mean_squared_error: 0.4355 - val_loss: 0.6635 - val_mean_squared_error: 0.6635\n",
      "Epoch 201/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.4347 - mean_squared_error: 0.4347 - val_loss: 0.6618 - val_mean_squared_error: 0.6618\n",
      "Epoch 202/700\n",
      "800/800 [==============================] - 0s 27us/sample - loss: 0.4340 - mean_squared_error: 0.4340 - val_loss: 0.6602 - val_mean_squared_error: 0.6602\n",
      "Epoch 203/700\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.4332 - mean_squared_error: 0.4332 - val_loss: 0.6586 - val_mean_squared_error: 0.6586\n",
      "Epoch 204/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.4325 - mean_squared_error: 0.4325 - val_loss: 0.6570 - val_mean_squared_error: 0.6570\n",
      "Epoch 205/700\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 0.4318 - mean_squared_error: 0.4318 - val_loss: 0.6555 - val_mean_squared_error: 0.6555\n",
      "Epoch 206/700\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 0.4311 - mean_squared_error: 0.4311 - val_loss: 0.6539 - val_mean_squared_error: 0.6539\n",
      "Epoch 207/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.4305 - mean_squared_error: 0.4305 - val_loss: 0.6524 - val_mean_squared_error: 0.6524\n",
      "Epoch 208/700\n",
      "800/800 [==============================] - 0s 25us/sample - loss: 0.4298 - mean_squared_error: 0.4298 - val_loss: 0.6510 - val_mean_squared_error: 0.6510\n",
      "Epoch 209/700\n",
      "800/800 [==============================] - 0s 26us/sample - loss: 0.4291 - mean_squared_error: 0.4291 - val_loss: 0.6495 - val_mean_squared_error: 0.6495\n",
      "Epoch 210/700\n",
      "800/800 [==============================] - 0s 25us/sample - loss: 0.4285 - mean_squared_error: 0.4285 - val_loss: 0.6480 - val_mean_squared_error: 0.6480\n",
      "Epoch 211/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.4278 - mean_squared_error: 0.4278 - val_loss: 0.6466 - val_mean_squared_error: 0.6466\n",
      "Epoch 212/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.4272 - mean_squared_error: 0.4272 - val_loss: 0.6451 - val_mean_squared_error: 0.6451\n",
      "Epoch 213/700\n",
      "800/800 [==============================] - 0s 27us/sample - loss: 0.4265 - mean_squared_error: 0.4265 - val_loss: 0.6437 - val_mean_squared_error: 0.6437\n",
      "Epoch 214/700\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 0.4259 - mean_squared_error: 0.4259 - val_loss: 0.6423 - val_mean_squared_error: 0.6423\n",
      "Epoch 215/700\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 0.4253 - mean_squared_error: 0.4253 - val_loss: 0.6409 - val_mean_squared_error: 0.6409\n",
      "Epoch 216/700\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 0.4246 - mean_squared_error: 0.4246 - val_loss: 0.6395 - val_mean_squared_error: 0.6395\n",
      "Epoch 217/700\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 0.4240 - mean_squared_error: 0.4240 - val_loss: 0.6382 - val_mean_squared_error: 0.6382\n",
      "Epoch 218/700\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 0.4234 - mean_squared_error: 0.4234 - val_loss: 0.6368 - val_mean_squared_error: 0.6368\n",
      "Epoch 219/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.4228 - mean_squared_error: 0.4228 - val_loss: 0.6355 - val_mean_squared_error: 0.6355\n",
      "Epoch 220/700\n",
      "800/800 [==============================] - 0s 39us/sample - loss: 0.4222 - mean_squared_error: 0.4222 - val_loss: 0.6343 - val_mean_squared_error: 0.6343\n",
      "Epoch 221/700\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.4216 - mean_squared_error: 0.4216 - val_loss: 0.6330 - val_mean_squared_error: 0.6330\n",
      "Epoch 222/700\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.4211 - mean_squared_error: 0.4211 - val_loss: 0.6317 - val_mean_squared_error: 0.6317\n",
      "Epoch 223/700\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4205 - mean_squared_error: 0.4205 - val_loss: 0.6305 - val_mean_squared_error: 0.6305\n",
      "Epoch 224/700\n",
      "800/800 [==============================] - 0s 26us/sample - loss: 0.4199 - mean_squared_error: 0.4199 - val_loss: 0.6292 - val_mean_squared_error: 0.6292\n",
      "Epoch 225/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.4193 - mean_squared_error: 0.4193 - val_loss: 0.6280 - val_mean_squared_error: 0.6280\n",
      "Epoch 226/700\n",
      "800/800 [==============================] - 0s 28us/sample - loss: 0.4188 - mean_squared_error: 0.4188 - val_loss: 0.6267 - val_mean_squared_error: 0.6267\n",
      "Epoch 227/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.4182 - mean_squared_error: 0.4182 - val_loss: 0.6255 - val_mean_squared_error: 0.6255\n",
      "Epoch 228/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.4177 - mean_squared_error: 0.4177 - val_loss: 0.6243 - val_mean_squared_error: 0.6243\n",
      "Epoch 229/700\n",
      "800/800 [==============================] - 0s 25us/sample - loss: 0.4171 - mean_squared_error: 0.4171 - val_loss: 0.6230 - val_mean_squared_error: 0.6230\n",
      "Epoch 230/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.4166 - mean_squared_error: 0.4166 - val_loss: 0.6218 - val_mean_squared_error: 0.6218\n",
      "Epoch 231/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.4160 - mean_squared_error: 0.4160 - val_loss: 0.6205 - val_mean_squared_error: 0.6205\n",
      "Epoch 232/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.4155 - mean_squared_error: 0.4155 - val_loss: 0.6193 - val_mean_squared_error: 0.6193\n",
      "Epoch 233/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.4149 - mean_squared_error: 0.4149 - val_loss: 0.6181 - val_mean_squared_error: 0.6181\n",
      "Epoch 234/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.4144 - mean_squared_error: 0.4144 - val_loss: 0.6168 - val_mean_squared_error: 0.6168\n",
      "Epoch 235/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.4139 - mean_squared_error: 0.4139 - val_loss: 0.6156 - val_mean_squared_error: 0.6156\n",
      "Epoch 236/700\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 0.4134 - mean_squared_error: 0.4134 - val_loss: 0.6144 - val_mean_squared_error: 0.6144\n",
      "Epoch 237/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.4129 - mean_squared_error: 0.4129 - val_loss: 0.6132 - val_mean_squared_error: 0.6132\n",
      "Epoch 238/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.4124 - mean_squared_error: 0.4124 - val_loss: 0.6119 - val_mean_squared_error: 0.6119\n",
      "Epoch 239/700\n",
      "800/800 [==============================] - 0s 26us/sample - loss: 0.4118 - mean_squared_error: 0.4118 - val_loss: 0.6107 - val_mean_squared_error: 0.6107\n",
      "Epoch 240/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.4113 - mean_squared_error: 0.4113 - val_loss: 0.6095 - val_mean_squared_error: 0.6095\n",
      "Epoch 241/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.4108 - mean_squared_error: 0.4108 - val_loss: 0.6084 - val_mean_squared_error: 0.6084\n",
      "Epoch 242/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.4104 - mean_squared_error: 0.4104 - val_loss: 0.6072 - val_mean_squared_error: 0.6072\n",
      "Epoch 243/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.4099 - mean_squared_error: 0.4099 - val_loss: 0.6060 - val_mean_squared_error: 0.6060\n",
      "Epoch 244/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.4094 - mean_squared_error: 0.4094 - val_loss: 0.6049 - val_mean_squared_error: 0.6049\n",
      "Epoch 245/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.4089 - mean_squared_error: 0.4089 - val_loss: 0.6037 - val_mean_squared_error: 0.6037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.4084 - mean_squared_error: 0.4084 - val_loss: 0.6026 - val_mean_squared_error: 0.6026\n",
      "Epoch 247/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.4079 - mean_squared_error: 0.4079 - val_loss: 0.6015 - val_mean_squared_error: 0.6015\n",
      "Epoch 248/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.4075 - mean_squared_error: 0.4075 - val_loss: 0.6004 - val_mean_squared_error: 0.6004\n",
      "Epoch 249/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.4070 - mean_squared_error: 0.4070 - val_loss: 0.5993 - val_mean_squared_error: 0.5993\n",
      "Epoch 250/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.4065 - mean_squared_error: 0.4065 - val_loss: 0.5982 - val_mean_squared_error: 0.5982\n",
      "Epoch 251/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.4061 - mean_squared_error: 0.4061 - val_loss: 0.5971 - val_mean_squared_error: 0.5971\n",
      "Epoch 252/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.4056 - mean_squared_error: 0.4056 - val_loss: 0.5961 - val_mean_squared_error: 0.5961\n",
      "Epoch 253/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.4052 - mean_squared_error: 0.4052 - val_loss: 0.5950 - val_mean_squared_error: 0.5950\n",
      "Epoch 254/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.4047 - mean_squared_error: 0.4047 - val_loss: 0.5939 - val_mean_squared_error: 0.5939\n",
      "Epoch 255/700\n",
      "800/800 [==============================] - 0s 27us/sample - loss: 0.4042 - mean_squared_error: 0.4042 - val_loss: 0.5928 - val_mean_squared_error: 0.5928\n",
      "Epoch 256/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.4038 - mean_squared_error: 0.4038 - val_loss: 0.5918 - val_mean_squared_error: 0.5918\n",
      "Epoch 257/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.4034 - mean_squared_error: 0.4034 - val_loss: 0.5907 - val_mean_squared_error: 0.5907\n",
      "Epoch 258/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.4029 - mean_squared_error: 0.4029 - val_loss: 0.5896 - val_mean_squared_error: 0.5896\n",
      "Epoch 259/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.4025 - mean_squared_error: 0.4025 - val_loss: 0.5886 - val_mean_squared_error: 0.5886\n",
      "Epoch 260/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.4020 - mean_squared_error: 0.4020 - val_loss: 0.5875 - val_mean_squared_error: 0.5875\n",
      "Epoch 261/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.4016 - mean_squared_error: 0.4016 - val_loss: 0.5864 - val_mean_squared_error: 0.5864\n",
      "Epoch 262/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.4012 - mean_squared_error: 0.4012 - val_loss: 0.5853 - val_mean_squared_error: 0.5853\n",
      "Epoch 263/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.4007 - mean_squared_error: 0.4007 - val_loss: 0.5843 - val_mean_squared_error: 0.5843\n",
      "Epoch 264/700\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 0.4003 - mean_squared_error: 0.4003 - val_loss: 0.5832 - val_mean_squared_error: 0.5832\n",
      "Epoch 265/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3999 - mean_squared_error: 0.3999 - val_loss: 0.5821 - val_mean_squared_error: 0.5821\n",
      "Epoch 266/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3995 - mean_squared_error: 0.3995 - val_loss: 0.5811 - val_mean_squared_error: 0.5811\n",
      "Epoch 267/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3990 - mean_squared_error: 0.3990 - val_loss: 0.5800 - val_mean_squared_error: 0.5800\n",
      "Epoch 268/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3986 - mean_squared_error: 0.3986 - val_loss: 0.5789 - val_mean_squared_error: 0.5789\n",
      "Epoch 269/700\n",
      "800/800 [==============================] - 0s 25us/sample - loss: 0.3982 - mean_squared_error: 0.3982 - val_loss: 0.5779 - val_mean_squared_error: 0.5779\n",
      "Epoch 270/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3978 - mean_squared_error: 0.3978 - val_loss: 0.5768 - val_mean_squared_error: 0.5768\n",
      "Epoch 271/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3974 - mean_squared_error: 0.3974 - val_loss: 0.5758 - val_mean_squared_error: 0.5758\n",
      "Epoch 272/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.3969 - mean_squared_error: 0.3969 - val_loss: 0.5748 - val_mean_squared_error: 0.5748\n",
      "Epoch 273/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3965 - mean_squared_error: 0.3965 - val_loss: 0.5737 - val_mean_squared_error: 0.5737\n",
      "Epoch 274/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3961 - mean_squared_error: 0.3961 - val_loss: 0.5727 - val_mean_squared_error: 0.5727\n",
      "Epoch 275/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3957 - mean_squared_error: 0.3957 - val_loss: 0.5717 - val_mean_squared_error: 0.5717\n",
      "Epoch 276/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3953 - mean_squared_error: 0.3953 - val_loss: 0.5706 - val_mean_squared_error: 0.5706\n",
      "Epoch 277/700\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 0.3949 - mean_squared_error: 0.3949 - val_loss: 0.5696 - val_mean_squared_error: 0.5696\n",
      "Epoch 278/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3945 - mean_squared_error: 0.3945 - val_loss: 0.5686 - val_mean_squared_error: 0.5686\n",
      "Epoch 279/700\n",
      "800/800 [==============================] - 0s 25us/sample - loss: 0.3941 - mean_squared_error: 0.3941 - val_loss: 0.5676 - val_mean_squared_error: 0.5676\n",
      "Epoch 280/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3937 - mean_squared_error: 0.3937 - val_loss: 0.5666 - val_mean_squared_error: 0.5666\n",
      "Epoch 281/700\n",
      "800/800 [==============================] - 0s 27us/sample - loss: 0.3933 - mean_squared_error: 0.3933 - val_loss: 0.5656 - val_mean_squared_error: 0.5656\n",
      "Epoch 282/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3929 - mean_squared_error: 0.3929 - val_loss: 0.5646 - val_mean_squared_error: 0.5646\n",
      "Epoch 283/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3925 - mean_squared_error: 0.3925 - val_loss: 0.5636 - val_mean_squared_error: 0.5636\n",
      "Epoch 284/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.3921 - mean_squared_error: 0.3921 - val_loss: 0.5626 - val_mean_squared_error: 0.5626\n",
      "Epoch 285/700\n",
      "800/800 [==============================] - 0s 25us/sample - loss: 0.3917 - mean_squared_error: 0.3917 - val_loss: 0.5616 - val_mean_squared_error: 0.5616\n",
      "Epoch 286/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.3913 - mean_squared_error: 0.3913 - val_loss: 0.5607 - val_mean_squared_error: 0.5607\n",
      "Epoch 287/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.3909 - mean_squared_error: 0.3909 - val_loss: 0.5597 - val_mean_squared_error: 0.5597\n",
      "Epoch 288/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3905 - mean_squared_error: 0.3905 - val_loss: 0.5587 - val_mean_squared_error: 0.5587\n",
      "Epoch 289/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3902 - mean_squared_error: 0.3902 - val_loss: 0.5577 - val_mean_squared_error: 0.5577\n",
      "Epoch 290/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3898 - mean_squared_error: 0.3898 - val_loss: 0.5568 - val_mean_squared_error: 0.5568\n",
      "Epoch 291/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3894 - mean_squared_error: 0.3894 - val_loss: 0.5558 - val_mean_squared_error: 0.5558\n",
      "Epoch 292/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3890 - mean_squared_error: 0.3890 - val_loss: 0.5549 - val_mean_squared_error: 0.5549\n",
      "Epoch 293/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3886 - mean_squared_error: 0.3886 - val_loss: 0.5539 - val_mean_squared_error: 0.5539\n",
      "Epoch 294/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3882 - mean_squared_error: 0.3882 - val_loss: 0.5530 - val_mean_squared_error: 0.5530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3879 - mean_squared_error: 0.3879 - val_loss: 0.5521 - val_mean_squared_error: 0.5521\n",
      "Epoch 296/700\n",
      "800/800 [==============================] - 0s 14us/sample - loss: 0.3875 - mean_squared_error: 0.3875 - val_loss: 0.5511 - val_mean_squared_error: 0.5511\n",
      "Epoch 297/700\n",
      "800/800 [==============================] - 0s 14us/sample - loss: 0.3871 - mean_squared_error: 0.3871 - val_loss: 0.5502 - val_mean_squared_error: 0.5502\n",
      "Epoch 298/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3867 - mean_squared_error: 0.3867 - val_loss: 0.5493 - val_mean_squared_error: 0.5493\n",
      "Epoch 299/700\n",
      "800/800 [==============================] - 0s 28us/sample - loss: 0.3863 - mean_squared_error: 0.3863 - val_loss: 0.5484 - val_mean_squared_error: 0.5484\n",
      "Epoch 300/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3860 - mean_squared_error: 0.3860 - val_loss: 0.5475 - val_mean_squared_error: 0.5475\n",
      "Epoch 301/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.3856 - mean_squared_error: 0.3856 - val_loss: 0.5466 - val_mean_squared_error: 0.5466\n",
      "Epoch 302/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3852 - mean_squared_error: 0.3852 - val_loss: 0.5457 - val_mean_squared_error: 0.5457\n",
      "Epoch 303/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3848 - mean_squared_error: 0.3848 - val_loss: 0.5448 - val_mean_squared_error: 0.5448\n",
      "Epoch 304/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3845 - mean_squared_error: 0.3845 - val_loss: 0.5439 - val_mean_squared_error: 0.5439\n",
      "Epoch 305/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3841 - mean_squared_error: 0.3841 - val_loss: 0.5430 - val_mean_squared_error: 0.5430\n",
      "Epoch 306/700\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 0.3837 - mean_squared_error: 0.3837 - val_loss: 0.5422 - val_mean_squared_error: 0.5422\n",
      "Epoch 307/700\n",
      "800/800 [==============================] - 0s 27us/sample - loss: 0.3833 - mean_squared_error: 0.3833 - val_loss: 0.5413 - val_mean_squared_error: 0.5413\n",
      "Epoch 308/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3830 - mean_squared_error: 0.3830 - val_loss: 0.5404 - val_mean_squared_error: 0.5404\n",
      "Epoch 309/700\n",
      "800/800 [==============================] - 0s 27us/sample - loss: 0.3826 - mean_squared_error: 0.3826 - val_loss: 0.5396 - val_mean_squared_error: 0.5396\n",
      "Epoch 310/700\n",
      "800/800 [==============================] - 0s 38us/sample - loss: 0.3822 - mean_squared_error: 0.3822 - val_loss: 0.5387 - val_mean_squared_error: 0.5387\n",
      "Epoch 311/700\n",
      "800/800 [==============================] - 0s 41us/sample - loss: 0.3819 - mean_squared_error: 0.3819 - val_loss: 0.5379 - val_mean_squared_error: 0.5379\n",
      "Epoch 312/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3815 - mean_squared_error: 0.3815 - val_loss: 0.5370 - val_mean_squared_error: 0.5370\n",
      "Epoch 313/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.3811 - mean_squared_error: 0.3811 - val_loss: 0.5362 - val_mean_squared_error: 0.5362\n",
      "Epoch 314/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3808 - mean_squared_error: 0.3808 - val_loss: 0.5354 - val_mean_squared_error: 0.5354\n",
      "Epoch 315/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3804 - mean_squared_error: 0.3804 - val_loss: 0.5346 - val_mean_squared_error: 0.5346\n",
      "Epoch 316/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3800 - mean_squared_error: 0.3800 - val_loss: 0.5337 - val_mean_squared_error: 0.5337\n",
      "Epoch 317/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3797 - mean_squared_error: 0.3797 - val_loss: 0.5329 - val_mean_squared_error: 0.5329\n",
      "Epoch 318/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3793 - mean_squared_error: 0.3793 - val_loss: 0.5321 - val_mean_squared_error: 0.5321\n",
      "Epoch 319/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3790 - mean_squared_error: 0.3790 - val_loss: 0.5313 - val_mean_squared_error: 0.5313\n",
      "Epoch 320/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3786 - mean_squared_error: 0.3786 - val_loss: 0.5305 - val_mean_squared_error: 0.5305\n",
      "Epoch 321/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.3782 - mean_squared_error: 0.3782 - val_loss: 0.5298 - val_mean_squared_error: 0.5298\n",
      "Epoch 322/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.3779 - mean_squared_error: 0.3779 - val_loss: 0.5290 - val_mean_squared_error: 0.5290\n",
      "Epoch 323/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3775 - mean_squared_error: 0.3775 - val_loss: 0.5282 - val_mean_squared_error: 0.5282\n",
      "Epoch 324/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3772 - mean_squared_error: 0.3772 - val_loss: 0.5274 - val_mean_squared_error: 0.5274\n",
      "Epoch 325/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3768 - mean_squared_error: 0.3768 - val_loss: 0.5267 - val_mean_squared_error: 0.5267\n",
      "Epoch 326/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3765 - mean_squared_error: 0.3765 - val_loss: 0.5259 - val_mean_squared_error: 0.5259\n",
      "Epoch 327/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3761 - mean_squared_error: 0.3761 - val_loss: 0.5252 - val_mean_squared_error: 0.5252\n",
      "Epoch 328/700\n",
      "800/800 [==============================] - 0s 14us/sample - loss: 0.3758 - mean_squared_error: 0.3758 - val_loss: 0.5244 - val_mean_squared_error: 0.5244\n",
      "Epoch 329/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3754 - mean_squared_error: 0.3754 - val_loss: 0.5237 - val_mean_squared_error: 0.5237\n",
      "Epoch 330/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3751 - mean_squared_error: 0.3751 - val_loss: 0.5229 - val_mean_squared_error: 0.5229\n",
      "Epoch 331/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3747 - mean_squared_error: 0.3747 - val_loss: 0.5222 - val_mean_squared_error: 0.5222\n",
      "Epoch 332/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.3744 - mean_squared_error: 0.3744 - val_loss: 0.5215 - val_mean_squared_error: 0.5215\n",
      "Epoch 333/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3740 - mean_squared_error: 0.3740 - val_loss: 0.5208 - val_mean_squared_error: 0.5208\n",
      "Epoch 334/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3737 - mean_squared_error: 0.3737 - val_loss: 0.5200 - val_mean_squared_error: 0.5200\n",
      "Epoch 335/700\n",
      "800/800 [==============================] - 0s 25us/sample - loss: 0.3733 - mean_squared_error: 0.3733 - val_loss: 0.5193 - val_mean_squared_error: 0.5193\n",
      "Epoch 336/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3730 - mean_squared_error: 0.3730 - val_loss: 0.5186 - val_mean_squared_error: 0.5186\n",
      "Epoch 337/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3726 - mean_squared_error: 0.3726 - val_loss: 0.5179 - val_mean_squared_error: 0.5179\n",
      "Epoch 338/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3723 - mean_squared_error: 0.3723 - val_loss: 0.5172 - val_mean_squared_error: 0.5172\n",
      "Epoch 339/700\n",
      "800/800 [==============================] - 0s 13us/sample - loss: 0.3719 - mean_squared_error: 0.3719 - val_loss: 0.5165 - val_mean_squared_error: 0.5165\n",
      "Epoch 340/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.3716 - mean_squared_error: 0.3716 - val_loss: 0.5158 - val_mean_squared_error: 0.5158\n",
      "Epoch 341/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3712 - mean_squared_error: 0.3712 - val_loss: 0.5151 - val_mean_squared_error: 0.5151\n",
      "Epoch 342/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3709 - mean_squared_error: 0.3709 - val_loss: 0.5145 - val_mean_squared_error: 0.5145\n",
      "Epoch 343/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3706 - mean_squared_error: 0.3706 - val_loss: 0.5138 - val_mean_squared_error: 0.5138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3702 - mean_squared_error: 0.3702 - val_loss: 0.5131 - val_mean_squared_error: 0.5131\n",
      "Epoch 345/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3699 - mean_squared_error: 0.3699 - val_loss: 0.5125 - val_mean_squared_error: 0.5125\n",
      "Epoch 346/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3695 - mean_squared_error: 0.3695 - val_loss: 0.5118 - val_mean_squared_error: 0.5118\n",
      "Epoch 347/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3692 - mean_squared_error: 0.3692 - val_loss: 0.5112 - val_mean_squared_error: 0.5112\n",
      "Epoch 348/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3689 - mean_squared_error: 0.3689 - val_loss: 0.5105 - val_mean_squared_error: 0.5105\n",
      "Epoch 349/700\n",
      "800/800 [==============================] - 0s 26us/sample - loss: 0.3685 - mean_squared_error: 0.3685 - val_loss: 0.5099 - val_mean_squared_error: 0.5099\n",
      "Epoch 350/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.3682 - mean_squared_error: 0.3682 - val_loss: 0.5092 - val_mean_squared_error: 0.5092\n",
      "Epoch 351/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3678 - mean_squared_error: 0.3678 - val_loss: 0.5086 - val_mean_squared_error: 0.5086\n",
      "Epoch 352/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3675 - mean_squared_error: 0.3675 - val_loss: 0.5080 - val_mean_squared_error: 0.5080\n",
      "Epoch 353/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3672 - mean_squared_error: 0.3672 - val_loss: 0.5073 - val_mean_squared_error: 0.5073\n",
      "Epoch 354/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3668 - mean_squared_error: 0.3668 - val_loss: 0.5067 - val_mean_squared_error: 0.5067\n",
      "Epoch 355/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.3665 - mean_squared_error: 0.3665 - val_loss: 0.5061 - val_mean_squared_error: 0.5061\n",
      "Epoch 356/700\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 0.3662 - mean_squared_error: 0.3662 - val_loss: 0.5055 - val_mean_squared_error: 0.5055\n",
      "Epoch 357/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3659 - mean_squared_error: 0.3659 - val_loss: 0.5049 - val_mean_squared_error: 0.5049\n",
      "Epoch 358/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3655 - mean_squared_error: 0.3655 - val_loss: 0.5043 - val_mean_squared_error: 0.5043\n",
      "Epoch 359/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3652 - mean_squared_error: 0.3652 - val_loss: 0.5037 - val_mean_squared_error: 0.5037\n",
      "Epoch 360/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3649 - mean_squared_error: 0.3649 - val_loss: 0.5031 - val_mean_squared_error: 0.5031\n",
      "Epoch 361/700\n",
      "800/800 [==============================] - 0s 25us/sample - loss: 0.3645 - mean_squared_error: 0.3645 - val_loss: 0.5025 - val_mean_squared_error: 0.5025\n",
      "Epoch 362/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3642 - mean_squared_error: 0.3642 - val_loss: 0.5019 - val_mean_squared_error: 0.5019\n",
      "Epoch 363/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3639 - mean_squared_error: 0.3639 - val_loss: 0.5013 - val_mean_squared_error: 0.5013\n",
      "Epoch 364/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3636 - mean_squared_error: 0.3636 - val_loss: 0.5008 - val_mean_squared_error: 0.5008\n",
      "Epoch 365/700\n",
      "800/800 [==============================] - 0s 14us/sample - loss: 0.3632 - mean_squared_error: 0.3632 - val_loss: 0.5002 - val_mean_squared_error: 0.5002\n",
      "Epoch 366/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3629 - mean_squared_error: 0.3629 - val_loss: 0.4996 - val_mean_squared_error: 0.4996\n",
      "Epoch 367/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.3626 - mean_squared_error: 0.3626 - val_loss: 0.4991 - val_mean_squared_error: 0.4991\n",
      "Epoch 368/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3623 - mean_squared_error: 0.3623 - val_loss: 0.4985 - val_mean_squared_error: 0.4985\n",
      "Epoch 369/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.3619 - mean_squared_error: 0.3619 - val_loss: 0.4980 - val_mean_squared_error: 0.4980\n",
      "Epoch 370/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.3616 - mean_squared_error: 0.3616 - val_loss: 0.4974 - val_mean_squared_error: 0.4974\n",
      "Epoch 371/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3613 - mean_squared_error: 0.3613 - val_loss: 0.4969 - val_mean_squared_error: 0.4969\n",
      "Epoch 372/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3610 - mean_squared_error: 0.3610 - val_loss: 0.4963 - val_mean_squared_error: 0.4963\n",
      "Epoch 373/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3607 - mean_squared_error: 0.3607 - val_loss: 0.4958 - val_mean_squared_error: 0.4958\n",
      "Epoch 374/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3603 - mean_squared_error: 0.3603 - val_loss: 0.4953 - val_mean_squared_error: 0.4953\n",
      "Epoch 375/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3600 - mean_squared_error: 0.3600 - val_loss: 0.4948 - val_mean_squared_error: 0.4948\n",
      "Epoch 376/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3597 - mean_squared_error: 0.3597 - val_loss: 0.4942 - val_mean_squared_error: 0.4942\n",
      "Epoch 377/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3594 - mean_squared_error: 0.3594 - val_loss: 0.4937 - val_mean_squared_error: 0.4937\n",
      "Epoch 378/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.3591 - mean_squared_error: 0.3591 - val_loss: 0.4932 - val_mean_squared_error: 0.4932\n",
      "Epoch 379/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3588 - mean_squared_error: 0.3588 - val_loss: 0.4927 - val_mean_squared_error: 0.4927\n",
      "Epoch 380/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3585 - mean_squared_error: 0.3585 - val_loss: 0.4922 - val_mean_squared_error: 0.4922\n",
      "Epoch 381/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3581 - mean_squared_error: 0.3581 - val_loss: 0.4917 - val_mean_squared_error: 0.4917\n",
      "Epoch 382/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3578 - mean_squared_error: 0.3578 - val_loss: 0.4912 - val_mean_squared_error: 0.4912\n",
      "Epoch 383/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3575 - mean_squared_error: 0.3575 - val_loss: 0.4907 - val_mean_squared_error: 0.4907\n",
      "Epoch 384/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.3572 - mean_squared_error: 0.3572 - val_loss: 0.4902 - val_mean_squared_error: 0.4902\n",
      "Epoch 385/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.3569 - mean_squared_error: 0.3569 - val_loss: 0.4897 - val_mean_squared_error: 0.4897\n",
      "Epoch 386/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3566 - mean_squared_error: 0.3566 - val_loss: 0.4893 - val_mean_squared_error: 0.4893\n",
      "Epoch 387/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3563 - mean_squared_error: 0.3563 - val_loss: 0.4888 - val_mean_squared_error: 0.4888\n",
      "Epoch 388/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3560 - mean_squared_error: 0.3560 - val_loss: 0.4883 - val_mean_squared_error: 0.4883\n",
      "Epoch 389/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3557 - mean_squared_error: 0.3557 - val_loss: 0.4878 - val_mean_squared_error: 0.4878\n",
      "Epoch 390/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3554 - mean_squared_error: 0.3554 - val_loss: 0.4874 - val_mean_squared_error: 0.4874\n",
      "Epoch 391/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3551 - mean_squared_error: 0.3551 - val_loss: 0.4869 - val_mean_squared_error: 0.4869\n",
      "Epoch 392/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3548 - mean_squared_error: 0.3548 - val_loss: 0.4864 - val_mean_squared_error: 0.4864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/700\n",
      "800/800 [==============================] - 0s 26us/sample - loss: 0.3545 - mean_squared_error: 0.3545 - val_loss: 0.4860 - val_mean_squared_error: 0.4860\n",
      "Epoch 394/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3542 - mean_squared_error: 0.3542 - val_loss: 0.4855 - val_mean_squared_error: 0.4855\n",
      "Epoch 395/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3539 - mean_squared_error: 0.3539 - val_loss: 0.4851 - val_mean_squared_error: 0.4851\n",
      "Epoch 396/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.3536 - mean_squared_error: 0.3536 - val_loss: 0.4846 - val_mean_squared_error: 0.4846\n",
      "Epoch 397/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.3533 - mean_squared_error: 0.3533 - val_loss: 0.4842 - val_mean_squared_error: 0.4842\n",
      "Epoch 398/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3530 - mean_squared_error: 0.3530 - val_loss: 0.4838 - val_mean_squared_error: 0.4838\n",
      "Epoch 399/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3527 - mean_squared_error: 0.3527 - val_loss: 0.4833 - val_mean_squared_error: 0.4833\n",
      "Epoch 400/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.3524 - mean_squared_error: 0.3524 - val_loss: 0.4829 - val_mean_squared_error: 0.4829\n",
      "Epoch 401/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3521 - mean_squared_error: 0.3521 - val_loss: 0.4825 - val_mean_squared_error: 0.4825\n",
      "Epoch 402/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3518 - mean_squared_error: 0.3518 - val_loss: 0.4820 - val_mean_squared_error: 0.4820\n",
      "Epoch 403/700\n",
      "800/800 [==============================] - 0s 40us/sample - loss: 0.3515 - mean_squared_error: 0.3515 - val_loss: 0.4816 - val_mean_squared_error: 0.4816\n",
      "Epoch 404/700\n",
      "800/800 [==============================] - 0s 44us/sample - loss: 0.3512 - mean_squared_error: 0.3512 - val_loss: 0.4812 - val_mean_squared_error: 0.4812\n",
      "Epoch 405/700\n",
      "800/800 [==============================] - 0s 41us/sample - loss: 0.3509 - mean_squared_error: 0.3509 - val_loss: 0.4808 - val_mean_squared_error: 0.4808\n",
      "Epoch 406/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3506 - mean_squared_error: 0.3506 - val_loss: 0.4804 - val_mean_squared_error: 0.4804\n",
      "Epoch 407/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3503 - mean_squared_error: 0.3503 - val_loss: 0.4800 - val_mean_squared_error: 0.4800\n",
      "Epoch 408/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.3500 - mean_squared_error: 0.3500 - val_loss: 0.4796 - val_mean_squared_error: 0.4796\n",
      "Epoch 409/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3497 - mean_squared_error: 0.3497 - val_loss: 0.4792 - val_mean_squared_error: 0.4792\n",
      "Epoch 410/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.3495 - mean_squared_error: 0.3495 - val_loss: 0.4788 - val_mean_squared_error: 0.4788\n",
      "Epoch 411/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.3492 - mean_squared_error: 0.3492 - val_loss: 0.4784 - val_mean_squared_error: 0.4784\n",
      "Epoch 412/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3489 - mean_squared_error: 0.3489 - val_loss: 0.4780 - val_mean_squared_error: 0.4780\n",
      "Epoch 413/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3486 - mean_squared_error: 0.3486 - val_loss: 0.4776 - val_mean_squared_error: 0.4776\n",
      "Epoch 414/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3483 - mean_squared_error: 0.3483 - val_loss: 0.4772 - val_mean_squared_error: 0.4772\n",
      "Epoch 415/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3480 - mean_squared_error: 0.3480 - val_loss: 0.4768 - val_mean_squared_error: 0.4768\n",
      "Epoch 416/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.3478 - mean_squared_error: 0.3478 - val_loss: 0.4765 - val_mean_squared_error: 0.4765\n",
      "Epoch 417/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3475 - mean_squared_error: 0.3475 - val_loss: 0.4761 - val_mean_squared_error: 0.4761\n",
      "Epoch 418/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3472 - mean_squared_error: 0.3472 - val_loss: 0.4757 - val_mean_squared_error: 0.4757\n",
      "Epoch 419/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3469 - mean_squared_error: 0.3469 - val_loss: 0.4753 - val_mean_squared_error: 0.4753\n",
      "Epoch 420/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.3466 - mean_squared_error: 0.3466 - val_loss: 0.4750 - val_mean_squared_error: 0.4750\n",
      "Epoch 421/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3464 - mean_squared_error: 0.3464 - val_loss: 0.4746 - val_mean_squared_error: 0.4746\n",
      "Epoch 422/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3461 - mean_squared_error: 0.3461 - val_loss: 0.4743 - val_mean_squared_error: 0.4743\n",
      "Epoch 423/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3458 - mean_squared_error: 0.3458 - val_loss: 0.4739 - val_mean_squared_error: 0.4739\n",
      "Epoch 424/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3455 - mean_squared_error: 0.3455 - val_loss: 0.4735 - val_mean_squared_error: 0.4735\n",
      "Epoch 425/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3453 - mean_squared_error: 0.3453 - val_loss: 0.4732 - val_mean_squared_error: 0.4732\n",
      "Epoch 426/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3450 - mean_squared_error: 0.3450 - val_loss: 0.4728 - val_mean_squared_error: 0.4728\n",
      "Epoch 427/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3447 - mean_squared_error: 0.3447 - val_loss: 0.4725 - val_mean_squared_error: 0.4725\n",
      "Epoch 428/700\n",
      "800/800 [==============================] - 0s 26us/sample - loss: 0.3445 - mean_squared_error: 0.3445 - val_loss: 0.4721 - val_mean_squared_error: 0.4721\n",
      "Epoch 429/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3442 - mean_squared_error: 0.3442 - val_loss: 0.4718 - val_mean_squared_error: 0.4718\n",
      "Epoch 430/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3439 - mean_squared_error: 0.3439 - val_loss: 0.4715 - val_mean_squared_error: 0.4715\n",
      "Epoch 431/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3437 - mean_squared_error: 0.3437 - val_loss: 0.4711 - val_mean_squared_error: 0.4711\n",
      "Epoch 432/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.3434 - mean_squared_error: 0.3434 - val_loss: 0.4708 - val_mean_squared_error: 0.4708\n",
      "Epoch 433/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.3431 - mean_squared_error: 0.3431 - val_loss: 0.4705 - val_mean_squared_error: 0.4705\n",
      "Epoch 434/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3429 - mean_squared_error: 0.3429 - val_loss: 0.4702 - val_mean_squared_error: 0.4702\n",
      "Epoch 435/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3426 - mean_squared_error: 0.3426 - val_loss: 0.4698 - val_mean_squared_error: 0.4698\n",
      "Epoch 436/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3424 - mean_squared_error: 0.3424 - val_loss: 0.4695 - val_mean_squared_error: 0.4695\n",
      "Epoch 437/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3421 - mean_squared_error: 0.3421 - val_loss: 0.4692 - val_mean_squared_error: 0.4692\n",
      "Epoch 438/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3418 - mean_squared_error: 0.3418 - val_loss: 0.4689 - val_mean_squared_error: 0.4689\n",
      "Epoch 439/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3416 - mean_squared_error: 0.3416 - val_loss: 0.4686 - val_mean_squared_error: 0.4686\n",
      "Epoch 440/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3413 - mean_squared_error: 0.3413 - val_loss: 0.4683 - val_mean_squared_error: 0.4683\n",
      "Epoch 441/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3411 - mean_squared_error: 0.3411 - val_loss: 0.4680 - val_mean_squared_error: 0.4680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3408 - mean_squared_error: 0.3408 - val_loss: 0.4677 - val_mean_squared_error: 0.4677\n",
      "Epoch 443/700\n",
      "800/800 [==============================] - 0s 26us/sample - loss: 0.3406 - mean_squared_error: 0.3406 - val_loss: 0.4674 - val_mean_squared_error: 0.4674\n",
      "Epoch 444/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.3403 - mean_squared_error: 0.3403 - val_loss: 0.4671 - val_mean_squared_error: 0.4671\n",
      "Epoch 445/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.3401 - mean_squared_error: 0.3401 - val_loss: 0.4668 - val_mean_squared_error: 0.4668\n",
      "Epoch 446/700\n",
      "800/800 [==============================] - 0s 27us/sample - loss: 0.3398 - mean_squared_error: 0.3398 - val_loss: 0.4665 - val_mean_squared_error: 0.4665\n",
      "Epoch 447/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.3396 - mean_squared_error: 0.3396 - val_loss: 0.4662 - val_mean_squared_error: 0.4662\n",
      "Epoch 448/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3393 - mean_squared_error: 0.3393 - val_loss: 0.4659 - val_mean_squared_error: 0.4659\n",
      "Epoch 449/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3391 - mean_squared_error: 0.3391 - val_loss: 0.4656 - val_mean_squared_error: 0.4656\n",
      "Epoch 450/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3388 - mean_squared_error: 0.3388 - val_loss: 0.4653 - val_mean_squared_error: 0.4653\n",
      "Epoch 451/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.3386 - mean_squared_error: 0.3386 - val_loss: 0.4651 - val_mean_squared_error: 0.4651\n",
      "Epoch 452/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3383 - mean_squared_error: 0.3383 - val_loss: 0.4648 - val_mean_squared_error: 0.4648\n",
      "Epoch 453/700\n",
      "800/800 [==============================] - 0s 26us/sample - loss: 0.3381 - mean_squared_error: 0.3381 - val_loss: 0.4645 - val_mean_squared_error: 0.4645\n",
      "Epoch 454/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3378 - mean_squared_error: 0.3378 - val_loss: 0.4642 - val_mean_squared_error: 0.4642\n",
      "Epoch 455/700\n",
      "800/800 [==============================] - 0s 28us/sample - loss: 0.3376 - mean_squared_error: 0.3376 - val_loss: 0.4640 - val_mean_squared_error: 0.4640\n",
      "Epoch 456/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.3374 - mean_squared_error: 0.3374 - val_loss: 0.4637 - val_mean_squared_error: 0.4637\n",
      "Epoch 457/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3371 - mean_squared_error: 0.3371 - val_loss: 0.4635 - val_mean_squared_error: 0.4635\n",
      "Epoch 458/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3369 - mean_squared_error: 0.3369 - val_loss: 0.4632 - val_mean_squared_error: 0.4632\n",
      "Epoch 459/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3366 - mean_squared_error: 0.3366 - val_loss: 0.4629 - val_mean_squared_error: 0.4629\n",
      "Epoch 460/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3364 - mean_squared_error: 0.3364 - val_loss: 0.4627 - val_mean_squared_error: 0.4627\n",
      "Epoch 461/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.3362 - mean_squared_error: 0.3362 - val_loss: 0.4625 - val_mean_squared_error: 0.4625\n",
      "Epoch 462/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.3359 - mean_squared_error: 0.3359 - val_loss: 0.4622 - val_mean_squared_error: 0.4622\n",
      "Epoch 463/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3357 - mean_squared_error: 0.3357 - val_loss: 0.4620 - val_mean_squared_error: 0.4620\n",
      "Epoch 464/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.3355 - mean_squared_error: 0.3355 - val_loss: 0.4617 - val_mean_squared_error: 0.4617\n",
      "Epoch 465/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3352 - mean_squared_error: 0.3352 - val_loss: 0.4615 - val_mean_squared_error: 0.4615\n",
      "Epoch 466/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3350 - mean_squared_error: 0.3350 - val_loss: 0.4613 - val_mean_squared_error: 0.4613\n",
      "Epoch 467/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3348 - mean_squared_error: 0.3348 - val_loss: 0.4610 - val_mean_squared_error: 0.4610\n",
      "Epoch 468/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3345 - mean_squared_error: 0.3345 - val_loss: 0.4608 - val_mean_squared_error: 0.4608\n",
      "Epoch 469/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3343 - mean_squared_error: 0.3343 - val_loss: 0.4606 - val_mean_squared_error: 0.4606\n",
      "Epoch 470/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3341 - mean_squared_error: 0.3341 - val_loss: 0.4604 - val_mean_squared_error: 0.4604\n",
      "Epoch 471/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3338 - mean_squared_error: 0.3338 - val_loss: 0.4601 - val_mean_squared_error: 0.4601\n",
      "Epoch 472/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3336 - mean_squared_error: 0.3336 - val_loss: 0.4599 - val_mean_squared_error: 0.4599\n",
      "Epoch 473/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3334 - mean_squared_error: 0.3334 - val_loss: 0.4597 - val_mean_squared_error: 0.4597\n",
      "Epoch 474/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3332 - mean_squared_error: 0.3332 - val_loss: 0.4595 - val_mean_squared_error: 0.4595\n",
      "Epoch 475/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3329 - mean_squared_error: 0.3329 - val_loss: 0.4593 - val_mean_squared_error: 0.4593\n",
      "Epoch 476/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3327 - mean_squared_error: 0.3327 - val_loss: 0.4590 - val_mean_squared_error: 0.4590\n",
      "Epoch 477/700\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 0.3325 - mean_squared_error: 0.3325 - val_loss: 0.4588 - val_mean_squared_error: 0.4588\n",
      "Epoch 478/700\n",
      "800/800 [==============================] - 0s 28us/sample - loss: 0.3323 - mean_squared_error: 0.3323 - val_loss: 0.4586 - val_mean_squared_error: 0.4586\n",
      "Epoch 479/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.3320 - mean_squared_error: 0.3320 - val_loss: 0.4584 - val_mean_squared_error: 0.4584\n",
      "Epoch 480/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3318 - mean_squared_error: 0.3318 - val_loss: 0.4582 - val_mean_squared_error: 0.4582\n",
      "Epoch 481/700\n",
      "800/800 [==============================] - 0s 14us/sample - loss: 0.3316 - mean_squared_error: 0.3316 - val_loss: 0.4580 - val_mean_squared_error: 0.4580\n",
      "Epoch 482/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3314 - mean_squared_error: 0.3314 - val_loss: 0.4578 - val_mean_squared_error: 0.4578\n",
      "Epoch 483/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3311 - mean_squared_error: 0.3311 - val_loss: 0.4576 - val_mean_squared_error: 0.4576\n",
      "Epoch 484/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3309 - mean_squared_error: 0.3309 - val_loss: 0.4574 - val_mean_squared_error: 0.4574\n",
      "Epoch 485/700\n",
      "800/800 [==============================] - 0s 14us/sample - loss: 0.3307 - mean_squared_error: 0.3307 - val_loss: 0.4572 - val_mean_squared_error: 0.4572\n",
      "Epoch 486/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3305 - mean_squared_error: 0.3305 - val_loss: 0.4570 - val_mean_squared_error: 0.4570\n",
      "Epoch 487/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3303 - mean_squared_error: 0.3303 - val_loss: 0.4568 - val_mean_squared_error: 0.4568\n",
      "Epoch 488/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3301 - mean_squared_error: 0.3301 - val_loss: 0.4567 - val_mean_squared_error: 0.4567\n",
      "Epoch 489/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.3298 - mean_squared_error: 0.3298 - val_loss: 0.4565 - val_mean_squared_error: 0.4565\n",
      "Epoch 490/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3296 - mean_squared_error: 0.3296 - val_loss: 0.4563 - val_mean_squared_error: 0.4563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3294 - mean_squared_error: 0.3294 - val_loss: 0.4561 - val_mean_squared_error: 0.4561\n",
      "Epoch 492/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3292 - mean_squared_error: 0.3292 - val_loss: 0.4559 - val_mean_squared_error: 0.4559\n",
      "Epoch 493/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3290 - mean_squared_error: 0.3290 - val_loss: 0.4557 - val_mean_squared_error: 0.4557\n",
      "Epoch 494/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.3288 - mean_squared_error: 0.3288 - val_loss: 0.4556 - val_mean_squared_error: 0.4556\n",
      "Epoch 495/700\n",
      "800/800 [==============================] - 0s 14us/sample - loss: 0.3285 - mean_squared_error: 0.3285 - val_loss: 0.4554 - val_mean_squared_error: 0.4554\n",
      "Epoch 496/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.3283 - mean_squared_error: 0.3283 - val_loss: 0.4552 - val_mean_squared_error: 0.4552\n",
      "Epoch 497/700\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 0.3281 - mean_squared_error: 0.3281 - val_loss: 0.4551 - val_mean_squared_error: 0.4551\n",
      "Epoch 498/700\n",
      "800/800 [==============================] - 0s 43us/sample - loss: 0.3279 - mean_squared_error: 0.3279 - val_loss: 0.4549 - val_mean_squared_error: 0.4549\n",
      "Epoch 499/700\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 0.3277 - mean_squared_error: 0.3277 - val_loss: 0.4547 - val_mean_squared_error: 0.4547\n",
      "Epoch 500/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3275 - mean_squared_error: 0.3275 - val_loss: 0.4546 - val_mean_squared_error: 0.4546\n",
      "Epoch 501/700\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 0.3273 - mean_squared_error: 0.3273 - val_loss: 0.4544 - val_mean_squared_error: 0.4544\n",
      "Epoch 502/700\n",
      "800/800 [==============================] - 0s 25us/sample - loss: 0.3271 - mean_squared_error: 0.3271 - val_loss: 0.4542 - val_mean_squared_error: 0.4542\n",
      "Epoch 503/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3269 - mean_squared_error: 0.3269 - val_loss: 0.4541 - val_mean_squared_error: 0.4541\n",
      "Epoch 504/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3267 - mean_squared_error: 0.3267 - val_loss: 0.4539 - val_mean_squared_error: 0.4539\n",
      "Epoch 505/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3265 - mean_squared_error: 0.3265 - val_loss: 0.4538 - val_mean_squared_error: 0.4538\n",
      "Epoch 506/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.3262 - mean_squared_error: 0.3262 - val_loss: 0.4536 - val_mean_squared_error: 0.4536\n",
      "Epoch 507/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3260 - mean_squared_error: 0.3260 - val_loss: 0.4534 - val_mean_squared_error: 0.4534\n",
      "Epoch 508/700\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.3258 - mean_squared_error: 0.3258 - val_loss: 0.4533 - val_mean_squared_error: 0.4533\n",
      "Epoch 509/700\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.3256 - mean_squared_error: 0.3256 - val_loss: 0.4531 - val_mean_squared_error: 0.4531\n",
      "Epoch 510/700\n",
      "800/800 [==============================] - 0s 38us/sample - loss: 0.3254 - mean_squared_error: 0.3254 - val_loss: 0.4530 - val_mean_squared_error: 0.4530\n",
      "Epoch 511/700\n",
      "800/800 [==============================] - 0s 40us/sample - loss: 0.3252 - mean_squared_error: 0.3252 - val_loss: 0.4528 - val_mean_squared_error: 0.4528\n",
      "Epoch 512/700\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.3250 - mean_squared_error: 0.3250 - val_loss: 0.4527 - val_mean_squared_error: 0.4527\n",
      "Epoch 513/700\n",
      "800/800 [==============================] - 0s 26us/sample - loss: 0.3248 - mean_squared_error: 0.3248 - val_loss: 0.4525 - val_mean_squared_error: 0.4525\n",
      "Epoch 514/700\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.3246 - mean_squared_error: 0.3246 - val_loss: 0.4524 - val_mean_squared_error: 0.4524\n",
      "Epoch 515/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.3244 - mean_squared_error: 0.3244 - val_loss: 0.4522 - val_mean_squared_error: 0.4522\n",
      "Epoch 516/700\n",
      "800/800 [==============================] - 0s 27us/sample - loss: 0.3242 - mean_squared_error: 0.3242 - val_loss: 0.4521 - val_mean_squared_error: 0.4521\n",
      "Epoch 517/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.3240 - mean_squared_error: 0.3240 - val_loss: 0.4520 - val_mean_squared_error: 0.4520\n",
      "Epoch 518/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3238 - mean_squared_error: 0.3238 - val_loss: 0.4518 - val_mean_squared_error: 0.4518\n",
      "Epoch 519/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3236 - mean_squared_error: 0.3236 - val_loss: 0.4517 - val_mean_squared_error: 0.4517\n",
      "Epoch 520/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3234 - mean_squared_error: 0.3234 - val_loss: 0.4515 - val_mean_squared_error: 0.4515\n",
      "Epoch 521/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3232 - mean_squared_error: 0.3232 - val_loss: 0.4514 - val_mean_squared_error: 0.4514\n",
      "Epoch 522/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.3230 - mean_squared_error: 0.3230 - val_loss: 0.4512 - val_mean_squared_error: 0.4512\n",
      "Epoch 523/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3228 - mean_squared_error: 0.3228 - val_loss: 0.4511 - val_mean_squared_error: 0.4511\n",
      "Epoch 524/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3226 - mean_squared_error: 0.3226 - val_loss: 0.4509 - val_mean_squared_error: 0.4509\n",
      "Epoch 525/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3224 - mean_squared_error: 0.3224 - val_loss: 0.4508 - val_mean_squared_error: 0.4508\n",
      "Epoch 526/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3222 - mean_squared_error: 0.3222 - val_loss: 0.4507 - val_mean_squared_error: 0.4507\n",
      "Epoch 527/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3220 - mean_squared_error: 0.3220 - val_loss: 0.4505 - val_mean_squared_error: 0.4505\n",
      "Epoch 528/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3218 - mean_squared_error: 0.3218 - val_loss: 0.4504 - val_mean_squared_error: 0.4504\n",
      "Epoch 529/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3216 - mean_squared_error: 0.3216 - val_loss: 0.4503 - val_mean_squared_error: 0.4503\n",
      "Epoch 530/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3214 - mean_squared_error: 0.3214 - val_loss: 0.4501 - val_mean_squared_error: 0.4501\n",
      "Epoch 531/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3213 - mean_squared_error: 0.3213 - val_loss: 0.4500 - val_mean_squared_error: 0.4500\n",
      "Epoch 532/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3211 - mean_squared_error: 0.3211 - val_loss: 0.4499 - val_mean_squared_error: 0.4499\n",
      "Epoch 533/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3209 - mean_squared_error: 0.3209 - val_loss: 0.4497 - val_mean_squared_error: 0.4497\n",
      "Epoch 534/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3207 - mean_squared_error: 0.3207 - val_loss: 0.4496 - val_mean_squared_error: 0.4496\n",
      "Epoch 535/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3205 - mean_squared_error: 0.3205 - val_loss: 0.4495 - val_mean_squared_error: 0.4495\n",
      "Epoch 536/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3203 - mean_squared_error: 0.3203 - val_loss: 0.4494 - val_mean_squared_error: 0.4494\n",
      "Epoch 537/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3201 - mean_squared_error: 0.3201 - val_loss: 0.4492 - val_mean_squared_error: 0.4492\n",
      "Epoch 538/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3199 - mean_squared_error: 0.3199 - val_loss: 0.4491 - val_mean_squared_error: 0.4491\n",
      "Epoch 539/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.3197 - mean_squared_error: 0.3197 - val_loss: 0.4490 - val_mean_squared_error: 0.4490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 540/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3195 - mean_squared_error: 0.3195 - val_loss: 0.4488 - val_mean_squared_error: 0.4488\n",
      "Epoch 541/700\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 0.3193 - mean_squared_error: 0.3193 - val_loss: 0.4487 - val_mean_squared_error: 0.4487\n",
      "Epoch 542/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3191 - mean_squared_error: 0.3191 - val_loss: 0.4486 - val_mean_squared_error: 0.4486\n",
      "Epoch 543/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3190 - mean_squared_error: 0.3190 - val_loss: 0.4485 - val_mean_squared_error: 0.4485\n",
      "Epoch 544/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3188 - mean_squared_error: 0.3188 - val_loss: 0.4483 - val_mean_squared_error: 0.4483\n",
      "Epoch 545/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3186 - mean_squared_error: 0.3186 - val_loss: 0.4482 - val_mean_squared_error: 0.4482\n",
      "Epoch 546/700\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 0.3184 - mean_squared_error: 0.3184 - val_loss: 0.4481 - val_mean_squared_error: 0.4481\n",
      "Epoch 547/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.3182 - mean_squared_error: 0.3182 - val_loss: 0.4479 - val_mean_squared_error: 0.4479\n",
      "Epoch 548/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3180 - mean_squared_error: 0.3180 - val_loss: 0.4478 - val_mean_squared_error: 0.4478\n",
      "Epoch 549/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3178 - mean_squared_error: 0.3178 - val_loss: 0.4477 - val_mean_squared_error: 0.4477\n",
      "Epoch 550/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3176 - mean_squared_error: 0.3176 - val_loss: 0.4476 - val_mean_squared_error: 0.4476\n",
      "Epoch 551/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3175 - mean_squared_error: 0.3175 - val_loss: 0.4475 - val_mean_squared_error: 0.4475\n",
      "Epoch 552/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3173 - mean_squared_error: 0.3173 - val_loss: 0.4473 - val_mean_squared_error: 0.4473\n",
      "Epoch 553/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3171 - mean_squared_error: 0.3171 - val_loss: 0.4472 - val_mean_squared_error: 0.4472\n",
      "Epoch 554/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3169 - mean_squared_error: 0.3169 - val_loss: 0.4471 - val_mean_squared_error: 0.4471\n",
      "Epoch 555/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3167 - mean_squared_error: 0.3167 - val_loss: 0.4470 - val_mean_squared_error: 0.4470\n",
      "Epoch 556/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.3165 - mean_squared_error: 0.3165 - val_loss: 0.4469 - val_mean_squared_error: 0.4469\n",
      "Epoch 557/700\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 0.3163 - mean_squared_error: 0.3163 - val_loss: 0.4468 - val_mean_squared_error: 0.4468\n",
      "Epoch 558/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.3162 - mean_squared_error: 0.3162 - val_loss: 0.4466 - val_mean_squared_error: 0.4466\n",
      "Epoch 559/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.3160 - mean_squared_error: 0.3160 - val_loss: 0.4465 - val_mean_squared_error: 0.4465\n",
      "Epoch 560/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3158 - mean_squared_error: 0.3158 - val_loss: 0.4464 - val_mean_squared_error: 0.4464\n",
      "Epoch 561/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3156 - mean_squared_error: 0.3156 - val_loss: 0.4463 - val_mean_squared_error: 0.4463\n",
      "Epoch 562/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3154 - mean_squared_error: 0.3154 - val_loss: 0.4462 - val_mean_squared_error: 0.4462\n",
      "Epoch 563/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3152 - mean_squared_error: 0.3152 - val_loss: 0.4461 - val_mean_squared_error: 0.4461\n",
      "Epoch 564/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3151 - mean_squared_error: 0.3151 - val_loss: 0.4460 - val_mean_squared_error: 0.4460\n",
      "Epoch 565/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3149 - mean_squared_error: 0.3149 - val_loss: 0.4459 - val_mean_squared_error: 0.4459\n",
      "Epoch 566/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3147 - mean_squared_error: 0.3147 - val_loss: 0.4458 - val_mean_squared_error: 0.4458\n",
      "Epoch 567/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3145 - mean_squared_error: 0.3145 - val_loss: 0.4457 - val_mean_squared_error: 0.4457\n",
      "Epoch 568/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3143 - mean_squared_error: 0.3143 - val_loss: 0.4456 - val_mean_squared_error: 0.4456\n",
      "Epoch 569/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3142 - mean_squared_error: 0.3142 - val_loss: 0.4455 - val_mean_squared_error: 0.4455\n",
      "Epoch 570/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3140 - mean_squared_error: 0.3140 - val_loss: 0.4454 - val_mean_squared_error: 0.4454\n",
      "Epoch 571/700\n",
      "800/800 [==============================] - 0s 26us/sample - loss: 0.3138 - mean_squared_error: 0.3138 - val_loss: 0.4453 - val_mean_squared_error: 0.4453\n",
      "Epoch 572/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3136 - mean_squared_error: 0.3136 - val_loss: 0.4452 - val_mean_squared_error: 0.4452\n",
      "Epoch 573/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3134 - mean_squared_error: 0.3134 - val_loss: 0.4451 - val_mean_squared_error: 0.4451\n",
      "Epoch 574/700\n",
      "800/800 [==============================] - 0s 27us/sample - loss: 0.3133 - mean_squared_error: 0.3133 - val_loss: 0.4450 - val_mean_squared_error: 0.4450\n",
      "Epoch 575/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3131 - mean_squared_error: 0.3131 - val_loss: 0.4449 - val_mean_squared_error: 0.4449\n",
      "Epoch 576/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3129 - mean_squared_error: 0.3129 - val_loss: 0.4448 - val_mean_squared_error: 0.4448\n",
      "Epoch 577/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3127 - mean_squared_error: 0.3127 - val_loss: 0.4447 - val_mean_squared_error: 0.4447\n",
      "Epoch 578/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3125 - mean_squared_error: 0.3125 - val_loss: 0.4446 - val_mean_squared_error: 0.4446\n",
      "Epoch 579/700\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.3124 - mean_squared_error: 0.3124 - val_loss: 0.4445 - val_mean_squared_error: 0.4445\n",
      "Epoch 580/700\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.3122 - mean_squared_error: 0.3122 - val_loss: 0.4444 - val_mean_squared_error: 0.4444\n",
      "Epoch 581/700\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 0.3120 - mean_squared_error: 0.3120 - val_loss: 0.4443 - val_mean_squared_error: 0.4443\n",
      "Epoch 582/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3118 - mean_squared_error: 0.3118 - val_loss: 0.4442 - val_mean_squared_error: 0.4442\n",
      "Epoch 583/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.3117 - mean_squared_error: 0.3117 - val_loss: 0.4441 - val_mean_squared_error: 0.4441\n",
      "Epoch 584/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3115 - mean_squared_error: 0.3115 - val_loss: 0.4440 - val_mean_squared_error: 0.4440\n",
      "Epoch 585/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3113 - mean_squared_error: 0.3113 - val_loss: 0.4439 - val_mean_squared_error: 0.4439\n",
      "Epoch 586/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.3111 - mean_squared_error: 0.3111 - val_loss: 0.4438 - val_mean_squared_error: 0.4438\n",
      "Epoch 587/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.3110 - mean_squared_error: 0.3110 - val_loss: 0.4437 - val_mean_squared_error: 0.4437\n",
      "Epoch 588/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3108 - mean_squared_error: 0.3108 - val_loss: 0.4436 - val_mean_squared_error: 0.4436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 589/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3106 - mean_squared_error: 0.3106 - val_loss: 0.4435 - val_mean_squared_error: 0.4435\n",
      "Epoch 590/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3104 - mean_squared_error: 0.3104 - val_loss: 0.4434 - val_mean_squared_error: 0.4434\n",
      "Epoch 591/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3102 - mean_squared_error: 0.3102 - val_loss: 0.4434 - val_mean_squared_error: 0.4434\n",
      "Epoch 592/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3101 - mean_squared_error: 0.3101 - val_loss: 0.4433 - val_mean_squared_error: 0.4433\n",
      "Epoch 593/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3099 - mean_squared_error: 0.3099 - val_loss: 0.4432 - val_mean_squared_error: 0.4432\n",
      "Epoch 594/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3097 - mean_squared_error: 0.3097 - val_loss: 0.4431 - val_mean_squared_error: 0.4431\n",
      "Epoch 595/700\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 0.3096 - mean_squared_error: 0.3096 - val_loss: 0.4430 - val_mean_squared_error: 0.4430\n",
      "Epoch 596/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3094 - mean_squared_error: 0.3094 - val_loss: 0.4429 - val_mean_squared_error: 0.4429\n",
      "Epoch 597/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3092 - mean_squared_error: 0.3092 - val_loss: 0.4428 - val_mean_squared_error: 0.4428\n",
      "Epoch 598/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3090 - mean_squared_error: 0.3090 - val_loss: 0.4428 - val_mean_squared_error: 0.4428\n",
      "Epoch 599/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.3089 - mean_squared_error: 0.3089 - val_loss: 0.4427 - val_mean_squared_error: 0.4427\n",
      "Epoch 600/700\n",
      "800/800 [==============================] - 0s 27us/sample - loss: 0.3087 - mean_squared_error: 0.3087 - val_loss: 0.4426 - val_mean_squared_error: 0.4426\n",
      "Epoch 601/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.3085 - mean_squared_error: 0.3085 - val_loss: 0.4425 - val_mean_squared_error: 0.4425\n",
      "Epoch 602/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.3083 - mean_squared_error: 0.3083 - val_loss: 0.4424 - val_mean_squared_error: 0.4424\n",
      "Epoch 603/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.3082 - mean_squared_error: 0.3082 - val_loss: 0.4423 - val_mean_squared_error: 0.4423\n",
      "Epoch 604/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3080 - mean_squared_error: 0.3080 - val_loss: 0.4423 - val_mean_squared_error: 0.4423\n",
      "Epoch 605/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.3078 - mean_squared_error: 0.3078 - val_loss: 0.4422 - val_mean_squared_error: 0.4422\n",
      "Epoch 606/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3076 - mean_squared_error: 0.3076 - val_loss: 0.4421 - val_mean_squared_error: 0.4421\n",
      "Epoch 607/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3075 - mean_squared_error: 0.3075 - val_loss: 0.4420 - val_mean_squared_error: 0.4420\n",
      "Epoch 608/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3073 - mean_squared_error: 0.3073 - val_loss: 0.4419 - val_mean_squared_error: 0.4419\n",
      "Epoch 609/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3071 - mean_squared_error: 0.3071 - val_loss: 0.4419 - val_mean_squared_error: 0.4419\n",
      "Epoch 610/700\n",
      "800/800 [==============================] - 0s 14us/sample - loss: 0.3070 - mean_squared_error: 0.3070 - val_loss: 0.4418 - val_mean_squared_error: 0.4418\n",
      "Epoch 611/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3068 - mean_squared_error: 0.3068 - val_loss: 0.4417 - val_mean_squared_error: 0.4417\n",
      "Epoch 612/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3066 - mean_squared_error: 0.3066 - val_loss: 0.4416 - val_mean_squared_error: 0.4416\n",
      "Epoch 613/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3064 - mean_squared_error: 0.3064 - val_loss: 0.4415 - val_mean_squared_error: 0.4415\n",
      "Epoch 614/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3063 - mean_squared_error: 0.3063 - val_loss: 0.4415 - val_mean_squared_error: 0.4415\n",
      "Epoch 615/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.3061 - mean_squared_error: 0.3061 - val_loss: 0.4414 - val_mean_squared_error: 0.4414\n",
      "Epoch 616/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.3059 - mean_squared_error: 0.3059 - val_loss: 0.4413 - val_mean_squared_error: 0.4413\n",
      "Epoch 617/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.3057 - mean_squared_error: 0.3057 - val_loss: 0.4412 - val_mean_squared_error: 0.4412\n",
      "Epoch 618/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.3056 - mean_squared_error: 0.3056 - val_loss: 0.4412 - val_mean_squared_error: 0.4412\n",
      "Epoch 619/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3054 - mean_squared_error: 0.3054 - val_loss: 0.4411 - val_mean_squared_error: 0.4411\n",
      "Epoch 620/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3052 - mean_squared_error: 0.3052 - val_loss: 0.4410 - val_mean_squared_error: 0.4410\n",
      "Epoch 621/700\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.3051 - mean_squared_error: 0.3051 - val_loss: 0.4409 - val_mean_squared_error: 0.4409\n",
      "Epoch 622/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - val_loss: 0.4408 - val_mean_squared_error: 0.4408\n",
      "Epoch 623/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3047 - mean_squared_error: 0.3047 - val_loss: 0.4408 - val_mean_squared_error: 0.4408\n",
      "Epoch 624/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3046 - mean_squared_error: 0.3046 - val_loss: 0.4407 - val_mean_squared_error: 0.4407\n",
      "Epoch 625/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3044 - mean_squared_error: 0.3044 - val_loss: 0.4406 - val_mean_squared_error: 0.4406\n",
      "Epoch 626/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3042 - mean_squared_error: 0.3042 - val_loss: 0.4405 - val_mean_squared_error: 0.4405\n",
      "Epoch 627/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3040 - mean_squared_error: 0.3040 - val_loss: 0.4404 - val_mean_squared_error: 0.4404\n",
      "Epoch 628/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3039 - mean_squared_error: 0.3039 - val_loss: 0.4403 - val_mean_squared_error: 0.4403\n",
      "Epoch 629/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3037 - mean_squared_error: 0.3037 - val_loss: 0.4402 - val_mean_squared_error: 0.4402\n",
      "Epoch 630/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3035 - mean_squared_error: 0.3035 - val_loss: 0.4402 - val_mean_squared_error: 0.4402\n",
      "Epoch 631/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3034 - mean_squared_error: 0.3034 - val_loss: 0.4401 - val_mean_squared_error: 0.4401\n",
      "Epoch 632/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3032 - mean_squared_error: 0.3032 - val_loss: 0.4400 - val_mean_squared_error: 0.4400\n",
      "Epoch 633/700\n",
      "800/800 [==============================] - 0s 14us/sample - loss: 0.3030 - mean_squared_error: 0.3030 - val_loss: 0.4399 - val_mean_squared_error: 0.4399\n",
      "Epoch 634/700\n",
      "800/800 [==============================] - 0s 14us/sample - loss: 0.3029 - mean_squared_error: 0.3029 - val_loss: 0.4398 - val_mean_squared_error: 0.4398\n",
      "Epoch 635/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3027 - mean_squared_error: 0.3027 - val_loss: 0.4397 - val_mean_squared_error: 0.4397\n",
      "Epoch 636/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3025 - mean_squared_error: 0.3025 - val_loss: 0.4397 - val_mean_squared_error: 0.4397\n",
      "Epoch 637/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3023 - mean_squared_error: 0.3023 - val_loss: 0.4396 - val_mean_squared_error: 0.4396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 638/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3022 - mean_squared_error: 0.3022 - val_loss: 0.4395 - val_mean_squared_error: 0.4395\n",
      "Epoch 639/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3020 - mean_squared_error: 0.3020 - val_loss: 0.4394 - val_mean_squared_error: 0.4394\n",
      "Epoch 640/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3018 - mean_squared_error: 0.3018 - val_loss: 0.4393 - val_mean_squared_error: 0.4393\n",
      "Epoch 641/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.3017 - mean_squared_error: 0.3017 - val_loss: 0.4392 - val_mean_squared_error: 0.4392\n",
      "Epoch 642/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3015 - mean_squared_error: 0.3015 - val_loss: 0.4392 - val_mean_squared_error: 0.4392\n",
      "Epoch 643/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.3013 - mean_squared_error: 0.3013 - val_loss: 0.4391 - val_mean_squared_error: 0.4391\n",
      "Epoch 644/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.3012 - mean_squared_error: 0.3012 - val_loss: 0.4390 - val_mean_squared_error: 0.4390\n",
      "Epoch 645/700\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 0.3010 - mean_squared_error: 0.3010 - val_loss: 0.4389 - val_mean_squared_error: 0.4389\n",
      "Epoch 646/700\n",
      "800/800 [==============================] - 0s 27us/sample - loss: 0.3008 - mean_squared_error: 0.3008 - val_loss: 0.4388 - val_mean_squared_error: 0.4388\n",
      "Epoch 647/700\n",
      "800/800 [==============================] - 0s 26us/sample - loss: 0.3007 - mean_squared_error: 0.3007 - val_loss: 0.4387 - val_mean_squared_error: 0.4387\n",
      "Epoch 648/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.3005 - mean_squared_error: 0.3005 - val_loss: 0.4387 - val_mean_squared_error: 0.4387\n",
      "Epoch 649/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.3003 - mean_squared_error: 0.3003 - val_loss: 0.4386 - val_mean_squared_error: 0.4386\n",
      "Epoch 650/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.3002 - mean_squared_error: 0.3002 - val_loss: 0.4385 - val_mean_squared_error: 0.4385\n",
      "Epoch 651/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.3000 - mean_squared_error: 0.3000 - val_loss: 0.4384 - val_mean_squared_error: 0.4384\n",
      "Epoch 652/700\n",
      "800/800 [==============================] - 0s 14us/sample - loss: 0.2998 - mean_squared_error: 0.2998 - val_loss: 0.4383 - val_mean_squared_error: 0.4383\n",
      "Epoch 653/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.2997 - mean_squared_error: 0.2997 - val_loss: 0.4383 - val_mean_squared_error: 0.4383\n",
      "Epoch 654/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.2995 - mean_squared_error: 0.2995 - val_loss: 0.4382 - val_mean_squared_error: 0.4382\n",
      "Epoch 655/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.2993 - mean_squared_error: 0.2993 - val_loss: 0.4381 - val_mean_squared_error: 0.4381\n",
      "Epoch 656/700\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.2992 - mean_squared_error: 0.2992 - val_loss: 0.4380 - val_mean_squared_error: 0.4380\n",
      "Epoch 657/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.2990 - mean_squared_error: 0.2990 - val_loss: 0.4380 - val_mean_squared_error: 0.4380\n",
      "Epoch 658/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.2988 - mean_squared_error: 0.2988 - val_loss: 0.4379 - val_mean_squared_error: 0.4379\n",
      "Epoch 659/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.2987 - mean_squared_error: 0.2987 - val_loss: 0.4378 - val_mean_squared_error: 0.4378\n",
      "Epoch 660/700\n",
      "800/800 [==============================] - 0s 18us/sample - loss: 0.2985 - mean_squared_error: 0.2985 - val_loss: 0.4377 - val_mean_squared_error: 0.4377\n",
      "Epoch 661/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.2983 - mean_squared_error: 0.2983 - val_loss: 0.4377 - val_mean_squared_error: 0.4377\n",
      "Epoch 662/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.2981 - mean_squared_error: 0.2981 - val_loss: 0.4376 - val_mean_squared_error: 0.4376\n",
      "Epoch 663/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.2980 - mean_squared_error: 0.2980 - val_loss: 0.4375 - val_mean_squared_error: 0.4375\n",
      "Epoch 664/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.2978 - mean_squared_error: 0.2978 - val_loss: 0.4374 - val_mean_squared_error: 0.4374\n",
      "Epoch 665/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.2976 - mean_squared_error: 0.2976 - val_loss: 0.4374 - val_mean_squared_error: 0.4374\n",
      "Epoch 666/700\n",
      "800/800 [==============================] - 0s 38us/sample - loss: 0.2975 - mean_squared_error: 0.2975 - val_loss: 0.4373 - val_mean_squared_error: 0.4373\n",
      "Epoch 667/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.2973 - mean_squared_error: 0.2973 - val_loss: 0.4372 - val_mean_squared_error: 0.4372\n",
      "Epoch 668/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.2971 - mean_squared_error: 0.2971 - val_loss: 0.4372 - val_mean_squared_error: 0.4372\n",
      "Epoch 669/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.2970 - mean_squared_error: 0.2970 - val_loss: 0.4371 - val_mean_squared_error: 0.4371\n",
      "Epoch 670/700\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 0.2968 - mean_squared_error: 0.2968 - val_loss: 0.4370 - val_mean_squared_error: 0.4370\n",
      "Epoch 671/700\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.2966 - mean_squared_error: 0.2966 - val_loss: 0.4370 - val_mean_squared_error: 0.4370\n",
      "Epoch 672/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.2965 - mean_squared_error: 0.2965 - val_loss: 0.4369 - val_mean_squared_error: 0.4369\n",
      "Epoch 673/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.2963 - mean_squared_error: 0.2963 - val_loss: 0.4368 - val_mean_squared_error: 0.4368\n",
      "Epoch 674/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.2961 - mean_squared_error: 0.2961 - val_loss: 0.4368 - val_mean_squared_error: 0.4368\n",
      "Epoch 675/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.2960 - mean_squared_error: 0.2960 - val_loss: 0.4367 - val_mean_squared_error: 0.4367\n",
      "Epoch 676/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.2958 - mean_squared_error: 0.2958 - val_loss: 0.4366 - val_mean_squared_error: 0.4366\n",
      "Epoch 677/700\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.2956 - mean_squared_error: 0.2956 - val_loss: 0.4366 - val_mean_squared_error: 0.4366\n",
      "Epoch 678/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.2955 - mean_squared_error: 0.2955 - val_loss: 0.4365 - val_mean_squared_error: 0.4365\n",
      "Epoch 679/700\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 0.2953 - mean_squared_error: 0.2953 - val_loss: 0.4364 - val_mean_squared_error: 0.4364\n",
      "Epoch 680/700\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 0.2951 - mean_squared_error: 0.2951 - val_loss: 0.4364 - val_mean_squared_error: 0.4364\n",
      "Epoch 681/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.2950 - mean_squared_error: 0.2950 - val_loss: 0.4363 - val_mean_squared_error: 0.4363\n",
      "Epoch 682/700\n",
      "800/800 [==============================] - 0s 23us/sample - loss: 0.2948 - mean_squared_error: 0.2948 - val_loss: 0.4362 - val_mean_squared_error: 0.4362\n",
      "Epoch 683/700\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 0.2946 - mean_squared_error: 0.2946 - val_loss: 0.4362 - val_mean_squared_error: 0.4362\n",
      "Epoch 684/700\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 0.2945 - mean_squared_error: 0.2945 - val_loss: 0.4361 - val_mean_squared_error: 0.4361\n",
      "Epoch 685/700\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 0.2943 - mean_squared_error: 0.2943 - val_loss: 0.4360 - val_mean_squared_error: 0.4360\n",
      "Epoch 686/700\n",
      "800/800 [==============================] - 0s 38us/sample - loss: 0.2941 - mean_squared_error: 0.2941 - val_loss: 0.4359 - val_mean_squared_error: 0.4359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 687/700\n",
      "800/800 [==============================] - 0s 26us/sample - loss: 0.2940 - mean_squared_error: 0.2940 - val_loss: 0.4359 - val_mean_squared_error: 0.4359\n",
      "Epoch 688/700\n",
      "800/800 [==============================] - 0s 24us/sample - loss: 0.2938 - mean_squared_error: 0.2938 - val_loss: 0.4358 - val_mean_squared_error: 0.4358\n",
      "Epoch 689/700\n",
      "800/800 [==============================] - 0s 26us/sample - loss: 0.2937 - mean_squared_error: 0.2937 - val_loss: 0.4357 - val_mean_squared_error: 0.4357\n",
      "Epoch 690/700\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 0.2935 - mean_squared_error: 0.2935 - val_loss: 0.4356 - val_mean_squared_error: 0.4356\n",
      "Epoch 691/700\n",
      "800/800 [==============================] - 0s 26us/sample - loss: 0.2933 - mean_squared_error: 0.2933 - val_loss: 0.4356 - val_mean_squared_error: 0.4356\n",
      "Epoch 692/700\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.2932 - mean_squared_error: 0.2932 - val_loss: 0.4355 - val_mean_squared_error: 0.4355\n",
      "Epoch 693/700\n",
      "800/800 [==============================] - 0s 25us/sample - loss: 0.2930 - mean_squared_error: 0.2930 - val_loss: 0.4354 - val_mean_squared_error: 0.4354\n",
      "Epoch 694/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.2928 - mean_squared_error: 0.2928 - val_loss: 0.4353 - val_mean_squared_error: 0.4353\n",
      "Epoch 695/700\n",
      "800/800 [==============================] - 0s 21us/sample - loss: 0.2927 - mean_squared_error: 0.2927 - val_loss: 0.4353 - val_mean_squared_error: 0.4353\n",
      "Epoch 696/700\n",
      "800/800 [==============================] - 0s 20us/sample - loss: 0.2925 - mean_squared_error: 0.2925 - val_loss: 0.4352 - val_mean_squared_error: 0.4352\n",
      "Epoch 697/700\n",
      "800/800 [==============================] - 0s 17us/sample - loss: 0.2923 - mean_squared_error: 0.2923 - val_loss: 0.4351 - val_mean_squared_error: 0.4351\n",
      "Epoch 698/700\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.2922 - mean_squared_error: 0.2922 - val_loss: 0.4351 - val_mean_squared_error: 0.4351\n",
      "Epoch 699/700\n",
      "800/800 [==============================] - 0s 27us/sample - loss: 0.2920 - mean_squared_error: 0.2920 - val_loss: 0.4350 - val_mean_squared_error: 0.4350\n",
      "Epoch 700/700\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 0.2918 - mean_squared_error: 0.2918 - val_loss: 0.4349 - val_mean_squared_error: 0.4349\n",
      "CPU times: user 19.2 s, sys: 542 ms, total: 19.7 s\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_epochs = 700\n",
    "model.fit(x=train_df[feature_cols].values, \n",
    "          y=train_df[feature_cols].values,  \n",
    "          epochs=num_epochs,\n",
    "          validation_data=(valid_df[feature_cols].values, \n",
    "                           valid_df[feature_cols].values),\n",
    "          batch_size=800\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 30ms/sample - loss: 0.3731 - mean_squared_error: 0.3731\n",
      "7/7 [==============================] - 0s 229us/sample - loss: 1.7795 - mean_squared_error: 1.7795\n",
      "Average loss on the eval set:\t 0.3731\n",
      "Average loss on fraud set:\t 1.7795\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = compute_reconstruction_loss(model, eval_df)\n",
    "model_fraud = compute_reconstruction_loss(model, fraud_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the reconstruction losses from baseline and autoencoder model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>autoencoder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.233120</td>\n",
       "      <td>0.070637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.934373</td>\n",
       "      <td>0.969130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.317213</td>\n",
       "      <td>0.325807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.300937</td>\n",
       "      <td>0.422348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.822465</td>\n",
       "      <td>0.504984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.109636</td>\n",
       "      <td>0.090340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.155583</td>\n",
       "      <td>0.228394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   baseline  autoencoder\n",
       "0  0.233120     0.070637\n",
       "1  0.934373     0.969130\n",
       "2  0.317213     0.325807\n",
       "3  0.300937     0.422348\n",
       "4  0.822465     0.504984\n",
       "5  0.109636     0.090340\n",
       "6  0.155583     0.228394"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_eval = pd.concat([\n",
    "    baseline_eval,\n",
    "    model_eval\n",
    "],\n",
    "axis=1)\n",
    "\n",
    "loss_eval.columns = [\"baseline\", \"autoencoder\"]\n",
    "\n",
    "loss_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>autoencoder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.410475</td>\n",
       "      <td>0.373091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.329604</td>\n",
       "      <td>0.308135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.109636</td>\n",
       "      <td>0.070637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.194351</td>\n",
       "      <td>0.159367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.300937</td>\n",
       "      <td>0.325807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.569839</td>\n",
       "      <td>0.463666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.934373</td>\n",
       "      <td>0.969130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       baseline  autoencoder\n",
       "count  7.000000     7.000000\n",
       "mean   0.410475     0.373091\n",
       "std    0.329604     0.308135\n",
       "min    0.109636     0.070637\n",
       "25%    0.194351     0.159367\n",
       "50%    0.300937     0.325807\n",
       "75%    0.569839     0.463666\n",
       "max    0.934373     0.969130"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_eval.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>autoencoder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.129046</td>\n",
       "      <td>0.784801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.364508</td>\n",
       "      <td>0.811793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.320477</td>\n",
       "      <td>2.932226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.801669</td>\n",
       "      <td>2.125167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330132</td>\n",
       "      <td>0.578325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.395267</td>\n",
       "      <td>1.461898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.049002</td>\n",
       "      <td>3.761956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   baseline  autoencoder\n",
       "0  1.129046     0.784801\n",
       "1  0.364508     0.811793\n",
       "2  2.320477     2.932226\n",
       "3  1.801669     2.125167\n",
       "4  0.330132     0.578325\n",
       "5  1.395267     1.461898\n",
       "6  3.049002     3.761956"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fraud = pd.concat([\n",
    "    baseline_fraud,\n",
    "    model_fraud\n",
    "],\n",
    "axis=1)\n",
    "\n",
    "loss_fraud.columns = [\"baseline\", \"autoencoder\"]\n",
    "\n",
    "loss_fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>autoencoder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.484300</td>\n",
       "      <td>1.779452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.997361</td>\n",
       "      <td>1.214357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.330132</td>\n",
       "      <td>0.578325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.746777</td>\n",
       "      <td>0.798297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.395267</td>\n",
       "      <td>1.461898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.061073</td>\n",
       "      <td>2.528696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.049002</td>\n",
       "      <td>3.761956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       baseline  autoencoder\n",
       "count  7.000000     7.000000\n",
       "mean   1.484300     1.779452\n",
       "std    0.997361     1.214357\n",
       "min    0.330132     0.578325\n",
       "25%    0.746777     0.798297\n",
       "50%    1.395267     1.461898\n",
       "75%    2.061073     2.528696\n",
       "max    3.049002     3.761956"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fraud.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on the Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to normalize the reconstruction loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_loss_scaler(model, df):\n",
    "    recon_loss = compute_reconstruction_loss(model, df)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(recon_loss)\n",
    "    \n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute the fraud score of a customer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fraud_score(model, df, scaler):\n",
    "    predictions = model.predict(df[feature_cols].values)\n",
    "    recon_loss = compute_reconstruction_loss(model, df)\n",
    "    \n",
    "    fraud_scores = pd.DataFrame.from_records(scaler.transform(recon_loss), \n",
    "                                             columns=[\"fraud_score\"])\n",
    "    \n",
    "    return fraud_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute fraud score for the train, valid and fraud set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = build_loss_scaler(model, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.241012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.155532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.129440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.203142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.314493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fraud_score\n",
       "count   800.000000\n",
       "mean      0.241012\n",
       "std       0.155532\n",
       "min       0.000000\n",
       "25%       0.129440\n",
       "50%       0.203142\n",
       "75%       0.314493\n",
       "max       1.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_fraud_score(model, train_df, scaler).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.877574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.820826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.836677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>0.813874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fraud_score\n",
       "119     0.877574\n",
       "124     0.820826\n",
       "141     0.836677\n",
       "305     1.000000\n",
       "697     0.813874"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_fraud_score(model, train_df, scaler).query('fraud_score > 0.8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.328893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.220852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.029441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.157177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.295544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.425886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.635822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fraud_score\n",
       "count   200.000000\n",
       "mean      0.328893\n",
       "std       0.220852\n",
       "min       0.029441\n",
       "25%       0.157177\n",
       "50%       0.295544\n",
       "75%       0.425886\n",
       "max       1.635822"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_fraud_score(model, valid_df, scaler).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.393763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.961767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.442474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.616691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.142262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.987162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.963901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fraud_score\n",
       "count     7.000000\n",
       "mean      1.393763\n",
       "std       0.961767\n",
       "min       0.442474\n",
       "25%       0.616691\n",
       "50%       1.142262\n",
       "75%       1.987162\n",
       "max       2.963901"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_fraud_score(model, fraud_df, scaler).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.606003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.627380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.306757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.667568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.442474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.142262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.963901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fraud_score\n",
       "0     0.606003\n",
       "1     0.627380\n",
       "2     2.306757\n",
       "3     1.667568\n",
       "4     0.442474\n",
       "5     1.142262\n",
       "6     2.963901"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_fraud_score(model, fraud_df, scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these tables, we will set a threshold of 0.8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAUD_SCORE_THRESHOLD = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we predict the which of the customers in the test set is fraud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['fraud_score'] = compute_fraud_score(model, test_df[feature_cols], scaler)\n",
    "test_df['Marker'] = test_df['fraud_score'].apply(lambda score: 'FRAUD' if score >= FRAUD_SCORE_THRESHOLD else 'NOT FRAUD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the `CustomerID` of the people we think are fraud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CustomerID\n",
       "9         2010\n",
       "38        2039\n",
       "79        2080\n",
       "81        2082\n",
       "92        2093"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.query('Marker == \"FRAUD\"')['CustomerID'].to_frame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
